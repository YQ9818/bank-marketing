{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>...</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171429</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414286</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.389322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  default  housing  loan  campaign  pdays  previous  poutcome  \\\n",
       "0  0.171429        1       -1     1  0.029412    1.0       0.0         0   \n",
       "1  0.300000        1        1     1  0.088235    1.0       0.0         0   \n",
       "2  0.100000        1       -1     1  0.000000    1.0       0.0         0   \n",
       "3  0.285714        1        0     0  0.058824    1.0       0.0         0   \n",
       "4  0.414286        1       -1     1  0.000000    1.0       0.0         0   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  ...  month_mar  month_may  month_nov  \\\n",
       "0      0.333333        0.269680  ...          0          1          0   \n",
       "1      0.937500        0.698753  ...          0          1          0   \n",
       "2      1.000000        0.882307  ...          0          0          0   \n",
       "3      1.000000        0.882307  ...          0          0          0   \n",
       "4      0.687500        0.389322  ...          0          0          1   \n",
       "\n",
       "   month_oct  month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0          0          0                1                0                0   \n",
       "1          0          0                1                0                0   \n",
       "2          0          0                0                0                0   \n",
       "3          0          0                1                0                0   \n",
       "4          0          0                0                1                0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                1  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"..\\..\\Data\\small_ohe.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'default', 'housing', 'loan', 'campaign', 'pdays', 'previous',\n",
       "       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
       "       'euribor3m', 'nr.employed', 'y', 'pdays2', 'job_admin.',\n",
       "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
       "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'contact_cellular', 'contact_telephone',\n",
       "       'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'day_of_week_fri', 'day_of_week_mon', 'day_of_week_thu',\n",
       "       'day_of_week_tue', 'day_of_week_wed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saperating features and result vectors\n",
    "X = data.drop('y', axis=1).values\n",
    "y = data['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define no sequence of layers\n",
    "input_tensor = tf.keras.Input(shape=(55,))\n",
    "layer1 = tf.keras.layers.Dense(64,name = 'layer_1', activation='relu',use_bias=True)(input_tensor)\n",
    "layer2 = tf.keras.layers.Dense(64,name = 'layer_2', activation='relu',use_bias=True)(layer1)\n",
    "layer3 = tf.keras.layers.Dense(32,name = 'layer_3', activation='relu',use_bias=True)(layer2)\n",
    "layer4 = tf.keras.layers.Dense(1, name = 'logit', activation=None,use_bias=True)(layer3)\n",
    "output_tensor = tf.keras.layers.Activation('sigmoid', name='output')(layer4)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=[layer1,layer2,layer3,layer4,output_tensor]) \n",
    "losses = {'logit': 'BinaryCrossentropy'}\n",
    "model.compile(loss=losses, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 0.7678 - logit_loss: 0.7678 - layer_1_accuracy: 0.0059 - layer_2_accuracy: 0.0668 - layer_3_accuracy: 0.0310 - logit_accuracy: 0.6069 - output_accuracy: 0.5003 - val_loss: 0.5879 - val_logit_loss: 0.5879 - val_layer_1_accuracy: 0.0078 - val_layer_2_accuracy: 0.1154 - val_layer_3_accuracy: 0.0339 - val_logit_accuracy: 0.7087 - val_output_accuracy: 0.4961\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5858 - logit_loss: 0.5858 - layer_1_accuracy: 0.0081 - layer_2_accuracy: 0.1166 - layer_3_accuracy: 0.0320 - logit_accuracy: 0.7177 - output_accuracy: 0.4968 - val_loss: 0.5690 - val_logit_loss: 0.5690 - val_layer_1_accuracy: 0.0124 - val_layer_2_accuracy: 0.1466 - val_layer_3_accuracy: 0.0325 - val_logit_accuracy: 0.7265 - val_output_accuracy: 0.4993\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5556 - logit_loss: 0.5556 - layer_1_accuracy: 0.0088 - layer_2_accuracy: 0.1347 - layer_3_accuracy: 0.0267 - logit_accuracy: 0.7392 - output_accuracy: 0.4987 - val_loss: 0.5571 - val_logit_loss: 0.5571 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.1168 - val_layer_3_accuracy: 0.0183 - val_logit_accuracy: 0.7458 - val_output_accuracy: 0.4970\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5264 - logit_loss: 0.5264 - layer_1_accuracy: 0.0110 - layer_2_accuracy: 0.1096 - layer_3_accuracy: 0.0226 - logit_accuracy: 0.7526 - output_accuracy: 0.5060 - val_loss: 0.5441 - val_logit_loss: 0.5441 - val_layer_1_accuracy: 0.0133 - val_layer_2_accuracy: 0.1283 - val_layer_3_accuracy: 0.0234 - val_logit_accuracy: 0.7426 - val_output_accuracy: 0.5158\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4991 - logit_loss: 0.4991 - layer_1_accuracy: 0.0118 - layer_2_accuracy: 0.1103 - layer_3_accuracy: 0.0157 - logit_accuracy: 0.7575 - output_accuracy: 0.5129 - val_loss: 0.5188 - val_logit_loss: 0.5188 - val_layer_1_accuracy: 0.0142 - val_layer_2_accuracy: 0.1040 - val_layer_3_accuracy: 0.0156 - val_logit_accuracy: 0.7526 - val_output_accuracy: 0.5245\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4737 - logit_loss: 0.4737 - layer_1_accuracy: 0.0157 - layer_2_accuracy: 0.1064 - layer_3_accuracy: 0.0145 - logit_accuracy: 0.7665 - output_accuracy: 0.5264 - val_loss: 0.5121 - val_logit_loss: 0.5121 - val_layer_1_accuracy: 0.0174 - val_layer_2_accuracy: 0.1191 - val_layer_3_accuracy: 0.0206 - val_logit_accuracy: 0.7604 - val_output_accuracy: 0.5479\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4629 - logit_loss: 0.4629 - layer_1_accuracy: 0.0122 - layer_2_accuracy: 0.0872 - layer_3_accuracy: 0.0100 - logit_accuracy: 0.7807 - output_accuracy: 0.5439 - val_loss: 0.5037 - val_logit_loss: 0.5037 - val_layer_1_accuracy: 0.0142 - val_layer_2_accuracy: 0.0394 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.7568 - val_output_accuracy: 0.5158\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4726 - logit_loss: 0.4726 - layer_1_accuracy: 0.0069 - layer_2_accuracy: 0.0518 - layer_3_accuracy: 0.0075 - logit_accuracy: 0.7691 - output_accuracy: 0.5402 - val_loss: 0.5151 - val_logit_loss: 0.5151 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0522 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.7696 - val_output_accuracy: 0.5323\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4250 - logit_loss: 0.4250 - layer_1_accuracy: 0.0112 - layer_2_accuracy: 0.0734 - layer_3_accuracy: 0.0063 - logit_accuracy: 0.7909 - output_accuracy: 0.5739 - val_loss: 0.5039 - val_logit_loss: 0.5039 - val_layer_1_accuracy: 0.0160 - val_layer_2_accuracy: 0.0806 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.7815 - val_output_accuracy: 0.5598\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3981 - logit_loss: 0.3981 - layer_1_accuracy: 0.0130 - layer_2_accuracy: 0.0909 - layer_3_accuracy: 0.0075 - logit_accuracy: 0.8037 - output_accuracy: 0.5965 - val_loss: 0.5023 - val_logit_loss: 0.5023 - val_layer_1_accuracy: 0.0156 - val_layer_2_accuracy: 0.0889 - val_layer_3_accuracy: 0.0018 - val_logit_accuracy: 0.7888 - val_output_accuracy: 0.5712\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3714 - logit_loss: 0.3714 - layer_1_accuracy: 0.0132 - layer_2_accuracy: 0.0878 - layer_3_accuracy: 0.0057 - logit_accuracy: 0.8158 - output_accuracy: 0.6250 - val_loss: 0.4589 - val_logit_loss: 0.4589 - val_layer_1_accuracy: 0.0160 - val_layer_2_accuracy: 0.0820 - val_layer_3_accuracy: 0.0073 - val_logit_accuracy: 0.8117 - val_output_accuracy: 0.6335\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3429 - logit_loss: 0.3429 - layer_1_accuracy: 0.0134 - layer_2_accuracy: 0.0768 - layer_3_accuracy: 0.0073 - logit_accuracy: 0.8359 - output_accuracy: 0.6534 - val_loss: 0.4494 - val_logit_loss: 0.4494 - val_layer_1_accuracy: 0.0147 - val_layer_2_accuracy: 0.0774 - val_layer_3_accuracy: 0.0032 - val_logit_accuracy: 0.8255 - val_output_accuracy: 0.6326\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3190 - logit_loss: 0.3190 - layer_1_accuracy: 0.0126 - layer_2_accuracy: 0.0695 - layer_3_accuracy: 0.0049 - logit_accuracy: 0.8492 - output_accuracy: 0.6752 - val_loss: 0.4110 - val_logit_loss: 0.4110 - val_layer_1_accuracy: 0.0147 - val_layer_2_accuracy: 0.0760 - val_layer_3_accuracy: 0.0050 - val_logit_accuracy: 0.8177 - val_output_accuracy: 0.6922\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2988 - logit_loss: 0.2988 - layer_1_accuracy: 0.0124 - layer_2_accuracy: 0.0673 - layer_3_accuracy: 0.0059 - logit_accuracy: 0.8651 - output_accuracy: 0.6988 - val_loss: 0.4568 - val_logit_loss: 0.4568 - val_layer_1_accuracy: 0.0160 - val_layer_2_accuracy: 0.0609 - val_layer_3_accuracy: 0.0069 - val_logit_accuracy: 0.8383 - val_output_accuracy: 0.6706\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2788 - logit_loss: 0.2788 - layer_1_accuracy: 0.0132 - layer_2_accuracy: 0.0571 - layer_3_accuracy: 0.0057 - logit_accuracy: 0.8763 - output_accuracy: 0.7273 - val_loss: 0.4328 - val_logit_loss: 0.4328 - val_layer_1_accuracy: 0.0160 - val_layer_2_accuracy: 0.0559 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.8447 - val_output_accuracy: 0.6853\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3267 - logit_loss: 0.3267 - layer_1_accuracy: 0.0102 - layer_2_accuracy: 0.0638 - layer_3_accuracy: 0.0118 - logit_accuracy: 0.8741 - output_accuracy: 0.7367 - val_loss: 0.4822 - val_logit_loss: 0.4822 - val_layer_1_accuracy: 0.0128 - val_layer_2_accuracy: 0.0733 - val_layer_3_accuracy: 0.0101 - val_logit_accuracy: 0.8585 - val_output_accuracy: 0.7041\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2693 - logit_loss: 0.2693 - layer_1_accuracy: 0.0098 - layer_2_accuracy: 0.0564 - layer_3_accuracy: 0.0090 - logit_accuracy: 0.8987 - output_accuracy: 0.7532 - val_loss: 0.4041 - val_logit_loss: 0.4041 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0508 - val_layer_3_accuracy: 0.0105 - val_logit_accuracy: 0.8525 - val_output_accuracy: 0.7590\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3019 - logit_loss: 0.3019 - layer_1_accuracy: 0.0116 - layer_2_accuracy: 0.0532 - layer_3_accuracy: 0.0106 - logit_accuracy: 0.8802 - output_accuracy: 0.7760 - val_loss: 0.5691 - val_logit_loss: 0.5691 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0683 - val_layer_3_accuracy: 0.0133 - val_logit_accuracy: 0.8259 - val_output_accuracy: 0.6537\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2873 - logit_loss: 0.2873 - layer_1_accuracy: 0.0132 - layer_2_accuracy: 0.0693 - layer_3_accuracy: 0.0094 - logit_accuracy: 0.8877 - output_accuracy: 0.7440 - val_loss: 0.4395 - val_logit_loss: 0.4395 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0614 - val_layer_3_accuracy: 0.0105 - val_logit_accuracy: 0.8731 - val_output_accuracy: 0.7426\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2359 - logit_loss: 0.2359 - layer_1_accuracy: 0.0116 - layer_2_accuracy: 0.0530 - layer_3_accuracy: 0.0084 - logit_accuracy: 0.9118 - output_accuracy: 0.7970 - val_loss: 0.4373 - val_logit_loss: 0.4373 - val_layer_1_accuracy: 0.0128 - val_layer_2_accuracy: 0.0513 - val_layer_3_accuracy: 0.0105 - val_logit_accuracy: 0.8823 - val_output_accuracy: 0.7293\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2273 - logit_loss: 0.2273 - layer_1_accuracy: 0.0104 - layer_2_accuracy: 0.0436 - layer_3_accuracy: 0.0096 - logit_accuracy: 0.9264 - output_accuracy: 0.8091 - val_loss: 0.3987 - val_logit_loss: 0.3987 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0458 - val_layer_3_accuracy: 0.0137 - val_logit_accuracy: 0.8896 - val_output_accuracy: 0.7778\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2026 - logit_loss: 0.2026 - layer_1_accuracy: 0.0112 - layer_2_accuracy: 0.0403 - layer_3_accuracy: 0.0114 - logit_accuracy: 0.9380 - output_accuracy: 0.8203 - val_loss: 0.3652 - val_logit_loss: 0.3652 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0467 - val_layer_3_accuracy: 0.0119 - val_logit_accuracy: 0.8992 - val_output_accuracy: 0.7971\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1910 - logit_loss: 0.1910 - layer_1_accuracy: 0.0110 - layer_2_accuracy: 0.0406 - layer_3_accuracy: 0.0139 - logit_accuracy: 0.9399 - output_accuracy: 0.8359 - val_loss: 0.4327 - val_logit_loss: 0.4327 - val_layer_1_accuracy: 0.0087 - val_layer_2_accuracy: 0.0454 - val_layer_3_accuracy: 0.0147 - val_logit_accuracy: 0.8969 - val_output_accuracy: 0.7870\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1815 - logit_loss: 0.1815 - layer_1_accuracy: 0.0120 - layer_2_accuracy: 0.0406 - layer_3_accuracy: 0.0120 - logit_accuracy: 0.9452 - output_accuracy: 0.8451 - val_loss: 0.3859 - val_logit_loss: 0.3859 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0389 - val_layer_3_accuracy: 0.0096 - val_logit_accuracy: 0.9079 - val_output_accuracy: 0.8204\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1643 - logit_loss: 0.1643 - layer_1_accuracy: 0.0110 - layer_2_accuracy: 0.0365 - layer_3_accuracy: 0.0126 - logit_accuracy: 0.9509 - output_accuracy: 0.8622 - val_loss: 0.3880 - val_logit_loss: 0.3880 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0426 - val_layer_3_accuracy: 0.0133 - val_logit_accuracy: 0.9162 - val_output_accuracy: 0.8168\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1610 - logit_loss: 0.1610 - layer_1_accuracy: 0.0126 - layer_2_accuracy: 0.0418 - layer_3_accuracy: 0.0126 - logit_accuracy: 0.9556 - output_accuracy: 0.8681 - val_loss: 0.3421 - val_logit_loss: 0.3421 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0508 - val_layer_3_accuracy: 0.0165 - val_logit_accuracy: 0.9061 - val_output_accuracy: 0.8571\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4748 - logit_loss: 0.4748 - layer_1_accuracy: 0.0104 - layer_2_accuracy: 0.0253 - layer_3_accuracy: 0.0122 - logit_accuracy: 0.9032 - output_accuracy: 0.8362 - val_loss: 2.1917 - val_logit_loss: 2.1917 - val_layer_1_accuracy: 0.0041 - val_layer_2_accuracy: 0.0179 - val_layer_3_accuracy: 0.0096 - val_logit_accuracy: 0.6917 - val_output_accuracy: 0.8108\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6187 - logit_loss: 0.6187 - layer_1_accuracy: 0.0049 - layer_2_accuracy: 0.0202 - layer_3_accuracy: 0.0055 - logit_accuracy: 0.8506 - output_accuracy: 0.7705 - val_loss: 0.5207 - val_logit_loss: 0.5207 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0325 - val_layer_3_accuracy: 0.0050 - val_logit_accuracy: 0.8759 - val_output_accuracy: 0.7623\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3236 - logit_loss: 0.3236 - layer_1_accuracy: 0.0041 - layer_2_accuracy: 0.0312 - layer_3_accuracy: 0.0075 - logit_accuracy: 0.9136 - output_accuracy: 0.8040 - val_loss: 0.4544 - val_logit_loss: 0.4544 - val_layer_1_accuracy: 0.0064 - val_layer_2_accuracy: 0.0412 - val_layer_3_accuracy: 0.0082 - val_logit_accuracy: 0.8713 - val_output_accuracy: 0.8365\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3200 - logit_loss: 0.3200 - layer_1_accuracy: 0.0037 - layer_2_accuracy: 0.0353 - layer_3_accuracy: 0.0084 - logit_accuracy: 0.9248 - output_accuracy: 0.8278 - val_loss: 0.4954 - val_logit_loss: 0.4954 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0454 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.8736 - val_output_accuracy: 0.8204\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2841 - logit_loss: 0.2841 - layer_1_accuracy: 0.0053 - layer_2_accuracy: 0.0306 - layer_3_accuracy: 0.0102 - logit_accuracy: 0.9317 - output_accuracy: 0.8435 - val_loss: 0.5803 - val_logit_loss: 0.5803 - val_layer_1_accuracy: 0.0078 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0055 - val_logit_accuracy: 0.8749 - val_output_accuracy: 0.7494\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3582 - logit_loss: 0.3582 - layer_1_accuracy: 0.0049 - layer_2_accuracy: 0.0344 - layer_3_accuracy: 0.0098 - logit_accuracy: 0.9264 - output_accuracy: 0.8404 - val_loss: 0.5291 - val_logit_loss: 0.5291 - val_layer_1_accuracy: 0.0064 - val_layer_2_accuracy: 0.0421 - val_layer_3_accuracy: 0.0082 - val_logit_accuracy: 0.8901 - val_output_accuracy: 0.7962\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.2087 - logit_loss: 1.2087 - layer_1_accuracy: 0.0120 - layer_2_accuracy: 0.0340 - layer_3_accuracy: 0.0045 - logit_accuracy: 0.8107 - output_accuracy: 0.7624 - val_loss: 1.6492 - val_logit_loss: 1.6492 - val_layer_1_accuracy: 0.0192 - val_layer_2_accuracy: 0.0454 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.7187 - val_output_accuracy: 0.6949\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.9895 - logit_loss: 0.9895 - layer_1_accuracy: 0.0173 - layer_2_accuracy: 0.0348 - layer_3_accuracy: 5.8904e-04 - logit_accuracy: 0.7640 - output_accuracy: 0.6487 - val_loss: 2.3488 - val_logit_loss: 2.3488 - val_layer_1_accuracy: 0.0293 - val_layer_2_accuracy: 0.0518 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.6546 - val_output_accuracy: 0.5657\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.9147 - logit_loss: 0.9147 - layer_1_accuracy: 0.0326 - layer_2_accuracy: 0.2395 - layer_3_accuracy: 0.0055 - logit_accuracy: 0.7583 - output_accuracy: 0.6216 - val_loss: 0.6488 - val_logit_loss: 0.6488 - val_layer_1_accuracy: 0.0321 - val_layer_2_accuracy: 0.3124 - val_layer_3_accuracy: 0.0069 - val_logit_accuracy: 0.7590 - val_output_accuracy: 0.5552\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5281 - logit_loss: 0.5281 - layer_1_accuracy: 0.0304 - layer_2_accuracy: 0.3318 - layer_3_accuracy: 0.0073 - logit_accuracy: 0.7895 - output_accuracy: 0.6144 - val_loss: 0.6060 - val_logit_loss: 0.6060 - val_layer_1_accuracy: 0.0334 - val_layer_2_accuracy: 0.3408 - val_layer_3_accuracy: 0.0082 - val_logit_accuracy: 0.7801 - val_output_accuracy: 0.6253\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4872 - logit_loss: 0.4872 - layer_1_accuracy: 0.0277 - layer_2_accuracy: 0.3334 - layer_3_accuracy: 0.0086 - logit_accuracy: 0.8188 - output_accuracy: 0.6621 - val_loss: 0.6160 - val_logit_loss: 0.6160 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.3394 - val_layer_3_accuracy: 0.0101 - val_logit_accuracy: 0.7998 - val_output_accuracy: 0.6720\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4329 - logit_loss: 0.4329 - layer_1_accuracy: 0.0275 - layer_2_accuracy: 0.3326 - layer_3_accuracy: 0.0077 - logit_accuracy: 0.8378 - output_accuracy: 0.7014 - val_loss: 0.5632 - val_logit_loss: 0.5632 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.3372 - val_layer_3_accuracy: 0.0101 - val_logit_accuracy: 0.8163 - val_output_accuracy: 0.6954\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4003 - logit_loss: 0.4003 - layer_1_accuracy: 0.0275 - layer_2_accuracy: 0.3373 - layer_3_accuracy: 0.0090 - logit_accuracy: 0.8547 - output_accuracy: 0.7347 - val_loss: 0.5449 - val_logit_loss: 0.5449 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.3339 - val_layer_3_accuracy: 0.0110 - val_logit_accuracy: 0.8310 - val_output_accuracy: 0.7247\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3721 - logit_loss: 0.3721 - layer_1_accuracy: 0.0287 - layer_2_accuracy: 0.3318 - layer_3_accuracy: 0.0143 - logit_accuracy: 0.8681 - output_accuracy: 0.7601 - val_loss: 0.5424 - val_logit_loss: 0.5424 - val_layer_1_accuracy: 0.0321 - val_layer_2_accuracy: 0.3294 - val_layer_3_accuracy: 0.0247 - val_logit_accuracy: 0.8365 - val_output_accuracy: 0.7485\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3446 - logit_loss: 0.3446 - layer_1_accuracy: 0.0287 - layer_2_accuracy: 0.3297 - layer_3_accuracy: 0.0275 - logit_accuracy: 0.8783 - output_accuracy: 0.7740 - val_loss: 0.5377 - val_logit_loss: 0.5377 - val_layer_1_accuracy: 0.0321 - val_layer_2_accuracy: 0.3312 - val_layer_3_accuracy: 0.0215 - val_logit_accuracy: 0.8520 - val_output_accuracy: 0.7503\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3247 - logit_loss: 0.3247 - layer_1_accuracy: 0.0281 - layer_2_accuracy: 0.3275 - layer_3_accuracy: 0.0279 - logit_accuracy: 0.8983 - output_accuracy: 0.7885 - val_loss: 0.5557 - val_logit_loss: 0.5557 - val_layer_1_accuracy: 0.0321 - val_layer_2_accuracy: 0.3294 - val_layer_3_accuracy: 0.0257 - val_logit_accuracy: 0.8603 - val_output_accuracy: 0.7723\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3120 - logit_loss: 0.3120 - layer_1_accuracy: 0.0283 - layer_2_accuracy: 0.3218 - layer_3_accuracy: 0.0365 - logit_accuracy: 0.9030 - output_accuracy: 0.8044 - val_loss: 0.5421 - val_logit_loss: 0.5421 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.3184 - val_layer_3_accuracy: 0.0261 - val_logit_accuracy: 0.8713 - val_output_accuracy: 0.7728\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2941 - logit_loss: 0.2941 - layer_1_accuracy: 0.0281 - layer_2_accuracy: 0.3191 - layer_3_accuracy: 0.0373 - logit_accuracy: 0.9130 - output_accuracy: 0.8174 - val_loss: 0.5240 - val_logit_loss: 0.5240 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.3138 - val_layer_3_accuracy: 0.0357 - val_logit_accuracy: 0.8731 - val_output_accuracy: 0.7838\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2812 - logit_loss: 0.2812 - layer_1_accuracy: 0.0275 - layer_2_accuracy: 0.3155 - layer_3_accuracy: 0.0434 - logit_accuracy: 0.9185 - output_accuracy: 0.8239 - val_loss: 0.5055 - val_logit_loss: 0.5055 - val_layer_1_accuracy: 0.0325 - val_layer_2_accuracy: 0.3129 - val_layer_3_accuracy: 0.0376 - val_logit_accuracy: 0.8804 - val_output_accuracy: 0.7984\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2705 - logit_loss: 0.2705 - layer_1_accuracy: 0.0285 - layer_2_accuracy: 0.3118 - layer_3_accuracy: 0.0438 - logit_accuracy: 0.9236 - output_accuracy: 0.8343 - val_loss: 0.5078 - val_logit_loss: 0.5078 - val_layer_1_accuracy: 0.0325 - val_layer_2_accuracy: 0.3101 - val_layer_3_accuracy: 0.0366 - val_logit_accuracy: 0.8846 - val_output_accuracy: 0.7962\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2492 - logit_loss: 0.2492 - layer_1_accuracy: 0.0283 - layer_2_accuracy: 0.3100 - layer_3_accuracy: 0.0497 - logit_accuracy: 0.9215 - output_accuracy: 0.8368 - val_loss: 0.4938 - val_logit_loss: 0.4938 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.3138 - val_layer_3_accuracy: 0.0417 - val_logit_accuracy: 0.8855 - val_output_accuracy: 0.8200\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2457 - logit_loss: 0.2457 - layer_1_accuracy: 0.0275 - layer_2_accuracy: 0.3083 - layer_3_accuracy: 0.0457 - logit_accuracy: 0.9283 - output_accuracy: 0.8476 - val_loss: 0.5072 - val_logit_loss: 0.5072 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.3037 - val_layer_3_accuracy: 0.0344 - val_logit_accuracy: 0.8882 - val_output_accuracy: 0.8012\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2411 - logit_loss: 0.2411 - layer_1_accuracy: 0.0277 - layer_2_accuracy: 0.3057 - layer_3_accuracy: 0.0477 - logit_accuracy: 0.9327 - output_accuracy: 0.8533 - val_loss: 0.4902 - val_logit_loss: 0.4902 - val_layer_1_accuracy: 0.0325 - val_layer_2_accuracy: 0.3074 - val_layer_3_accuracy: 0.0412 - val_logit_accuracy: 0.8960 - val_output_accuracy: 0.8213\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3905 - logit_loss: 0.3905 - layer_1_accuracy: 0.0287 - layer_2_accuracy: 0.2951 - layer_3_accuracy: 0.0520 - logit_accuracy: 0.9056 - output_accuracy: 0.8270 - val_loss: 0.7517 - val_logit_loss: 0.7517 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.2863 - val_layer_3_accuracy: 0.0385 - val_logit_accuracy: 0.8488 - val_output_accuracy: 0.7481\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4103 - logit_loss: 0.4103 - layer_1_accuracy: 0.0261 - layer_2_accuracy: 0.2961 - layer_3_accuracy: 0.0391 - logit_accuracy: 0.8857 - output_accuracy: 0.7854 - val_loss: 0.5483 - val_logit_loss: 0.5483 - val_layer_1_accuracy: 0.0238 - val_layer_2_accuracy: 0.2932 - val_layer_3_accuracy: 0.0527 - val_logit_accuracy: 0.8662 - val_output_accuracy: 0.7710\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3790 - logit_loss: 0.3790 - layer_1_accuracy: 0.0204 - layer_2_accuracy: 0.3230 - layer_3_accuracy: 0.0336 - logit_accuracy: 0.8806 - output_accuracy: 0.7991 - val_loss: 0.6362 - val_logit_loss: 0.6362 - val_layer_1_accuracy: 0.0215 - val_layer_2_accuracy: 0.3298 - val_layer_3_accuracy: 0.0261 - val_logit_accuracy: 0.8429 - val_output_accuracy: 0.7787\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4043 - logit_loss: 0.4043 - layer_1_accuracy: 0.0200 - layer_2_accuracy: 0.3208 - layer_3_accuracy: 0.0271 - logit_accuracy: 0.9044 - output_accuracy: 0.8046 - val_loss: 0.6051 - val_logit_loss: 0.6051 - val_layer_1_accuracy: 0.0238 - val_layer_2_accuracy: 0.3184 - val_layer_3_accuracy: 0.0371 - val_logit_accuracy: 0.8694 - val_output_accuracy: 0.7957\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3523 - logit_loss: 0.3523 - layer_1_accuracy: 0.0222 - layer_2_accuracy: 0.3104 - layer_3_accuracy: 0.0348 - logit_accuracy: 0.9101 - output_accuracy: 0.8019 - val_loss: 0.5055 - val_logit_loss: 0.5055 - val_layer_1_accuracy: 0.0266 - val_layer_2_accuracy: 0.3115 - val_layer_3_accuracy: 0.0481 - val_logit_accuracy: 0.8704 - val_output_accuracy: 0.7673\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2534 - logit_loss: 0.2534 - layer_1_accuracy: 0.0224 - layer_2_accuracy: 0.3114 - layer_3_accuracy: 0.0544 - logit_accuracy: 0.9252 - output_accuracy: 0.8347 - val_loss: 0.4676 - val_logit_loss: 0.4676 - val_layer_1_accuracy: 0.0257 - val_layer_2_accuracy: 0.3120 - val_layer_3_accuracy: 0.0408 - val_logit_accuracy: 0.8804 - val_output_accuracy: 0.8058\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2340 - logit_loss: 0.2340 - layer_1_accuracy: 0.0236 - layer_2_accuracy: 0.3067 - layer_3_accuracy: 0.0471 - logit_accuracy: 0.9378 - output_accuracy: 0.8400 - val_loss: 0.4369 - val_logit_loss: 0.4369 - val_layer_1_accuracy: 0.0261 - val_layer_2_accuracy: 0.3074 - val_layer_3_accuracy: 0.0454 - val_logit_accuracy: 0.8882 - val_output_accuracy: 0.8209\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2215 - logit_loss: 0.2215 - layer_1_accuracy: 0.0240 - layer_2_accuracy: 0.3039 - layer_3_accuracy: 0.0477 - logit_accuracy: 0.9409 - output_accuracy: 0.8586 - val_loss: 0.4207 - val_logit_loss: 0.4207 - val_layer_1_accuracy: 0.0261 - val_layer_2_accuracy: 0.3028 - val_layer_3_accuracy: 0.0421 - val_logit_accuracy: 0.8946 - val_output_accuracy: 0.8204\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2118 - logit_loss: 0.2118 - layer_1_accuracy: 0.0238 - layer_2_accuracy: 0.3004 - layer_3_accuracy: 0.0442 - logit_accuracy: 0.9452 - output_accuracy: 0.8675 - val_loss: 0.4426 - val_logit_loss: 0.4426 - val_layer_1_accuracy: 0.0252 - val_layer_2_accuracy: 0.2973 - val_layer_3_accuracy: 0.0435 - val_logit_accuracy: 0.8933 - val_output_accuracy: 0.8200\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2054 - logit_loss: 0.2054 - layer_1_accuracy: 0.0228 - layer_2_accuracy: 0.2998 - layer_3_accuracy: 0.0479 - logit_accuracy: 0.9480 - output_accuracy: 0.8696 - val_loss: 0.4490 - val_logit_loss: 0.4490 - val_layer_1_accuracy: 0.0252 - val_layer_2_accuracy: 0.2982 - val_layer_3_accuracy: 0.0389 - val_logit_accuracy: 0.8919 - val_output_accuracy: 0.8259\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1994 - logit_loss: 0.1994 - layer_1_accuracy: 0.0222 - layer_2_accuracy: 0.2971 - layer_3_accuracy: 0.0471 - logit_accuracy: 0.9497 - output_accuracy: 0.8749 - val_loss: 0.4365 - val_logit_loss: 0.4365 - val_layer_1_accuracy: 0.0243 - val_layer_2_accuracy: 0.2923 - val_layer_3_accuracy: 0.0449 - val_logit_accuracy: 0.8992 - val_output_accuracy: 0.8401\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1928 - logit_loss: 0.1928 - layer_1_accuracy: 0.0222 - layer_2_accuracy: 0.2922 - layer_3_accuracy: 0.0497 - logit_accuracy: 0.9531 - output_accuracy: 0.8824 - val_loss: 0.4330 - val_logit_loss: 0.4330 - val_layer_1_accuracy: 0.0252 - val_layer_2_accuracy: 0.2900 - val_layer_3_accuracy: 0.0472 - val_logit_accuracy: 0.9029 - val_output_accuracy: 0.8438\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1904 - logit_loss: 0.1904 - layer_1_accuracy: 0.0224 - layer_2_accuracy: 0.2900 - layer_3_accuracy: 0.0522 - logit_accuracy: 0.9517 - output_accuracy: 0.8857 - val_loss: 0.4617 - val_logit_loss: 0.4617 - val_layer_1_accuracy: 0.0252 - val_layer_2_accuracy: 0.2854 - val_layer_3_accuracy: 0.0444 - val_logit_accuracy: 0.9047 - val_output_accuracy: 0.8378\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1837 - logit_loss: 0.1837 - layer_1_accuracy: 0.0220 - layer_2_accuracy: 0.2859 - layer_3_accuracy: 0.0532 - logit_accuracy: 0.9560 - output_accuracy: 0.8918 - val_loss: 0.4611 - val_logit_loss: 0.4611 - val_layer_1_accuracy: 0.0252 - val_layer_2_accuracy: 0.2831 - val_layer_3_accuracy: 0.0444 - val_logit_accuracy: 0.9052 - val_output_accuracy: 0.8484\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1790 - logit_loss: 0.1790 - layer_1_accuracy: 0.0230 - layer_2_accuracy: 0.2843 - layer_3_accuracy: 0.0548 - logit_accuracy: 0.9544 - output_accuracy: 0.8973 - val_loss: 0.4514 - val_logit_loss: 0.4514 - val_layer_1_accuracy: 0.0252 - val_layer_2_accuracy: 0.2808 - val_layer_3_accuracy: 0.0412 - val_logit_accuracy: 0.9075 - val_output_accuracy: 0.8543\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1774 - logit_loss: 0.1774 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.2863 - layer_3_accuracy: 0.0518 - logit_accuracy: 0.9574 - output_accuracy: 0.9010 - val_loss: 0.4414 - val_logit_loss: 0.4414 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2803 - val_layer_3_accuracy: 0.0486 - val_logit_accuracy: 0.9157 - val_output_accuracy: 0.8534\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1765 - logit_loss: 0.1765 - layer_1_accuracy: 0.0214 - layer_2_accuracy: 0.2835 - layer_3_accuracy: 0.0546 - logit_accuracy: 0.9613 - output_accuracy: 0.9050 - val_loss: 0.4433 - val_logit_loss: 0.4433 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2781 - val_layer_3_accuracy: 0.0550 - val_logit_accuracy: 0.9153 - val_output_accuracy: 0.8594\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1801 - logit_loss: 0.1801 - layer_1_accuracy: 0.0220 - layer_2_accuracy: 0.2780 - layer_3_accuracy: 0.0569 - logit_accuracy: 0.9576 - output_accuracy: 0.9036 - val_loss: 0.4948 - val_logit_loss: 0.4948 - val_layer_1_accuracy: 0.0247 - val_layer_2_accuracy: 0.2726 - val_layer_3_accuracy: 0.0508 - val_logit_accuracy: 0.9107 - val_output_accuracy: 0.8507\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1970 - logit_loss: 0.1970 - layer_1_accuracy: 0.0212 - layer_2_accuracy: 0.2814 - layer_3_accuracy: 0.0611 - logit_accuracy: 0.9529 - output_accuracy: 0.8975 - val_loss: 0.4967 - val_logit_loss: 0.4967 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2785 - val_layer_3_accuracy: 0.0554 - val_logit_accuracy: 0.9130 - val_output_accuracy: 0.8424\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1858 - logit_loss: 0.1858 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.2829 - layer_3_accuracy: 0.0550 - logit_accuracy: 0.9613 - output_accuracy: 0.9036 - val_loss: 0.4955 - val_logit_loss: 0.4955 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2808 - val_layer_3_accuracy: 0.0504 - val_logit_accuracy: 0.9180 - val_output_accuracy: 0.8681\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1717 - logit_loss: 0.1717 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.2822 - layer_3_accuracy: 0.0577 - logit_accuracy: 0.9633 - output_accuracy: 0.9122 - val_loss: 0.4779 - val_logit_loss: 0.4779 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2767 - val_layer_3_accuracy: 0.0504 - val_logit_accuracy: 0.9180 - val_output_accuracy: 0.8566\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1643 - logit_loss: 0.1643 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.2802 - layer_3_accuracy: 0.0571 - logit_accuracy: 0.9652 - output_accuracy: 0.9175 - val_loss: 0.4570 - val_logit_loss: 0.4570 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2749 - val_layer_3_accuracy: 0.0545 - val_logit_accuracy: 0.9226 - val_output_accuracy: 0.8708\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1609 - logit_loss: 0.1609 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.2763 - layer_3_accuracy: 0.0622 - logit_accuracy: 0.9656 - output_accuracy: 0.9222 - val_loss: 0.4795 - val_logit_loss: 0.4795 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2684 - val_layer_3_accuracy: 0.0518 - val_logit_accuracy: 0.9185 - val_output_accuracy: 0.8603\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1600 - logit_loss: 0.1600 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.2733 - layer_3_accuracy: 0.0662 - logit_accuracy: 0.9656 - output_accuracy: 0.9228 - val_loss: 0.4549 - val_logit_loss: 0.4549 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.2694 - val_layer_3_accuracy: 0.0577 - val_logit_accuracy: 0.9217 - val_output_accuracy: 0.8681\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1618 - logit_loss: 0.1618 - layer_1_accuracy: 0.0216 - layer_2_accuracy: 0.2751 - layer_3_accuracy: 0.0632 - logit_accuracy: 0.9684 - output_accuracy: 0.9289 - val_loss: 0.5342 - val_logit_loss: 0.5342 - val_layer_1_accuracy: 0.0247 - val_layer_2_accuracy: 0.2643 - val_layer_3_accuracy: 0.0605 - val_logit_accuracy: 0.9157 - val_output_accuracy: 0.8520\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6825 - logit_loss: 0.6825 - layer_1_accuracy: 0.0228 - layer_2_accuracy: 0.2372 - layer_3_accuracy: 0.0393 - logit_accuracy: 0.8659 - output_accuracy: 0.8052 - val_loss: 0.7288 - val_logit_loss: 0.7288 - val_layer_1_accuracy: 0.0266 - val_layer_2_accuracy: 0.2162 - val_layer_3_accuracy: 0.0238 - val_logit_accuracy: 0.8319 - val_output_accuracy: 0.7865\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4308 - logit_loss: 0.4308 - layer_1_accuracy: 0.0206 - layer_2_accuracy: 0.2038 - layer_3_accuracy: 0.0157 - logit_accuracy: 0.8971 - output_accuracy: 0.8027 - val_loss: 0.5245 - val_logit_loss: 0.5245 - val_layer_1_accuracy: 0.0224 - val_layer_2_accuracy: 0.2066 - val_layer_3_accuracy: 0.0115 - val_logit_accuracy: 0.8768 - val_output_accuracy: 0.7902\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3213 - logit_loss: 0.3213 - layer_1_accuracy: 0.0192 - layer_2_accuracy: 0.2068 - layer_3_accuracy: 0.0220 - logit_accuracy: 0.9275 - output_accuracy: 0.8262 - val_loss: 0.4600 - val_logit_loss: 0.4600 - val_layer_1_accuracy: 0.0229 - val_layer_2_accuracy: 0.2158 - val_layer_3_accuracy: 0.0188 - val_logit_accuracy: 0.8965 - val_output_accuracy: 0.8168\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2656 - logit_loss: 0.2656 - layer_1_accuracy: 0.0194 - layer_2_accuracy: 0.2254 - layer_3_accuracy: 0.0281 - logit_accuracy: 0.9436 - output_accuracy: 0.8628 - val_loss: 0.4497 - val_logit_loss: 0.4497 - val_layer_1_accuracy: 0.0229 - val_layer_2_accuracy: 0.2254 - val_layer_3_accuracy: 0.0206 - val_logit_accuracy: 0.9093 - val_output_accuracy: 0.8415\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2488 - logit_loss: 0.2488 - layer_1_accuracy: 0.0194 - layer_2_accuracy: 0.2276 - layer_3_accuracy: 0.0318 - logit_accuracy: 0.9493 - output_accuracy: 0.8804 - val_loss: 0.4478 - val_logit_loss: 0.4478 - val_layer_1_accuracy: 0.0229 - val_layer_2_accuracy: 0.2327 - val_layer_3_accuracy: 0.0247 - val_logit_accuracy: 0.9125 - val_output_accuracy: 0.8548\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2381 - logit_loss: 0.2381 - layer_1_accuracy: 0.0194 - layer_2_accuracy: 0.2331 - layer_3_accuracy: 0.0349 - logit_accuracy: 0.9493 - output_accuracy: 0.8944 - val_loss: 0.4649 - val_logit_loss: 0.4649 - val_layer_1_accuracy: 0.0229 - val_layer_2_accuracy: 0.2290 - val_layer_3_accuracy: 0.0266 - val_logit_accuracy: 0.9130 - val_output_accuracy: 0.8566\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4087 - logit_loss: 0.4087 - layer_1_accuracy: 0.0190 - layer_2_accuracy: 0.2360 - layer_3_accuracy: 0.0308 - logit_accuracy: 0.9187 - output_accuracy: 0.8989 - val_loss: 1.1557 - val_logit_loss: 1.1557 - val_layer_1_accuracy: 0.0179 - val_layer_2_accuracy: 0.2038 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.8191 - val_output_accuracy: 0.7393\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6372 - logit_loss: 0.6372 - layer_1_accuracy: 0.0151 - layer_2_accuracy: 0.1834 - layer_3_accuracy: 0.0194 - logit_accuracy: 0.8673 - output_accuracy: 0.7679 - val_loss: 0.6641 - val_logit_loss: 0.6641 - val_layer_1_accuracy: 0.0128 - val_layer_2_accuracy: 0.1645 - val_layer_3_accuracy: 0.0568 - val_logit_accuracy: 0.8259 - val_output_accuracy: 0.7755\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4053 - logit_loss: 0.4053 - layer_1_accuracy: 0.0088 - layer_2_accuracy: 0.1789 - layer_3_accuracy: 0.0379 - logit_accuracy: 0.8828 - output_accuracy: 0.7817 - val_loss: 0.4484 - val_logit_loss: 0.4484 - val_layer_1_accuracy: 0.0087 - val_layer_2_accuracy: 0.2057 - val_layer_3_accuracy: 0.0183 - val_logit_accuracy: 0.8566 - val_output_accuracy: 0.7810\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2714 - logit_loss: 0.2714 - layer_1_accuracy: 0.0082 - layer_2_accuracy: 0.2030 - layer_3_accuracy: 0.0298 - logit_accuracy: 0.9185 - output_accuracy: 0.8215 - val_loss: 0.4490 - val_logit_loss: 0.4490 - val_layer_1_accuracy: 0.0087 - val_layer_2_accuracy: 0.2162 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.8818 - val_output_accuracy: 0.8026\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2723 - logit_loss: 0.2723 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.2209 - layer_3_accuracy: 0.0324 - logit_accuracy: 0.9246 - output_accuracy: 0.8561 - val_loss: 0.5029 - val_logit_loss: 0.5029 - val_layer_1_accuracy: 0.0087 - val_layer_2_accuracy: 0.2382 - val_layer_3_accuracy: 0.0183 - val_logit_accuracy: 0.8727 - val_output_accuracy: 0.8058\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2229 - logit_loss: 0.2229 - layer_1_accuracy: 0.0067 - layer_2_accuracy: 0.2289 - layer_3_accuracy: 0.0298 - logit_accuracy: 0.9336 - output_accuracy: 0.8565 - val_loss: 0.4761 - val_logit_loss: 0.4761 - val_layer_1_accuracy: 0.0087 - val_layer_2_accuracy: 0.2304 - val_layer_3_accuracy: 0.0257 - val_logit_accuracy: 0.8896 - val_output_accuracy: 0.8287\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1955 - logit_loss: 0.1955 - layer_1_accuracy: 0.0077 - layer_2_accuracy: 0.2287 - layer_3_accuracy: 0.0346 - logit_accuracy: 0.9438 - output_accuracy: 0.8737 - val_loss: 0.4678 - val_logit_loss: 0.4678 - val_layer_1_accuracy: 0.0092 - val_layer_2_accuracy: 0.2313 - val_layer_3_accuracy: 0.0270 - val_logit_accuracy: 0.8997 - val_output_accuracy: 0.8388\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1837 - logit_loss: 0.1837 - layer_1_accuracy: 0.0077 - layer_2_accuracy: 0.2282 - layer_3_accuracy: 0.0365 - logit_accuracy: 0.9493 - output_accuracy: 0.8838 - val_loss: 0.4971 - val_logit_loss: 0.4971 - val_layer_1_accuracy: 0.0082 - val_layer_2_accuracy: 0.2304 - val_layer_3_accuracy: 0.0302 - val_logit_accuracy: 0.9001 - val_output_accuracy: 0.8355\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1728 - logit_loss: 0.1728 - layer_1_accuracy: 0.0069 - layer_2_accuracy: 0.2223 - layer_3_accuracy: 0.0403 - logit_accuracy: 0.9521 - output_accuracy: 0.8845 - val_loss: 0.4452 - val_logit_loss: 0.4452 - val_layer_1_accuracy: 0.0082 - val_layer_2_accuracy: 0.2231 - val_layer_3_accuracy: 0.0298 - val_logit_accuracy: 0.9066 - val_output_accuracy: 0.8443\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1594 - logit_loss: 0.1594 - layer_1_accuracy: 0.0069 - layer_2_accuracy: 0.2174 - layer_3_accuracy: 0.0391 - logit_accuracy: 0.9533 - output_accuracy: 0.8936 - val_loss: 0.4397 - val_logit_loss: 0.4397 - val_layer_1_accuracy: 0.0082 - val_layer_2_accuracy: 0.2199 - val_layer_3_accuracy: 0.0284 - val_logit_accuracy: 0.9084 - val_output_accuracy: 0.8552\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1531 - logit_loss: 0.1531 - layer_1_accuracy: 0.0069 - layer_2_accuracy: 0.2168 - layer_3_accuracy: 0.0353 - logit_accuracy: 0.9601 - output_accuracy: 0.9028 - val_loss: 0.4460 - val_logit_loss: 0.4460 - val_layer_1_accuracy: 0.0082 - val_layer_2_accuracy: 0.2158 - val_layer_3_accuracy: 0.0289 - val_logit_accuracy: 0.9189 - val_output_accuracy: 0.8557\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1477 - logit_loss: 0.1477 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.2136 - layer_3_accuracy: 0.0373 - logit_accuracy: 0.9617 - output_accuracy: 0.9097 - val_loss: 0.4430 - val_logit_loss: 0.4430 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.2103 - val_layer_3_accuracy: 0.0302 - val_logit_accuracy: 0.9240 - val_output_accuracy: 0.8626\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1886 - logit_loss: 0.1886 - layer_1_accuracy: 0.0082 - layer_2_accuracy: 0.2119 - layer_3_accuracy: 0.0373 - logit_accuracy: 0.9550 - output_accuracy: 0.9130 - val_loss: 0.5244 - val_logit_loss: 0.5244 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.2080 - val_layer_3_accuracy: 0.0321 - val_logit_accuracy: 0.9098 - val_output_accuracy: 0.8836\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2129 - logit_loss: 0.2129 - layer_1_accuracy: 0.0077 - layer_2_accuracy: 0.2044 - layer_3_accuracy: 0.0406 - logit_accuracy: 0.9586 - output_accuracy: 0.9038 - val_loss: 0.5393 - val_logit_loss: 0.5393 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.2002 - val_layer_3_accuracy: 0.0403 - val_logit_accuracy: 0.9180 - val_output_accuracy: 0.8598\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1822 - logit_loss: 0.1822 - layer_1_accuracy: 0.0077 - layer_2_accuracy: 0.1962 - layer_3_accuracy: 0.0444 - logit_accuracy: 0.9654 - output_accuracy: 0.9081 - val_loss: 0.5100 - val_logit_loss: 0.5100 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1942 - val_layer_3_accuracy: 0.0449 - val_logit_accuracy: 0.9221 - val_output_accuracy: 0.8681\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1762 - logit_loss: 0.1762 - layer_1_accuracy: 0.0077 - layer_2_accuracy: 0.1922 - layer_3_accuracy: 0.0487 - logit_accuracy: 0.9649 - output_accuracy: 0.9187 - val_loss: 0.5185 - val_logit_loss: 0.5185 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1910 - val_layer_3_accuracy: 0.0444 - val_logit_accuracy: 0.9244 - val_output_accuracy: 0.8713\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1725 - logit_loss: 0.1725 - layer_1_accuracy: 0.0077 - layer_2_accuracy: 0.1885 - layer_3_accuracy: 0.0522 - logit_accuracy: 0.9668 - output_accuracy: 0.9207 - val_loss: 0.5019 - val_logit_loss: 0.5019 - val_layer_1_accuracy: 0.0115 - val_layer_2_accuracy: 0.1874 - val_layer_3_accuracy: 0.0486 - val_logit_accuracy: 0.9262 - val_output_accuracy: 0.8736\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1705 - logit_loss: 0.1705 - layer_1_accuracy: 0.0088 - layer_2_accuracy: 0.1846 - layer_3_accuracy: 0.0538 - logit_accuracy: 0.9678 - output_accuracy: 0.9232 - val_loss: 0.5150 - val_logit_loss: 0.5150 - val_layer_1_accuracy: 0.0115 - val_layer_2_accuracy: 0.1887 - val_layer_3_accuracy: 0.0467 - val_logit_accuracy: 0.9267 - val_output_accuracy: 0.8781\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1693 - logit_loss: 0.1693 - layer_1_accuracy: 0.0088 - layer_2_accuracy: 0.1804 - layer_3_accuracy: 0.0534 - logit_accuracy: 0.9694 - output_accuracy: 0.9274 - val_loss: 0.5261 - val_logit_loss: 0.5261 - val_layer_1_accuracy: 0.0115 - val_layer_2_accuracy: 0.1800 - val_layer_3_accuracy: 0.0472 - val_logit_accuracy: 0.9253 - val_output_accuracy: 0.8740\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1672 - logit_loss: 0.1672 - layer_1_accuracy: 0.0077 - layer_2_accuracy: 0.1763 - layer_3_accuracy: 0.0558 - logit_accuracy: 0.9690 - output_accuracy: 0.9279 - val_loss: 0.5256 - val_logit_loss: 0.5256 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.1800 - val_layer_3_accuracy: 0.0513 - val_logit_accuracy: 0.9272 - val_output_accuracy: 0.8786\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1649 - logit_loss: 0.1649 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.1769 - layer_3_accuracy: 0.0534 - logit_accuracy: 0.9705 - output_accuracy: 0.9313 - val_loss: 0.5452 - val_logit_loss: 0.5452 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.1768 - val_layer_3_accuracy: 0.0481 - val_logit_accuracy: 0.9253 - val_output_accuracy: 0.8800\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1635 - logit_loss: 0.1635 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.1706 - layer_3_accuracy: 0.0565 - logit_accuracy: 0.9711 - output_accuracy: 0.9309 - val_loss: 0.5351 - val_logit_loss: 0.5351 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.1754 - val_layer_3_accuracy: 0.0518 - val_logit_accuracy: 0.9262 - val_output_accuracy: 0.8809\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1618 - logit_loss: 0.1618 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.1700 - layer_3_accuracy: 0.0550 - logit_accuracy: 0.9709 - output_accuracy: 0.9350 - val_loss: 0.5564 - val_logit_loss: 0.5564 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.1699 - val_layer_3_accuracy: 0.0495 - val_logit_accuracy: 0.9244 - val_output_accuracy: 0.8763\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1607 - logit_loss: 0.1607 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.1665 - layer_3_accuracy: 0.0556 - logit_accuracy: 0.9715 - output_accuracy: 0.9334 - val_loss: 0.5429 - val_logit_loss: 0.5429 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.1681 - val_layer_3_accuracy: 0.0541 - val_logit_accuracy: 0.9290 - val_output_accuracy: 0.8809\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1593 - logit_loss: 0.1593 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.1638 - layer_3_accuracy: 0.0579 - logit_accuracy: 0.9721 - output_accuracy: 0.9389 - val_loss: 0.5353 - val_logit_loss: 0.5353 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.1686 - val_layer_3_accuracy: 0.0518 - val_logit_accuracy: 0.9295 - val_output_accuracy: 0.8850\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1590 - logit_loss: 0.1590 - layer_1_accuracy: 0.0069 - layer_2_accuracy: 0.1610 - layer_3_accuracy: 0.0546 - logit_accuracy: 0.9721 - output_accuracy: 0.9374 - val_loss: 0.5551 - val_logit_loss: 0.5551 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.1635 - val_layer_3_accuracy: 0.0504 - val_logit_accuracy: 0.9262 - val_output_accuracy: 0.8841\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1569 - logit_loss: 0.1569 - layer_1_accuracy: 0.0069 - layer_2_accuracy: 0.1577 - layer_3_accuracy: 0.0567 - logit_accuracy: 0.9735 - output_accuracy: 0.9395 - val_loss: 0.5657 - val_logit_loss: 0.5657 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1617 - val_layer_3_accuracy: 0.0508 - val_logit_accuracy: 0.9281 - val_output_accuracy: 0.8814\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1579 - logit_loss: 0.1579 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1581 - layer_3_accuracy: 0.0569 - logit_accuracy: 0.9735 - output_accuracy: 0.9389 - val_loss: 0.5634 - val_logit_loss: 0.5634 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1626 - val_layer_3_accuracy: 0.0513 - val_logit_accuracy: 0.9295 - val_output_accuracy: 0.8864\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1551 - logit_loss: 0.1551 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1579 - layer_3_accuracy: 0.0581 - logit_accuracy: 0.9739 - output_accuracy: 0.9413 - val_loss: 0.5696 - val_logit_loss: 0.5696 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1626 - val_layer_3_accuracy: 0.0527 - val_logit_accuracy: 0.9308 - val_output_accuracy: 0.8836\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1543 - logit_loss: 0.1543 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1579 - layer_3_accuracy: 0.0595 - logit_accuracy: 0.9727 - output_accuracy: 0.9429 - val_loss: 0.5449 - val_logit_loss: 0.5449 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1603 - val_layer_3_accuracy: 0.0527 - val_logit_accuracy: 0.9304 - val_output_accuracy: 0.8878\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1527 - logit_loss: 0.1527 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1586 - layer_3_accuracy: 0.0597 - logit_accuracy: 0.9735 - output_accuracy: 0.9452 - val_loss: 0.5547 - val_logit_loss: 0.5547 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1603 - val_layer_3_accuracy: 0.0527 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8855\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1527 - logit_loss: 0.1527 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1569 - layer_3_accuracy: 0.0595 - logit_accuracy: 0.9749 - output_accuracy: 0.9464 - val_loss: 0.5487 - val_logit_loss: 0.5487 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1594 - val_layer_3_accuracy: 0.0554 - val_logit_accuracy: 0.9308 - val_output_accuracy: 0.8878\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1519 - logit_loss: 0.1519 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1559 - layer_3_accuracy: 0.0603 - logit_accuracy: 0.9751 - output_accuracy: 0.9446 - val_loss: 0.5503 - val_logit_loss: 0.5503 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1590 - val_layer_3_accuracy: 0.0536 - val_logit_accuracy: 0.9336 - val_output_accuracy: 0.8873\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1522 - logit_loss: 0.1522 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1583 - layer_3_accuracy: 0.0622 - logit_accuracy: 0.9739 - output_accuracy: 0.9456 - val_loss: 0.5512 - val_logit_loss: 0.5512 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1590 - val_layer_3_accuracy: 0.0641 - val_logit_accuracy: 0.9340 - val_output_accuracy: 0.8901\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1510 - logit_loss: 0.1510 - layer_1_accuracy: 0.0063 - layer_2_accuracy: 0.1579 - layer_3_accuracy: 0.0634 - logit_accuracy: 0.9741 - output_accuracy: 0.9470 - val_loss: 0.5740 - val_logit_loss: 0.5740 - val_layer_1_accuracy: 0.0101 - val_layer_2_accuracy: 0.1585 - val_layer_3_accuracy: 0.0550 - val_logit_accuracy: 0.9350 - val_output_accuracy: 0.8896\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1511 - logit_loss: 0.1511 - layer_1_accuracy: 0.0061 - layer_2_accuracy: 0.1565 - layer_3_accuracy: 0.0613 - logit_accuracy: 0.9747 - output_accuracy: 0.9480 - val_loss: 0.5239 - val_logit_loss: 0.5239 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1626 - val_layer_3_accuracy: 0.0600 - val_logit_accuracy: 0.9359 - val_output_accuracy: 0.8937\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1506 - logit_loss: 0.1506 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1551 - layer_3_accuracy: 0.0622 - logit_accuracy: 0.9755 - output_accuracy: 0.9491 - val_loss: 0.5467 - val_logit_loss: 0.5467 - val_layer_1_accuracy: 0.0082 - val_layer_2_accuracy: 0.1580 - val_layer_3_accuracy: 0.0628 - val_logit_accuracy: 0.9350 - val_output_accuracy: 0.8928\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1492 - logit_loss: 0.1492 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1559 - layer_3_accuracy: 0.0654 - logit_accuracy: 0.9760 - output_accuracy: 0.9488 - val_loss: 0.5503 - val_logit_loss: 0.5503 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1612 - val_layer_3_accuracy: 0.0632 - val_logit_accuracy: 0.9359 - val_output_accuracy: 0.8905\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1494 - logit_loss: 0.1494 - layer_1_accuracy: 0.0053 - layer_2_accuracy: 0.1555 - layer_3_accuracy: 0.0630 - logit_accuracy: 0.9762 - output_accuracy: 0.9535 - val_loss: 0.5353 - val_logit_loss: 0.5353 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1599 - val_layer_3_accuracy: 0.0609 - val_logit_accuracy: 0.9359 - val_output_accuracy: 0.8946\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1490 - logit_loss: 0.1490 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1577 - layer_3_accuracy: 0.0656 - logit_accuracy: 0.9757 - output_accuracy: 0.9513 - val_loss: 0.5454 - val_logit_loss: 0.5454 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1585 - val_layer_3_accuracy: 0.0554 - val_logit_accuracy: 0.9359 - val_output_accuracy: 0.8983\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1482 - logit_loss: 0.1482 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1537 - layer_3_accuracy: 0.0609 - logit_accuracy: 0.9758 - output_accuracy: 0.9501 - val_loss: 0.5543 - val_logit_loss: 0.5543 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1585 - val_layer_3_accuracy: 0.0586 - val_logit_accuracy: 0.9331 - val_output_accuracy: 0.8919\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1474 - logit_loss: 0.1474 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1516 - layer_3_accuracy: 0.0632 - logit_accuracy: 0.9774 - output_accuracy: 0.9546 - val_loss: 0.5452 - val_logit_loss: 0.5452 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1562 - val_layer_3_accuracy: 0.0618 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.8960\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1487 - logit_loss: 0.1487 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1522 - layer_3_accuracy: 0.0656 - logit_accuracy: 0.9751 - output_accuracy: 0.9488 - val_loss: 0.5697 - val_logit_loss: 0.5697 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1562 - val_layer_3_accuracy: 0.0554 - val_logit_accuracy: 0.9340 - val_output_accuracy: 0.8933\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1471 - logit_loss: 0.1471 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1532 - layer_3_accuracy: 0.0640 - logit_accuracy: 0.9762 - output_accuracy: 0.9576 - val_loss: 0.5842 - val_logit_loss: 0.5842 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1576 - val_layer_3_accuracy: 0.0618 - val_logit_accuracy: 0.9322 - val_output_accuracy: 0.8887\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1478 - logit_loss: 0.1478 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1533 - layer_3_accuracy: 0.0656 - logit_accuracy: 0.9762 - output_accuracy: 0.9548 - val_loss: 0.5703 - val_logit_loss: 0.5703 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1576 - val_layer_3_accuracy: 0.0641 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8887\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1473 - logit_loss: 0.1473 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1524 - layer_3_accuracy: 0.0693 - logit_accuracy: 0.9760 - output_accuracy: 0.9546 - val_loss: 0.6247 - val_logit_loss: 0.6247 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1516 - val_layer_3_accuracy: 0.0591 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8841\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1499 - logit_loss: 0.1499 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1508 - layer_3_accuracy: 0.0640 - logit_accuracy: 0.9758 - output_accuracy: 0.9539 - val_loss: 0.5656 - val_logit_loss: 0.5656 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1548 - val_layer_3_accuracy: 0.0637 - val_logit_accuracy: 0.9359 - val_output_accuracy: 0.8942\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1472 - logit_loss: 0.1472 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.1520 - layer_3_accuracy: 0.0677 - logit_accuracy: 0.9758 - output_accuracy: 0.9525 - val_loss: 0.5730 - val_logit_loss: 0.5730 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1590 - val_layer_3_accuracy: 0.0637 - val_logit_accuracy: 0.9354 - val_output_accuracy: 0.8988\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1446 - logit_loss: 0.1446 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1530 - layer_3_accuracy: 0.0662 - logit_accuracy: 0.9774 - output_accuracy: 0.9596 - val_loss: 0.5971 - val_logit_loss: 0.5971 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1548 - val_layer_3_accuracy: 0.0600 - val_logit_accuracy: 0.9340 - val_output_accuracy: 0.8933\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1452 - logit_loss: 0.1452 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1512 - layer_3_accuracy: 0.0638 - logit_accuracy: 0.9774 - output_accuracy: 0.9582 - val_loss: 0.5762 - val_logit_loss: 0.5762 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1544 - val_layer_3_accuracy: 0.0609 - val_logit_accuracy: 0.9331 - val_output_accuracy: 0.9001\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1453 - logit_loss: 0.1453 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1524 - layer_3_accuracy: 0.0618 - logit_accuracy: 0.9770 - output_accuracy: 0.9603 - val_loss: 0.5703 - val_logit_loss: 0.5703 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1530 - val_layer_3_accuracy: 0.0596 - val_logit_accuracy: 0.9372 - val_output_accuracy: 0.9001\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1487 - logit_loss: 0.1487 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1510 - layer_3_accuracy: 0.0618 - logit_accuracy: 0.9762 - output_accuracy: 0.9586 - val_loss: 0.6383 - val_logit_loss: 0.6383 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1516 - val_layer_3_accuracy: 0.0563 - val_logit_accuracy: 0.9285 - val_output_accuracy: 0.8869\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1447 - logit_loss: 0.1447 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1533 - layer_3_accuracy: 0.0638 - logit_accuracy: 0.9768 - output_accuracy: 0.9613 - val_loss: 0.6227 - val_logit_loss: 0.6227 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1539 - val_layer_3_accuracy: 0.0563 - val_logit_accuracy: 0.9304 - val_output_accuracy: 0.8937\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1456 - logit_loss: 0.1456 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1514 - layer_3_accuracy: 0.0634 - logit_accuracy: 0.9762 - output_accuracy: 0.9582 - val_loss: 0.5878 - val_logit_loss: 0.5878 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.1544 - val_layer_3_accuracy: 0.0641 - val_logit_accuracy: 0.9368 - val_output_accuracy: 0.9011\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1683 - logit_loss: 0.1683 - layer_1_accuracy: 0.0047 - layer_2_accuracy: 0.1484 - layer_3_accuracy: 0.0587 - logit_accuracy: 0.9755 - output_accuracy: 0.9529 - val_loss: 0.5606 - val_logit_loss: 0.5606 - val_layer_1_accuracy: 0.0078 - val_layer_2_accuracy: 0.1562 - val_layer_3_accuracy: 0.0623 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.9029\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1756 - logit_loss: 0.1756 - layer_1_accuracy: 0.0071 - layer_2_accuracy: 0.1516 - layer_3_accuracy: 0.0548 - logit_accuracy: 0.9749 - output_accuracy: 0.9560 - val_loss: 0.5921 - val_logit_loss: 0.5921 - val_layer_1_accuracy: 0.0078 - val_layer_2_accuracy: 0.1525 - val_layer_3_accuracy: 0.0536 - val_logit_accuracy: 0.9350 - val_output_accuracy: 0.9020\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2036 - logit_loss: 0.2036 - layer_1_accuracy: 0.0059 - layer_2_accuracy: 0.1473 - layer_3_accuracy: 0.0646 - logit_accuracy: 0.9707 - output_accuracy: 0.9523 - val_loss: 0.7096 - val_logit_loss: 0.7096 - val_layer_1_accuracy: 0.0073 - val_layer_2_accuracy: 0.1415 - val_layer_3_accuracy: 0.0490 - val_logit_accuracy: 0.9084 - val_output_accuracy: 0.8520\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2515 - logit_loss: 0.2515 - layer_1_accuracy: 0.0065 - layer_2_accuracy: 0.1494 - layer_3_accuracy: 0.0481 - logit_accuracy: 0.9619 - output_accuracy: 0.9252 - val_loss: 1.7608 - val_logit_loss: 1.7608 - val_layer_1_accuracy: 0.0179 - val_layer_2_accuracy: 0.0898 - val_layer_3_accuracy: 0.0050 - val_logit_accuracy: 0.8232 - val_output_accuracy: 0.7650\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8489 - logit_loss: 1.8489 - layer_1_accuracy: 0.0228 - layer_2_accuracy: 0.0432 - layer_3_accuracy: 0.0026 - logit_accuracy: 0.8188 - output_accuracy: 0.7915 - val_loss: 2.5933 - val_logit_loss: 2.5933 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0330 - val_layer_3_accuracy: 0.0014 - val_logit_accuracy: 0.7847 - val_output_accuracy: 0.7641\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.6075 - logit_loss: 2.6075 - layer_1_accuracy: 0.0092 - layer_2_accuracy: 0.0340 - layer_3_accuracy: 0.0047 - logit_accuracy: 0.7911 - output_accuracy: 0.7891 - val_loss: 3.3583 - val_logit_loss: 3.3583 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0380 - val_layer_3_accuracy: 0.0151 - val_logit_accuracy: 0.7462 - val_output_accuracy: 0.7609\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.5372 - logit_loss: 2.5372 - layer_1_accuracy: 0.0069 - layer_2_accuracy: 0.0243 - layer_3_accuracy: 0.0230 - logit_accuracy: 0.7956 - output_accuracy: 0.7917 - val_loss: 2.6989 - val_logit_loss: 2.6989 - val_layer_1_accuracy: 0.0078 - val_layer_2_accuracy: 0.0069 - val_layer_3_accuracy: 0.0165 - val_logit_accuracy: 0.7778 - val_output_accuracy: 0.7503\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1111 - logit_loss: 2.1111 - layer_1_accuracy: 0.0075 - layer_2_accuracy: 0.0096 - layer_3_accuracy: 0.0173 - logit_accuracy: 0.8107 - output_accuracy: 0.7987 - val_loss: 2.3035 - val_logit_loss: 2.3035 - val_layer_1_accuracy: 0.0078 - val_layer_2_accuracy: 0.0101 - val_layer_3_accuracy: 0.0124 - val_logit_accuracy: 0.8090 - val_output_accuracy: 0.8076\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.9794 - logit_loss: 2.9794 - layer_1_accuracy: 0.0061 - layer_2_accuracy: 0.0043 - layer_3_accuracy: 0.0147 - logit_accuracy: 0.7575 - output_accuracy: 0.7300 - val_loss: 4.5172 - val_logit_loss: 4.5172 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0018 - val_layer_3_accuracy: 0.0174 - val_logit_accuracy: 0.6505 - val_output_accuracy: 0.6358\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.0057 - logit_loss: 4.0057 - layer_1_accuracy: 0.0059 - layer_2_accuracy: 0.0018 - layer_3_accuracy: 0.0312 - logit_accuracy: 0.6959 - output_accuracy: 0.6856 - val_loss: 3.8627 - val_logit_loss: 3.8627 - val_layer_1_accuracy: 0.0060 - val_layer_2_accuracy: 0.0023 - val_layer_3_accuracy: 0.0444 - val_logit_accuracy: 0.7055 - val_output_accuracy: 0.6986\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6190 - logit_loss: 3.6190 - layer_1_accuracy: 0.0051 - layer_2_accuracy: 0.0016 - layer_3_accuracy: 0.0369 - logit_accuracy: 0.7239 - output_accuracy: 0.7153 - val_loss: 3.5217 - val_logit_loss: 3.5217 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0023 - val_layer_3_accuracy: 0.0357 - val_logit_accuracy: 0.7297 - val_output_accuracy: 0.7233\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3348 - logit_loss: 3.3348 - layer_1_accuracy: 0.0067 - layer_2_accuracy: 0.0043 - layer_3_accuracy: 0.0122 - logit_accuracy: 0.7400 - output_accuracy: 0.7294 - val_loss: 3.2109 - val_logit_loss: 3.2109 - val_layer_1_accuracy: 0.0064 - val_layer_2_accuracy: 0.0064 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.7435 - val_output_accuracy: 0.7412\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.8535 - logit_loss: 2.8535 - layer_1_accuracy: 0.0053 - layer_2_accuracy: 0.0055 - layer_3_accuracy: 0.0026 - logit_accuracy: 0.7626 - output_accuracy: 0.7677 - val_loss: 2.9749 - val_logit_loss: 2.9749 - val_layer_1_accuracy: 0.0060 - val_layer_2_accuracy: 0.0069 - val_layer_3_accuracy: 0.0014 - val_logit_accuracy: 0.7508 - val_output_accuracy: 0.7650\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.7592 - logit_loss: 2.7592 - layer_1_accuracy: 0.0049 - layer_2_accuracy: 0.0071 - layer_3_accuracy: 0.0020 - logit_accuracy: 0.7656 - output_accuracy: 0.7530 - val_loss: 3.1962 - val_logit_loss: 3.1962 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0151 - val_layer_3_accuracy: 0.0032 - val_logit_accuracy: 0.7251 - val_output_accuracy: 0.6867\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.0978 - logit_loss: 2.0978 - layer_1_accuracy: 0.0035 - layer_2_accuracy: 0.0120 - layer_3_accuracy: 0.0024 - logit_accuracy: 0.7787 - output_accuracy: 0.7444 - val_loss: 1.9611 - val_logit_loss: 1.9611 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0160 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.7801 - val_output_accuracy: 0.7554\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3598 - logit_loss: 1.3598 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0120 - layer_3_accuracy: 0.0016 - logit_accuracy: 0.8243 - output_accuracy: 0.7862 - val_loss: 1.4635 - val_logit_loss: 1.4635 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8007 - val_output_accuracy: 0.7481\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0423 - logit_loss: 1.0423 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0118 - layer_3_accuracy: 0.0016 - logit_accuracy: 0.8329 - output_accuracy: 0.7646 - val_loss: 1.1438 - val_logit_loss: 1.1438 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0188 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.8122 - val_output_accuracy: 0.7801\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7567 - logit_loss: 0.7567 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0122 - layer_3_accuracy: 9.8174e-04 - logit_accuracy: 0.8482 - output_accuracy: 0.7913 - val_loss: 0.9489 - val_logit_loss: 0.9489 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.8131 - val_output_accuracy: 0.7412\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6484 - logit_loss: 0.6484 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0122 - layer_3_accuracy: 5.8904e-04 - logit_accuracy: 0.8590 - output_accuracy: 0.7797 - val_loss: 0.9075 - val_logit_loss: 0.9075 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0179 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.8108 - val_output_accuracy: 0.7508\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6193 - logit_loss: 0.6193 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0143 - layer_3_accuracy: 3.9270e-04 - logit_accuracy: 0.8683 - output_accuracy: 0.7860 - val_loss: 0.9042 - val_logit_loss: 0.9042 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0183 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8158 - val_output_accuracy: 0.7623\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5930 - logit_loss: 0.5930 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0149 - layer_3_accuracy: 5.8904e-04 - logit_accuracy: 0.8773 - output_accuracy: 0.7991 - val_loss: 0.8971 - val_logit_loss: 0.8971 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0179 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8360 - val_output_accuracy: 0.7723\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5822 - logit_loss: 0.5822 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0151 - layer_3_accuracy: 3.9270e-04 - logit_accuracy: 0.8883 - output_accuracy: 0.8044 - val_loss: 0.9081 - val_logit_loss: 0.9081 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0188 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8424 - val_output_accuracy: 0.7723\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5730 - logit_loss: 0.5730 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0151 - layer_3_accuracy: 5.8904e-04 - logit_accuracy: 0.8936 - output_accuracy: 0.8150 - val_loss: 0.9135 - val_logit_loss: 0.9135 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0192 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8475 - val_output_accuracy: 0.7678\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5654 - logit_loss: 0.5654 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0151 - layer_3_accuracy: 7.8539e-04 - logit_accuracy: 0.8993 - output_accuracy: 0.8162 - val_loss: 0.9062 - val_logit_loss: 0.9062 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8488 - val_output_accuracy: 0.7728\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5478 - logit_loss: 0.5478 - layer_1_accuracy: 0.0039 - layer_2_accuracy: 0.0161 - layer_3_accuracy: 5.8904e-04 - logit_accuracy: 0.9001 - output_accuracy: 0.8227 - val_loss: 0.9412 - val_logit_loss: 0.9412 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8502 - val_output_accuracy: 0.7696\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5117 - logit_loss: 0.5117 - layer_1_accuracy: 0.0049 - layer_2_accuracy: 0.0155 - layer_3_accuracy: 5.8904e-04 - logit_accuracy: 0.9016 - output_accuracy: 0.8243 - val_loss: 0.8920 - val_logit_loss: 0.8920 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8571 - val_output_accuracy: 0.7842\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4972 - logit_loss: 0.4972 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0134 - layer_3_accuracy: 5.8904e-04 - logit_accuracy: 0.9040 - output_accuracy: 0.8355 - val_loss: 0.8855 - val_logit_loss: 0.8855 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8621 - val_output_accuracy: 0.7824\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4826 - logit_loss: 0.4826 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0135 - layer_3_accuracy: 9.8174e-04 - logit_accuracy: 0.9116 - output_accuracy: 0.8368 - val_loss: 0.8612 - val_logit_loss: 0.8612 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0188 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8612 - val_output_accuracy: 0.7939\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4735 - logit_loss: 0.4735 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0135 - layer_3_accuracy: 0.0014 - logit_accuracy: 0.9150 - output_accuracy: 0.8390 - val_loss: 0.8633 - val_logit_loss: 0.8633 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0183 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.8681 - val_output_accuracy: 0.7948\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4669 - logit_loss: 0.4669 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0139 - layer_3_accuracy: 0.0016 - logit_accuracy: 0.9205 - output_accuracy: 0.8427 - val_loss: 0.8556 - val_logit_loss: 0.8556 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0183 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8713 - val_output_accuracy: 0.8003\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4619 - logit_loss: 0.4619 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0145 - layer_3_accuracy: 0.0018 - logit_accuracy: 0.9222 - output_accuracy: 0.8484 - val_loss: 0.8632 - val_logit_loss: 0.8632 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8727 - val_output_accuracy: 0.7998\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4571 - logit_loss: 0.4571 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0147 - layer_3_accuracy: 0.0020 - logit_accuracy: 0.9258 - output_accuracy: 0.8520 - val_loss: 0.8348 - val_logit_loss: 0.8348 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0014 - val_logit_accuracy: 0.8777 - val_output_accuracy: 0.8062\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4528 - logit_loss: 0.4528 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0149 - layer_3_accuracy: 0.0020 - logit_accuracy: 0.9274 - output_accuracy: 0.8586 - val_loss: 0.8446 - val_logit_loss: 0.8446 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0211 - val_layer_3_accuracy: 0.0018 - val_logit_accuracy: 0.8795 - val_output_accuracy: 0.8071\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4489 - logit_loss: 0.4489 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0149 - layer_3_accuracy: 0.0022 - logit_accuracy: 0.9275 - output_accuracy: 0.8618 - val_loss: 0.8360 - val_logit_loss: 0.8360 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0215 - val_layer_3_accuracy: 0.0018 - val_logit_accuracy: 0.8791 - val_output_accuracy: 0.8071\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4454 - logit_loss: 0.4454 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0151 - layer_3_accuracy: 0.0024 - logit_accuracy: 0.9287 - output_accuracy: 0.8637 - val_loss: 0.8378 - val_logit_loss: 0.8378 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0220 - val_layer_3_accuracy: 0.0018 - val_logit_accuracy: 0.8814 - val_output_accuracy: 0.8104\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4421 - logit_loss: 0.4421 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0151 - layer_3_accuracy: 0.0027 - logit_accuracy: 0.9303 - output_accuracy: 0.8679 - val_loss: 0.8356 - val_logit_loss: 0.8356 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 0.0023 - val_logit_accuracy: 0.8800 - val_output_accuracy: 0.8131\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4369 - logit_loss: 0.4369 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0155 - layer_3_accuracy: 0.0027 - logit_accuracy: 0.9332 - output_accuracy: 0.8698 - val_loss: 0.8248 - val_logit_loss: 0.8248 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 0.0023 - val_logit_accuracy: 0.8846 - val_output_accuracy: 0.8163\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4357 - logit_loss: 0.4357 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0161 - layer_3_accuracy: 0.0031 - logit_accuracy: 0.9295 - output_accuracy: 0.8794 - val_loss: 0.7609 - val_logit_loss: 0.7609 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0220 - val_layer_3_accuracy: 0.0027 - val_logit_accuracy: 0.8713 - val_output_accuracy: 0.8351\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4737 - logit_loss: 0.4737 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0165 - layer_3_accuracy: 0.0029 - logit_accuracy: 0.9232 - output_accuracy: 0.8736 - val_loss: 0.8367 - val_logit_loss: 0.8367 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0023 - val_logit_accuracy: 0.8745 - val_output_accuracy: 0.8149\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4241 - logit_loss: 0.4241 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0179 - layer_3_accuracy: 0.0029 - logit_accuracy: 0.9319 - output_accuracy: 0.8651 - val_loss: 0.8898 - val_logit_loss: 0.8898 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0266 - val_layer_3_accuracy: 0.0023 - val_logit_accuracy: 0.8832 - val_output_accuracy: 0.8094\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3927 - logit_loss: 0.3927 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0192 - layer_3_accuracy: 0.0031 - logit_accuracy: 0.9385 - output_accuracy: 0.8765 - val_loss: 0.8126 - val_logit_loss: 0.8126 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0266 - val_layer_3_accuracy: 0.0037 - val_logit_accuracy: 0.8859 - val_output_accuracy: 0.8218\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3858 - logit_loss: 0.3858 - layer_1_accuracy: 0.0033 - layer_2_accuracy: 0.0183 - layer_3_accuracy: 0.0037 - logit_accuracy: 0.9427 - output_accuracy: 0.8802 - val_loss: 0.7955 - val_logit_loss: 0.7955 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 0.0037 - val_logit_accuracy: 0.8910 - val_output_accuracy: 0.8264\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4792 - logit_loss: 0.4792 - layer_1_accuracy: 0.0027 - layer_2_accuracy: 0.0181 - layer_3_accuracy: 0.0045 - logit_accuracy: 0.9136 - output_accuracy: 0.8920 - val_loss: 1.1235 - val_logit_loss: 1.1235 - val_layer_1_accuracy: 0.0041 - val_layer_2_accuracy: 0.0197 - val_layer_3_accuracy: 0.0032 - val_logit_accuracy: 0.8438 - val_output_accuracy: 0.7925\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5023 - logit_loss: 0.5023 - layer_1_accuracy: 0.0043 - layer_2_accuracy: 0.0183 - layer_3_accuracy: 0.0029 - logit_accuracy: 0.9122 - output_accuracy: 0.8582 - val_loss: 0.8717 - val_logit_loss: 0.8717 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 0.0023 - val_logit_accuracy: 0.8635 - val_output_accuracy: 0.8278\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4164 - logit_loss: 0.4164 - layer_1_accuracy: 0.0043 - layer_2_accuracy: 0.0192 - layer_3_accuracy: 0.0029 - logit_accuracy: 0.9285 - output_accuracy: 0.8765 - val_loss: 0.8343 - val_logit_loss: 0.8343 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0261 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.8891 - val_output_accuracy: 0.8255\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3867 - logit_loss: 0.3867 - layer_1_accuracy: 0.0045 - layer_2_accuracy: 0.0188 - layer_3_accuracy: 0.0041 - logit_accuracy: 0.9438 - output_accuracy: 0.8796 - val_loss: 0.8382 - val_logit_loss: 0.8382 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 0.0050 - val_logit_accuracy: 0.8914 - val_output_accuracy: 0.8255\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3786 - logit_loss: 0.3786 - layer_1_accuracy: 0.0037 - layer_2_accuracy: 0.0188 - layer_3_accuracy: 0.0053 - logit_accuracy: 0.9456 - output_accuracy: 0.8871 - val_loss: 0.8191 - val_logit_loss: 0.8191 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0261 - val_layer_3_accuracy: 0.0055 - val_logit_accuracy: 0.8951 - val_output_accuracy: 0.8291\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3730 - logit_loss: 0.3730 - layer_1_accuracy: 0.0029 - layer_2_accuracy: 0.0190 - layer_3_accuracy: 0.0065 - logit_accuracy: 0.9484 - output_accuracy: 0.8887 - val_loss: 0.8171 - val_logit_loss: 0.8171 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0261 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.8992 - val_output_accuracy: 0.8346\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3688 - logit_loss: 0.3688 - layer_1_accuracy: 0.0029 - layer_2_accuracy: 0.0190 - layer_3_accuracy: 0.0067 - logit_accuracy: 0.9495 - output_accuracy: 0.8942 - val_loss: 0.8205 - val_logit_loss: 0.8205 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.8951 - val_output_accuracy: 0.8319\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3632 - logit_loss: 0.3632 - layer_1_accuracy: 0.0029 - layer_2_accuracy: 0.0190 - layer_3_accuracy: 0.0067 - logit_accuracy: 0.9527 - output_accuracy: 0.8963 - val_loss: 0.7843 - val_logit_loss: 0.7843 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.9020 - val_output_accuracy: 0.8433\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3603 - logit_loss: 0.3603 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0190 - layer_3_accuracy: 0.0069 - logit_accuracy: 0.9525 - output_accuracy: 0.9003 - val_loss: 0.8272 - val_logit_loss: 0.8272 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.8965 - val_output_accuracy: 0.8346\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3575 - logit_loss: 0.3575 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0190 - layer_3_accuracy: 0.0081 - logit_accuracy: 0.9529 - output_accuracy: 0.9034 - val_loss: 0.7990 - val_logit_loss: 0.7990 - val_layer_1_accuracy: 0.0050 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.9006 - val_output_accuracy: 0.8424\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3576 - logit_loss: 0.3576 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0187 - layer_3_accuracy: 0.0079 - logit_accuracy: 0.9523 - output_accuracy: 0.9067 - val_loss: 0.8165 - val_logit_loss: 0.8165 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0229 - val_layer_3_accuracy: 0.0060 - val_logit_accuracy: 0.8928 - val_output_accuracy: 0.8301\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4544 - logit_loss: 0.4544 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0175 - layer_3_accuracy: 0.0059 - logit_accuracy: 0.9281 - output_accuracy: 0.8948 - val_loss: 0.9759 - val_logit_loss: 0.9759 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0215 - val_layer_3_accuracy: 0.0041 - val_logit_accuracy: 0.8800 - val_output_accuracy: 0.8264\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4029 - logit_loss: 0.4029 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0169 - layer_3_accuracy: 0.0043 - logit_accuracy: 0.9338 - output_accuracy: 0.9101 - val_loss: 0.7554 - val_logit_loss: 0.7554 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0215 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.8823 - val_output_accuracy: 0.8699\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4035 - logit_loss: 0.4035 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0161 - layer_3_accuracy: 0.0041 - logit_accuracy: 0.9421 - output_accuracy: 0.9001 - val_loss: 0.8350 - val_logit_loss: 0.8350 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0220 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.9024 - val_output_accuracy: 0.8410\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3796 - logit_loss: 0.3796 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0169 - layer_3_accuracy: 0.0045 - logit_accuracy: 0.9525 - output_accuracy: 0.9085 - val_loss: 0.7945 - val_logit_loss: 0.7945 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0234 - val_layer_3_accuracy: 0.0041 - val_logit_accuracy: 0.8997 - val_output_accuracy: 0.8420\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3726 - logit_loss: 0.3726 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0175 - layer_3_accuracy: 0.0043 - logit_accuracy: 0.9548 - output_accuracy: 0.9122 - val_loss: 0.7547 - val_logit_loss: 0.7547 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 0.0041 - val_logit_accuracy: 0.9001 - val_output_accuracy: 0.8484\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4077 - logit_loss: 0.4077 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0165 - layer_3_accuracy: 0.0051 - logit_accuracy: 0.9327 - output_accuracy: 0.8777 - val_loss: 0.7746 - val_logit_loss: 0.7746 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0275 - val_layer_3_accuracy: 0.0032 - val_logit_accuracy: 0.8919 - val_output_accuracy: 0.8374\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3391 - logit_loss: 0.3391 - layer_1_accuracy: 0.0029 - layer_2_accuracy: 0.0224 - layer_3_accuracy: 0.0041 - logit_accuracy: 0.9460 - output_accuracy: 0.8932 - val_loss: 0.7382 - val_logit_loss: 0.7382 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0293 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.9033 - val_output_accuracy: 0.8433\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3010 - logit_loss: 0.3010 - layer_1_accuracy: 0.0029 - layer_2_accuracy: 0.0212 - layer_3_accuracy: 0.0053 - logit_accuracy: 0.9521 - output_accuracy: 0.9052 - val_loss: 0.6691 - val_logit_loss: 0.6691 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0289 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.9001 - val_output_accuracy: 0.8566\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2771 - logit_loss: 0.2771 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0210 - layer_3_accuracy: 0.0047 - logit_accuracy: 0.9544 - output_accuracy: 0.9067 - val_loss: 0.7361 - val_logit_loss: 0.7361 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0046 - val_logit_accuracy: 0.8997 - val_output_accuracy: 0.8429\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2693 - logit_loss: 0.2693 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0190 - layer_3_accuracy: 0.0055 - logit_accuracy: 0.9574 - output_accuracy: 0.9126 - val_loss: 0.6911 - val_logit_loss: 0.6911 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0238 - val_layer_3_accuracy: 0.0050 - val_logit_accuracy: 0.9043 - val_output_accuracy: 0.8557\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3891 - logit_loss: 0.3891 - layer_1_accuracy: 0.0031 - layer_2_accuracy: 0.0183 - layer_3_accuracy: 0.0075 - logit_accuracy: 0.9415 - output_accuracy: 0.9160 - val_loss: 1.3204 - val_logit_loss: 1.3204 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0220 - val_layer_3_accuracy: 0.0197 - val_logit_accuracy: 0.8108 - val_output_accuracy: 0.8607\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.5433 - logit_loss: 1.5433 - layer_1_accuracy: 0.0035 - layer_2_accuracy: 0.0220 - layer_3_accuracy: 0.0096 - logit_accuracy: 0.8254 - output_accuracy: 0.8227 - val_loss: 1.8891 - val_logit_loss: 1.8891 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0041 - val_logit_accuracy: 0.7962 - val_output_accuracy: 0.7723\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.7801 - logit_loss: 1.7801 - layer_1_accuracy: 0.0041 - layer_2_accuracy: 0.0204 - layer_3_accuracy: 0.0029 - logit_accuracy: 0.8076 - output_accuracy: 0.8203 - val_loss: 1.8498 - val_logit_loss: 1.8498 - val_layer_1_accuracy: 0.0055 - val_layer_2_accuracy: 0.0270 - val_layer_3_accuracy: 0.0032 - val_logit_accuracy: 0.7888 - val_output_accuracy: 0.7517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a04e4c1220>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 55)]              0         \n",
      "                                                                 \n",
      " layer_1 (Dense)             (None, 64)                3584      \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " layer_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " logit (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      " output (Activation)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,857\n",
      "Trainable params: 9,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NN to ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "# convert the model to ONNX format\n",
    "onnx_net = onnxmltools.convert_keras(model)\n",
    "onnxmltools.utils.save_model(onnx_net, \"my_model.onnx\")\n",
    "content = onnx_net.SerializeToString()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def setup(onnx_file: str,):\n",
    "    # Load the ONNX model\n",
    "    ort_sess = ort.InferenceSession(onnx_file)\n",
    "    ortvalue = ort.OrtValue.ortvalue_from_numpy(X_train.astype(np.float32), 'cpu')\n",
    "    layer_output = ort_sess.run(['layer_1','layer_2','layer_3','logit'], {ort_sess.get_inputs()[0].name: ortvalue}) \n",
    "    neigh = []\n",
    "    for i in range(len(layer_output)):\n",
    "        neigh.append(NearestNeighbors().fit(layer_output[i]))\n",
    "    return  ort_sess, neigh\n",
    "\n",
    "ort_sess, neigh = setup('my_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.        , 0.6527649 , 0.        , ..., 0.        , 0.226087  ,\n",
       "         0.        ],\n",
       "        [0.        , 0.44003183, 0.        , ..., 0.20403242, 0.3326547 ,\n",
       "         0.03314645],\n",
       "        [0.8234054 , 0.42975003, 0.28593206, ..., 0.        , 0.5727266 ,\n",
       "         0.4528196 ],\n",
       "        ...,\n",
       "        [0.        , 0.7380428 , 0.        , ..., 0.50017697, 1.052403  ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.81401134,\n",
       "         0.47289377],\n",
       "        [0.        , 0.67658085, 0.        , ..., 0.5704702 , 0.28243923,\n",
       "         0.        ]], dtype=float32),\n",
       " array([[0.93117565, 0.        , 0.        , ..., 0.09432337, 0.61572105,\n",
       "         0.6949224 ],\n",
       "        [0.6982644 , 0.        , 0.10560359, ..., 0.        , 0.6548017 ,\n",
       "         0.9350475 ],\n",
       "        [0.06099963, 0.7337561 , 0.        , ..., 0.        , 0.26466605,\n",
       "         0.9146138 ],\n",
       "        ...,\n",
       "        [0.04251009, 0.        , 0.        , ..., 0.        , 0.52163696,\n",
       "         0.67867094],\n",
       "        [0.41373533, 0.        , 0.        , ..., 0.        , 0.26598042,\n",
       "         0.44329002],\n",
       "        [0.51713496, 0.        , 0.12475994, ..., 0.        , 0.9208949 ,\n",
       "         0.4448846 ]], dtype=float32),\n",
       " array([[0.        , 0.        , 0.3091035 , ..., 0.        , 0.        ,\n",
       "         0.3132608 ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.15894262,\n",
       "         0.9494298 ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.05709288,\n",
       "         1.4017395 ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.00747471,\n",
       "         0.30461833],\n",
       "        [0.        , 0.        , 0.        , ..., 0.4728918 , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.96878046, ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32),\n",
       " array([[1.5365746 ],\n",
       "        [3.7383258 ],\n",
       "        [4.677475  ],\n",
       "        ...,\n",
       "        [6.1427584 ],\n",
       "        [0.37591314],\n",
       "        [3.5490339 ]], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confidences(x, ort_sess, layer_out, y_train):\n",
    "    ortvalue = ort.OrtValue.ortvalue_from_numpy(x.astype(np.float32), 'cpu')\n",
    "    layer_output = ort_sess.run(['layer_1','layer_2','layer_3','logit'], {ort_sess.get_inputs()[0].name: ortvalue}) \n",
    "    for i in range(len(x)):\n",
    "        layer_predict = []\n",
    "        for j in range(len(layer_output)):\n",
    "            layer_predict.append(neigh[j].kneighbors(layer_output[j][i].reshape(1, -1), 1, return_distance=False))\n",
    "    return layer_predict\n",
    "\n",
    "confidences(X_test, ort_sess, layer_out, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a46493ef273555f0fac6598162cd73ee5d8ec19f64a4bbbda3cc3aa05bc0ca3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
