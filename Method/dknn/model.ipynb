{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>...</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171429</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414286</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.389322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  default  housing  loan  campaign  pdays  previous  poutcome  \\\n",
       "0  0.171429        1       -1     1  0.029412    1.0       0.0         0   \n",
       "1  0.300000        1        1     1  0.088235    1.0       0.0         0   \n",
       "2  0.100000        1       -1     1  0.000000    1.0       0.0         0   \n",
       "3  0.285714        1        0     0  0.058824    1.0       0.0         0   \n",
       "4  0.414286        1       -1     1  0.000000    1.0       0.0         0   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  ...  month_mar  month_may  month_nov  \\\n",
       "0      0.333333        0.269680  ...          0          1          0   \n",
       "1      0.937500        0.698753  ...          0          1          0   \n",
       "2      1.000000        0.882307  ...          0          0          0   \n",
       "3      1.000000        0.882307  ...          0          0          0   \n",
       "4      0.687500        0.389322  ...          0          0          1   \n",
       "\n",
       "   month_oct  month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0          0          0                1                0                0   \n",
       "1          0          0                1                0                0   \n",
       "2          0          0                0                0                0   \n",
       "3          0          0                1                0                0   \n",
       "4          0          0                0                1                0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                1  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"..\\..\\Data\\small_ohe.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'default', 'housing', 'loan', 'campaign', 'pdays', 'previous',\n",
       "       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
       "       'euribor3m', 'nr.employed', 'y', 'pdays2', 'job_admin.',\n",
       "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
       "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'contact_cellular', 'contact_telephone',\n",
       "       'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'day_of_week_fri', 'day_of_week_mon', 'day_of_week_thu',\n",
       "       'day_of_week_tue', 'day_of_week_wed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saperating features and result vectors\n",
    "X = data.drop('y', axis=1).values\n",
    "y = data['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "X_train, X_calibration, y_train, y_calibration = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define no sequence of layers\n",
    "input_tensor = tf.keras.Input(shape=(55,))\n",
    "layer1 = tf.keras.layers.Dense(64,name = 'layer_1', activation='relu',use_bias=True)(input_tensor)\n",
    "layer2 = tf.keras.layers.Dense(64,name = 'layer_2', activation='relu',use_bias=True)(layer1)\n",
    "layer3 = tf.keras.layers.Dense(32,name = 'layer_3', activation='relu',use_bias=True)(layer2)\n",
    "layer4 = tf.keras.layers.Dense(1, name = 'logit', activation=None,use_bias=True)(layer3)\n",
    "output_tensor = tf.keras.layers.Activation('sigmoid', name='output')(layer4)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=[layer1,layer2,layer3,layer4,output_tensor]) \n",
    "losses = {'logit': 'BinaryCrossentropy'}\n",
    "model.compile(loss=losses, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "41/41 [==============================] - 1s 5ms/step - loss: 1.5182 - logit_loss: 1.5182 - layer_1_accuracy: 0.0124 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0897 - logit_accuracy: 0.4969 - output_accuracy: 0.4990 - val_loss: 0.6171 - val_logit_loss: 0.6171 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0261 - val_logit_accuracy: 0.6703 - val_output_accuracy: 0.4973\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.6030 - logit_loss: 0.6030 - layer_1_accuracy: 0.0065 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0288 - logit_accuracy: 0.6865 - output_accuracy: 0.4987 - val_loss: 0.5288 - val_logit_loss: 0.5288 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0398 - val_logit_accuracy: 0.7665 - val_output_accuracy: 0.4986\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5493 - logit_loss: 0.5493 - layer_1_accuracy: 0.0065 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0361 - logit_accuracy: 0.7381 - output_accuracy: 0.4996 - val_loss: 0.5122 - val_logit_loss: 0.5122 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0467 - val_logit_accuracy: 0.7734 - val_output_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5205 - logit_loss: 0.5205 - layer_1_accuracy: 0.0080 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0483 - logit_accuracy: 0.7512 - output_accuracy: 0.5019 - val_loss: 0.4959 - val_logit_loss: 0.4959 - val_layer_1_accuracy: 0.0069 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.7788 - val_output_accuracy: 0.5041\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5389 - logit_loss: 0.5389 - layer_1_accuracy: 0.0124 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0430 - logit_accuracy: 0.7342 - output_accuracy: 0.5084 - val_loss: 0.5271 - val_logit_loss: 0.5271 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0041 - val_logit_accuracy: 0.7225 - val_output_accuracy: 0.4973\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5026 - logit_loss: 0.5026 - layer_1_accuracy: 0.0136 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0118 - logit_accuracy: 0.7566 - output_accuracy: 0.5185 - val_loss: 0.4872 - val_logit_loss: 0.4872 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0302 - val_logit_accuracy: 0.7596 - val_output_accuracy: 0.5110\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4682 - logit_loss: 0.4682 - layer_1_accuracy: 0.0145 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0332 - logit_accuracy: 0.7722 - output_accuracy: 0.5317 - val_loss: 0.4803 - val_logit_loss: 0.4803 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0481 - val_logit_accuracy: 0.7734 - val_output_accuracy: 0.5412\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4449 - logit_loss: 0.4449 - layer_1_accuracy: 0.0130 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0494 - logit_accuracy: 0.7787 - output_accuracy: 0.5529 - val_loss: 0.4663 - val_logit_loss: 0.4663 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0742 - val_logit_accuracy: 0.7775 - val_output_accuracy: 0.5549\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4300 - logit_loss: 0.4300 - layer_1_accuracy: 0.0126 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0573 - logit_accuracy: 0.7864 - output_accuracy: 0.5571 - val_loss: 0.4481 - val_logit_loss: 0.4481 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0728 - val_logit_accuracy: 0.7761 - val_output_accuracy: 0.5755\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3958 - logit_loss: 0.3958 - layer_1_accuracy: 0.0128 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0565 - logit_accuracy: 0.8005 - output_accuracy: 0.5941 - val_loss: 0.4278 - val_logit_loss: 0.4278 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0604 - val_logit_accuracy: 0.7857 - val_output_accuracy: 0.6099\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3682 - logit_loss: 0.3682 - layer_1_accuracy: 0.0149 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0496 - logit_accuracy: 0.8114 - output_accuracy: 0.6218 - val_loss: 0.4721 - val_logit_loss: 0.4721 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0467 - val_logit_accuracy: 0.7912 - val_output_accuracy: 0.6181\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3430 - logit_loss: 0.3430 - layer_1_accuracy: 0.0141 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0567 - logit_accuracy: 0.8244 - output_accuracy: 0.6422 - val_loss: 0.4291 - val_logit_loss: 0.4291 - val_layer_1_accuracy: 0.0082 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0577 - val_logit_accuracy: 0.7953 - val_output_accuracy: 0.6058\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3258 - logit_loss: 0.3258 - layer_1_accuracy: 0.0141 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0680 - logit_accuracy: 0.8436 - output_accuracy: 0.6688 - val_loss: 0.4205 - val_logit_loss: 0.4205 - val_layer_1_accuracy: 0.0124 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0385 - val_logit_accuracy: 0.8118 - val_output_accuracy: 0.6717\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2969 - logit_loss: 0.2969 - layer_1_accuracy: 0.0170 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0365 - logit_accuracy: 0.8625 - output_accuracy: 0.7006 - val_loss: 0.3862 - val_logit_loss: 0.3862 - val_layer_1_accuracy: 0.0110 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0426 - val_logit_accuracy: 0.8297 - val_output_accuracy: 0.7019\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2768 - logit_loss: 0.2768 - layer_1_accuracy: 0.0147 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0397 - logit_accuracy: 0.8706 - output_accuracy: 0.7352 - val_loss: 0.3685 - val_logit_loss: 0.3685 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0330 - val_logit_accuracy: 0.8283 - val_output_accuracy: 0.6964\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2739 - logit_loss: 0.2739 - layer_1_accuracy: 0.0141 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0386 - logit_accuracy: 0.8751 - output_accuracy: 0.7222 - val_loss: 0.3906 - val_logit_loss: 0.3906 - val_layer_1_accuracy: 0.0096 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0371 - val_logit_accuracy: 0.8613 - val_output_accuracy: 0.7074\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2380 - logit_loss: 0.2380 - layer_1_accuracy: 0.0143 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0384 - logit_accuracy: 0.8979 - output_accuracy: 0.7637 - val_loss: 0.4016 - val_logit_loss: 0.4016 - val_layer_1_accuracy: 0.0151 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0234 - val_logit_accuracy: 0.8585 - val_output_accuracy: 0.7115\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2139 - logit_loss: 0.2139 - layer_1_accuracy: 0.0143 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0307 - logit_accuracy: 0.9068 - output_accuracy: 0.7824 - val_loss: 0.3725 - val_logit_loss: 0.3725 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0234 - val_logit_accuracy: 0.8599 - val_output_accuracy: 0.7679\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1981 - logit_loss: 0.1981 - layer_1_accuracy: 0.0141 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0305 - logit_accuracy: 0.9170 - output_accuracy: 0.8028 - val_loss: 0.3752 - val_logit_loss: 0.3752 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0234 - val_logit_accuracy: 0.8723 - val_output_accuracy: 0.7706\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1780 - logit_loss: 0.1780 - layer_1_accuracy: 0.0149 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0323 - logit_accuracy: 0.9269 - output_accuracy: 0.8181 - val_loss: 0.5010 - val_logit_loss: 0.5010 - val_layer_1_accuracy: 0.0151 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0151 - val_logit_accuracy: 0.8489 - val_output_accuracy: 0.7170\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1775 - logit_loss: 0.1775 - layer_1_accuracy: 0.0155 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0376 - logit_accuracy: 0.9267 - output_accuracy: 0.8246 - val_loss: 0.3802 - val_logit_loss: 0.3802 - val_layer_1_accuracy: 0.0151 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0316 - val_logit_accuracy: 0.8874 - val_output_accuracy: 0.7734\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1578 - logit_loss: 0.1578 - layer_1_accuracy: 0.0147 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0326 - logit_accuracy: 0.9385 - output_accuracy: 0.8358 - val_loss: 0.3686 - val_logit_loss: 0.3686 - val_layer_1_accuracy: 0.0151 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0234 - val_logit_accuracy: 0.8997 - val_output_accuracy: 0.7802\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2298 - logit_loss: 0.2298 - layer_1_accuracy: 0.0160 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0428 - logit_accuracy: 0.9223 - output_accuracy: 0.8553 - val_loss: 0.7778 - val_logit_loss: 0.7778 - val_layer_1_accuracy: 0.0302 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0495 - val_logit_accuracy: 0.7898 - val_output_accuracy: 0.8503\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 1.0296 - logit_loss: 1.0296 - layer_1_accuracy: 0.0403 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0609 - logit_accuracy: 0.7892 - output_accuracy: 0.7024 - val_loss: 0.9854 - val_logit_loss: 0.9854 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0412 - val_logit_accuracy: 0.7170 - val_output_accuracy: 0.6772\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5163 - logit_loss: 0.5163 - layer_1_accuracy: 0.0430 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0363 - logit_accuracy: 0.8291 - output_accuracy: 0.6670 - val_loss: 0.8477 - val_logit_loss: 0.8477 - val_layer_1_accuracy: 0.0453 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0234 - val_logit_accuracy: 0.7720 - val_output_accuracy: 0.6181\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4078 - logit_loss: 0.4078 - layer_1_accuracy: 0.0554 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0313 - logit_accuracy: 0.8482 - output_accuracy: 0.7190 - val_loss: 0.4090 - val_logit_loss: 0.4090 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0467 - val_logit_accuracy: 0.8324 - val_output_accuracy: 0.7321\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2990 - logit_loss: 0.2990 - layer_1_accuracy: 0.0535 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0370 - logit_accuracy: 0.8872 - output_accuracy: 0.7635 - val_loss: 0.3981 - val_logit_loss: 0.3981 - val_layer_1_accuracy: 0.0467 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0398 - val_logit_accuracy: 0.8544 - val_output_accuracy: 0.7679\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2650 - logit_loss: 0.2650 - layer_1_accuracy: 0.0498 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0319 - logit_accuracy: 0.9030 - output_accuracy: 0.7934 - val_loss: 0.4367 - val_logit_loss: 0.4367 - val_layer_1_accuracy: 0.0467 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0261 - val_logit_accuracy: 0.8736 - val_output_accuracy: 0.7500\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2418 - logit_loss: 0.2418 - layer_1_accuracy: 0.0477 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0286 - logit_accuracy: 0.9147 - output_accuracy: 0.8095 - val_loss: 0.3756 - val_logit_loss: 0.3756 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.8887 - val_output_accuracy: 0.7857\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2266 - logit_loss: 0.2266 - layer_1_accuracy: 0.0460 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0229 - logit_accuracy: 0.9244 - output_accuracy: 0.8225 - val_loss: 0.3997 - val_logit_loss: 0.3997 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0206 - val_logit_accuracy: 0.8929 - val_output_accuracy: 0.7940\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2157 - logit_loss: 0.2157 - layer_1_accuracy: 0.0441 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0221 - logit_accuracy: 0.9315 - output_accuracy: 0.8299 - val_loss: 0.3616 - val_logit_loss: 0.3616 - val_layer_1_accuracy: 0.0398 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0192 - val_logit_accuracy: 0.8984 - val_output_accuracy: 0.8049\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1977 - logit_loss: 0.1977 - layer_1_accuracy: 0.0416 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0189 - logit_accuracy: 0.9359 - output_accuracy: 0.8459 - val_loss: 0.3858 - val_logit_loss: 0.3858 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0137 - val_logit_accuracy: 0.8956 - val_output_accuracy: 0.8146\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1840 - logit_loss: 0.1840 - layer_1_accuracy: 0.0409 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0193 - logit_accuracy: 0.9471 - output_accuracy: 0.8545 - val_loss: 0.5050 - val_logit_loss: 0.5050 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0124 - val_logit_accuracy: 0.9080 - val_output_accuracy: 0.7981\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1749 - logit_loss: 0.1749 - layer_1_accuracy: 0.0409 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0187 - logit_accuracy: 0.9485 - output_accuracy: 0.8604 - val_loss: 0.4067 - val_logit_loss: 0.4067 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0165 - val_logit_accuracy: 0.9080 - val_output_accuracy: 0.8255\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1681 - logit_loss: 0.1681 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0168 - logit_accuracy: 0.9544 - output_accuracy: 0.8725 - val_loss: 0.4710 - val_logit_loss: 0.4710 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0151 - val_logit_accuracy: 0.9135 - val_output_accuracy: 0.8146\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1970 - logit_loss: 0.1970 - layer_1_accuracy: 0.0376 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0195 - logit_accuracy: 0.9475 - output_accuracy: 0.8652 - val_loss: 0.3546 - val_logit_loss: 0.3546 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0096 - val_logit_accuracy: 0.9093 - val_output_accuracy: 0.8475\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1659 - logit_loss: 0.1659 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0090 - logit_accuracy: 0.9542 - output_accuracy: 0.8715 - val_loss: 0.3882 - val_logit_loss: 0.3882 - val_layer_1_accuracy: 0.0343 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0082 - val_logit_accuracy: 0.9190 - val_output_accuracy: 0.8407\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1533 - logit_loss: 0.1533 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0120 - logit_accuracy: 0.9591 - output_accuracy: 0.8856 - val_loss: 0.4285 - val_logit_loss: 0.4285 - val_layer_1_accuracy: 0.0343 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0096 - val_logit_accuracy: 0.9217 - val_output_accuracy: 0.8420\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1503 - logit_loss: 0.1503 - layer_1_accuracy: 0.0325 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0122 - logit_accuracy: 0.9622 - output_accuracy: 0.8918 - val_loss: 0.4076 - val_logit_loss: 0.4076 - val_layer_1_accuracy: 0.0343 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0096 - val_logit_accuracy: 0.9245 - val_output_accuracy: 0.8475\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2388 - logit_loss: 0.2388 - layer_1_accuracy: 0.0284 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0271 - logit_accuracy: 0.9376 - output_accuracy: 0.8830 - val_loss: 0.4544 - val_logit_loss: 0.4544 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.8942 - val_output_accuracy: 0.8269\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2316 - logit_loss: 0.2316 - layer_1_accuracy: 0.0220 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0332 - logit_accuracy: 0.9446 - output_accuracy: 0.8767 - val_loss: 0.5637 - val_logit_loss: 0.5637 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0302 - val_logit_accuracy: 0.8956 - val_output_accuracy: 0.8201\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1992 - logit_loss: 0.1992 - layer_1_accuracy: 0.0220 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0250 - logit_accuracy: 0.9567 - output_accuracy: 0.8771 - val_loss: 0.4357 - val_logit_loss: 0.4357 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0165 - val_logit_accuracy: 0.9135 - val_output_accuracy: 0.8475\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1759 - logit_loss: 0.1759 - layer_1_accuracy: 0.0218 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0200 - logit_accuracy: 0.9622 - output_accuracy: 0.8973 - val_loss: 0.4098 - val_logit_loss: 0.4098 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0179 - val_logit_accuracy: 0.9286 - val_output_accuracy: 0.8585\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1579 - logit_loss: 0.1579 - layer_1_accuracy: 0.0214 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0189 - logit_accuracy: 0.9672 - output_accuracy: 0.9053 - val_loss: 0.3964 - val_logit_loss: 0.3964 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0165 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.8558\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1434 - logit_loss: 0.1434 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0174 - logit_accuracy: 0.9685 - output_accuracy: 0.9118 - val_loss: 0.3944 - val_logit_loss: 0.3944 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0179 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8530\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1398 - logit_loss: 0.1398 - layer_1_accuracy: 0.0208 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0174 - logit_accuracy: 0.9702 - output_accuracy: 0.9107 - val_loss: 0.3457 - val_logit_loss: 0.3457 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0124 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8736\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1650 - logit_loss: 0.1650 - layer_1_accuracy: 0.0208 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0200 - logit_accuracy: 0.9647 - output_accuracy: 0.9166 - val_loss: 0.4746 - val_logit_loss: 0.4746 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0179 - val_logit_accuracy: 0.9093 - val_output_accuracy: 0.8475\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1889 - logit_loss: 0.1889 - layer_1_accuracy: 0.0208 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0204 - logit_accuracy: 0.9645 - output_accuracy: 0.9007 - val_loss: 0.3764 - val_logit_loss: 0.3764 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0179 - val_logit_accuracy: 0.9162 - val_output_accuracy: 0.8709\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1870 - logit_loss: 0.1870 - layer_1_accuracy: 0.0218 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0239 - logit_accuracy: 0.9670 - output_accuracy: 0.9120 - val_loss: 0.3879 - val_logit_loss: 0.3879 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0165 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8626\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1640 - logit_loss: 0.1640 - layer_1_accuracy: 0.0208 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0212 - logit_accuracy: 0.9677 - output_accuracy: 0.9147 - val_loss: 0.3959 - val_logit_loss: 0.3959 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0096 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.8626\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1533 - logit_loss: 0.1533 - layer_1_accuracy: 0.0208 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0174 - logit_accuracy: 0.9708 - output_accuracy: 0.9275 - val_loss: 0.4072 - val_logit_loss: 0.4072 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0137 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.8599\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1521 - logit_loss: 0.1521 - layer_1_accuracy: 0.0208 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0172 - logit_accuracy: 0.9723 - output_accuracy: 0.9296 - val_loss: 0.3672 - val_logit_loss: 0.3672 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0110 - val_logit_accuracy: 0.9341 - val_output_accuracy: 0.8681\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1525 - logit_loss: 0.1525 - layer_1_accuracy: 0.0206 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0172 - logit_accuracy: 0.9731 - output_accuracy: 0.9364 - val_loss: 0.5369 - val_logit_loss: 0.5369 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0179 - val_logit_accuracy: 0.9190 - val_output_accuracy: 0.8516\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2107 - logit_loss: 0.2107 - layer_1_accuracy: 0.0204 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0233 - logit_accuracy: 0.9668 - output_accuracy: 0.9175 - val_loss: 0.4181 - val_logit_loss: 0.4181 - val_layer_1_accuracy: 0.0206 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0165 - val_logit_accuracy: 0.9272 - val_output_accuracy: 0.8723\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1832 - logit_loss: 0.1832 - layer_1_accuracy: 0.0195 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0204 - logit_accuracy: 0.9651 - output_accuracy: 0.9128 - val_loss: 0.5392 - val_logit_loss: 0.5392 - val_layer_1_accuracy: 0.0234 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0151 - val_logit_accuracy: 0.9203 - val_output_accuracy: 0.8503\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4920 - logit_loss: 0.4920 - layer_1_accuracy: 0.0223 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0199 - logit_accuracy: 0.9233 - output_accuracy: 0.8740 - val_loss: 2.7453 - val_logit_loss: 2.7453 - val_layer_1_accuracy: 0.0275 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0069 - val_logit_accuracy: 0.7157 - val_output_accuracy: 0.6525\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 2.3669 - logit_loss: 2.3669 - layer_1_accuracy: 0.0172 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0021 - logit_accuracy: 0.7484 - output_accuracy: 0.7127 - val_loss: 2.1339 - val_logit_loss: 2.1339 - val_layer_1_accuracy: 0.0165 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7527 - val_output_accuracy: 0.6923\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.7311 - logit_loss: 1.7311 - layer_1_accuracy: 0.0158 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 3.8183e-04 - logit_accuracy: 0.7805 - output_accuracy: 0.7308 - val_loss: 0.8303 - val_logit_loss: 0.8303 - val_layer_1_accuracy: 0.0124 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8036 - val_output_accuracy: 0.7253\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.6541 - logit_loss: 0.6541 - layer_1_accuracy: 0.0145 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 5.7274e-04 - logit_accuracy: 0.8301 - output_accuracy: 0.7312 - val_loss: 0.6329 - val_logit_loss: 0.6329 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8393 - val_output_accuracy: 0.7212\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4853 - logit_loss: 0.4853 - layer_1_accuracy: 0.0168 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 3.8183e-04 - logit_accuracy: 0.8696 - output_accuracy: 0.7409 - val_loss: 0.6108 - val_logit_loss: 0.6108 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8613 - val_output_accuracy: 0.7555\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4661 - logit_loss: 0.4661 - layer_1_accuracy: 0.0158 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 5.7274e-04 - logit_accuracy: 0.8687 - output_accuracy: 0.7677 - val_loss: 0.5889 - val_logit_loss: 0.5889 - val_layer_1_accuracy: 0.0124 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8709 - val_output_accuracy: 0.7514\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4095 - logit_loss: 0.4095 - layer_1_accuracy: 0.0158 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8900 - output_accuracy: 0.7761 - val_loss: 0.5492 - val_logit_loss: 0.5492 - val_layer_1_accuracy: 0.0124 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8709 - val_output_accuracy: 0.7788\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3894 - logit_loss: 0.3894 - layer_1_accuracy: 0.0179 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.9038 - output_accuracy: 0.7944 - val_loss: 0.5338 - val_logit_loss: 0.5338 - val_layer_1_accuracy: 0.0179 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8874 - val_output_accuracy: 0.7926\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3759 - logit_loss: 0.3759 - layer_1_accuracy: 0.0178 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.9099 - output_accuracy: 0.8142 - val_loss: 0.5226 - val_logit_loss: 0.5226 - val_layer_1_accuracy: 0.0124 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8805 - val_output_accuracy: 0.8173\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3816 - logit_loss: 0.3816 - layer_1_accuracy: 0.0158 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.9128 - output_accuracy: 0.8265 - val_loss: 0.5454 - val_logit_loss: 0.5454 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8942 - val_output_accuracy: 0.8049\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3686 - logit_loss: 0.3686 - layer_1_accuracy: 0.0170 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9215 - output_accuracy: 0.8360 - val_loss: 0.5174 - val_logit_loss: 0.5174 - val_layer_1_accuracy: 0.0137 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9080 - val_output_accuracy: 0.8324\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3826 - logit_loss: 0.3826 - layer_1_accuracy: 0.0170 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9210 - output_accuracy: 0.8435 - val_loss: 0.9515 - val_logit_loss: 0.9515 - val_layer_1_accuracy: 0.0179 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8393 - val_output_accuracy: 0.7239\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5236 - logit_loss: 0.5236 - layer_1_accuracy: 0.0179 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8835 - output_accuracy: 0.8152 - val_loss: 0.9465 - val_logit_loss: 0.9465 - val_layer_1_accuracy: 0.0206 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8214 - val_output_accuracy: 0.7074\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 2.1091 - logit_loss: 2.1091 - layer_1_accuracy: 0.0174 - layer_2_accuracy: 0.0021 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.7438 - output_accuracy: 0.7507 - val_loss: 1.7663 - val_logit_loss: 1.7663 - val_layer_1_accuracy: 0.0192 - val_layer_2_accuracy: 0.0055 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7541 - val_output_accuracy: 0.7129\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.6984 - logit_loss: 1.6984 - layer_1_accuracy: 0.0296 - layer_2_accuracy: 9.5456e-04 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.7243 - output_accuracy: 0.6413 - val_loss: 1.2765 - val_logit_loss: 1.2765 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7679 - val_output_accuracy: 0.6799\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.8243 - logit_loss: 0.8243 - layer_1_accuracy: 0.0342 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.7751 - output_accuracy: 0.6724 - val_loss: 0.6483 - val_logit_loss: 0.6483 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7885 - val_output_accuracy: 0.6525\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5523 - logit_loss: 0.5523 - layer_1_accuracy: 0.0342 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8106 - output_accuracy: 0.6625 - val_loss: 0.5824 - val_logit_loss: 0.5824 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8036 - val_output_accuracy: 0.6387\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4967 - logit_loss: 0.4967 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8186 - output_accuracy: 0.6798 - val_loss: 0.5545 - val_logit_loss: 0.5545 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8242 - val_output_accuracy: 0.6538\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4589 - logit_loss: 0.4589 - layer_1_accuracy: 0.0363 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8291 - output_accuracy: 0.7077 - val_loss: 0.5652 - val_logit_loss: 0.5652 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8283 - val_output_accuracy: 0.6442\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4373 - logit_loss: 0.4373 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8471 - output_accuracy: 0.7056 - val_loss: 0.5113 - val_logit_loss: 0.5113 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8242 - val_output_accuracy: 0.6731\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4195 - logit_loss: 0.4195 - layer_1_accuracy: 0.0376 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8582 - output_accuracy: 0.7178 - val_loss: 0.5342 - val_logit_loss: 0.5342 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8379 - val_output_accuracy: 0.6758\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4015 - logit_loss: 0.4015 - layer_1_accuracy: 0.0376 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8637 - output_accuracy: 0.7356 - val_loss: 0.5257 - val_logit_loss: 0.5257 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8434 - val_output_accuracy: 0.6827\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3870 - logit_loss: 0.3870 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8736 - output_accuracy: 0.7394 - val_loss: 0.5519 - val_logit_loss: 0.5519 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8448 - val_output_accuracy: 0.7074\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3664 - logit_loss: 0.3664 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8792 - output_accuracy: 0.7468 - val_loss: 0.5624 - val_logit_loss: 0.5624 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8448 - val_output_accuracy: 0.7102\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3487 - logit_loss: 0.3487 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8856 - output_accuracy: 0.7583 - val_loss: 0.5377 - val_logit_loss: 0.5377 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8530 - val_output_accuracy: 0.7253\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3387 - logit_loss: 0.3387 - layer_1_accuracy: 0.0388 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8946 - output_accuracy: 0.7663 - val_loss: 0.5423 - val_logit_loss: 0.5423 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8613 - val_output_accuracy: 0.7308\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3293 - logit_loss: 0.3293 - layer_1_accuracy: 0.0391 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.9015 - output_accuracy: 0.7732 - val_loss: 0.5357 - val_logit_loss: 0.5357 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8613 - val_output_accuracy: 0.7390\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3204 - logit_loss: 0.3204 - layer_1_accuracy: 0.0391 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.9026 - output_accuracy: 0.7822 - val_loss: 0.5275 - val_logit_loss: 0.5275 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8613 - val_output_accuracy: 0.7527\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3125 - logit_loss: 0.3125 - layer_1_accuracy: 0.0391 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.9076 - output_accuracy: 0.7927 - val_loss: 0.4878 - val_logit_loss: 0.4878 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8709 - val_output_accuracy: 0.7665\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3047 - logit_loss: 0.3047 - layer_1_accuracy: 0.0391 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9103 - output_accuracy: 0.7984 - val_loss: 0.5320 - val_logit_loss: 0.5320 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8764 - val_output_accuracy: 0.7569\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2963 - logit_loss: 0.2963 - layer_1_accuracy: 0.0393 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9162 - output_accuracy: 0.8055 - val_loss: 0.5422 - val_logit_loss: 0.5422 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8819 - val_output_accuracy: 0.7582\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2890 - logit_loss: 0.2890 - layer_1_accuracy: 0.0391 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9204 - output_accuracy: 0.8135 - val_loss: 0.5186 - val_logit_loss: 0.5186 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8846 - val_output_accuracy: 0.7665\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2810 - logit_loss: 0.2810 - layer_1_accuracy: 0.0414 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9280 - output_accuracy: 0.8175 - val_loss: 0.4976 - val_logit_loss: 0.4976 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8860 - val_output_accuracy: 0.7679\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2735 - logit_loss: 0.2735 - layer_1_accuracy: 0.0407 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9263 - output_accuracy: 0.8280 - val_loss: 0.4879 - val_logit_loss: 0.4879 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8846 - val_output_accuracy: 0.7816\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2658 - logit_loss: 0.2658 - layer_1_accuracy: 0.0401 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9313 - output_accuracy: 0.8345 - val_loss: 0.4954 - val_logit_loss: 0.4954 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8860 - val_output_accuracy: 0.7981\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2612 - logit_loss: 0.2612 - layer_1_accuracy: 0.0401 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9332 - output_accuracy: 0.8425 - val_loss: 0.4767 - val_logit_loss: 0.4767 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8874 - val_output_accuracy: 0.7926\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2557 - logit_loss: 0.2557 - layer_1_accuracy: 0.0401 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9376 - output_accuracy: 0.8473 - val_loss: 0.4775 - val_logit_loss: 0.4775 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8832 - val_output_accuracy: 0.8008\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2493 - logit_loss: 0.2493 - layer_1_accuracy: 0.0403 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9387 - output_accuracy: 0.8526 - val_loss: 0.4834 - val_logit_loss: 0.4834 - val_layer_1_accuracy: 0.0453 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8956 - val_output_accuracy: 0.8104\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2443 - logit_loss: 0.2443 - layer_1_accuracy: 0.0397 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9414 - output_accuracy: 0.8612 - val_loss: 0.4607 - val_logit_loss: 0.4607 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8970 - val_output_accuracy: 0.8146\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2399 - logit_loss: 0.2399 - layer_1_accuracy: 0.0405 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9450 - output_accuracy: 0.8629 - val_loss: 0.4625 - val_logit_loss: 0.4625 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9025 - val_output_accuracy: 0.8201\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2341 - logit_loss: 0.2341 - layer_1_accuracy: 0.0393 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9469 - output_accuracy: 0.8696 - val_loss: 0.4722 - val_logit_loss: 0.4722 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9080 - val_output_accuracy: 0.8255\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2914 - logit_loss: 0.2914 - layer_1_accuracy: 0.0401 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9326 - output_accuracy: 0.8803 - val_loss: 0.7062 - val_logit_loss: 0.7062 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8544 - val_output_accuracy: 0.7926\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4741 - logit_loss: 0.4741 - layer_1_accuracy: 0.0498 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8856 - output_accuracy: 0.8299 - val_loss: 0.7319 - val_logit_loss: 0.7319 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8352 - val_output_accuracy: 0.7527\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3255 - logit_loss: 0.3255 - layer_1_accuracy: 0.0517 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9122 - output_accuracy: 0.8375 - val_loss: 0.4661 - val_logit_loss: 0.4661 - val_layer_1_accuracy: 0.0591 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8887 - val_output_accuracy: 0.7898\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2785 - logit_loss: 0.2785 - layer_1_accuracy: 0.0489 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9374 - output_accuracy: 0.8394 - val_loss: 0.4323 - val_logit_loss: 0.4323 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8997 - val_output_accuracy: 0.8104\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2598 - logit_loss: 0.2598 - layer_1_accuracy: 0.0481 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9435 - output_accuracy: 0.8606 - val_loss: 0.4457 - val_logit_loss: 0.4457 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8970 - val_output_accuracy: 0.8242\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2496 - logit_loss: 0.2496 - layer_1_accuracy: 0.0475 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9467 - output_accuracy: 0.8700 - val_loss: 0.4283 - val_logit_loss: 0.4283 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9052 - val_output_accuracy: 0.8201\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2415 - logit_loss: 0.2415 - layer_1_accuracy: 0.0468 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9527 - output_accuracy: 0.8732 - val_loss: 0.4085 - val_logit_loss: 0.4085 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9107 - val_output_accuracy: 0.8324\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2387 - logit_loss: 0.2387 - layer_1_accuracy: 0.0462 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9555 - output_accuracy: 0.8814 - val_loss: 0.3997 - val_logit_loss: 0.3997 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9093 - val_output_accuracy: 0.8448\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3976 - logit_loss: 0.3976 - layer_1_accuracy: 0.0452 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9084 - output_accuracy: 0.8477 - val_loss: 0.4276 - val_logit_loss: 0.4276 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8846 - val_output_accuracy: 0.8159\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3045 - logit_loss: 0.3045 - layer_1_accuracy: 0.0460 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9336 - output_accuracy: 0.8517 - val_loss: 0.3723 - val_logit_loss: 0.3723 - val_layer_1_accuracy: 0.0549 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9011 - val_output_accuracy: 0.8420\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2731 - logit_loss: 0.2731 - layer_1_accuracy: 0.0449 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9458 - output_accuracy: 0.8650 - val_loss: 0.3823 - val_logit_loss: 0.3823 - val_layer_1_accuracy: 0.0549 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9093 - val_output_accuracy: 0.8324\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2608 - logit_loss: 0.2608 - layer_1_accuracy: 0.0439 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9513 - output_accuracy: 0.8755 - val_loss: 0.3798 - val_logit_loss: 0.3798 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9107 - val_output_accuracy: 0.8324\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2536 - logit_loss: 0.2536 - layer_1_accuracy: 0.0430 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9538 - output_accuracy: 0.8807 - val_loss: 0.3759 - val_logit_loss: 0.3759 - val_layer_1_accuracy: 0.0481 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9162 - val_output_accuracy: 0.8407\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2701 - logit_loss: 0.2701 - layer_1_accuracy: 0.0424 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9498 - output_accuracy: 0.8788 - val_loss: 0.9470 - val_logit_loss: 0.9470 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8695 - val_output_accuracy: 0.7596\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3354 - logit_loss: 0.3354 - layer_1_accuracy: 0.0388 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9309 - output_accuracy: 0.8570 - val_loss: 0.4281 - val_logit_loss: 0.4281 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8956 - val_output_accuracy: 0.8118\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2628 - logit_loss: 0.2628 - layer_1_accuracy: 0.0410 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9504 - output_accuracy: 0.8784 - val_loss: 0.4297 - val_logit_loss: 0.4297 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8970 - val_output_accuracy: 0.8324\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2430 - logit_loss: 0.2430 - layer_1_accuracy: 0.0420 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9534 - output_accuracy: 0.8839 - val_loss: 0.3704 - val_logit_loss: 0.3704 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9190 - val_output_accuracy: 0.8503\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2315 - logit_loss: 0.2315 - layer_1_accuracy: 0.0410 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9565 - output_accuracy: 0.8961 - val_loss: 0.3985 - val_logit_loss: 0.3985 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9162 - val_output_accuracy: 0.8365\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2243 - logit_loss: 0.2243 - layer_1_accuracy: 0.0410 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9578 - output_accuracy: 0.8998 - val_loss: 0.4062 - val_logit_loss: 0.4062 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9190 - val_output_accuracy: 0.8516\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2196 - logit_loss: 0.2196 - layer_1_accuracy: 0.0403 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9607 - output_accuracy: 0.9057 - val_loss: 0.4140 - val_logit_loss: 0.4140 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9217 - val_output_accuracy: 0.8654\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2165 - logit_loss: 0.2165 - layer_1_accuracy: 0.0403 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9612 - output_accuracy: 0.9122 - val_loss: 0.4318 - val_logit_loss: 0.4318 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9162 - val_output_accuracy: 0.8599\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2136 - logit_loss: 0.2136 - layer_1_accuracy: 0.0403 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9635 - output_accuracy: 0.9149 - val_loss: 0.4264 - val_logit_loss: 0.4264 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9107 - val_output_accuracy: 0.8681\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2198 - logit_loss: 0.2198 - layer_1_accuracy: 0.0389 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9590 - output_accuracy: 0.9152 - val_loss: 0.4225 - val_logit_loss: 0.4225 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9190 - val_output_accuracy: 0.8599\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3131 - logit_loss: 0.3131 - layer_1_accuracy: 0.0437 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9458 - output_accuracy: 0.8998 - val_loss: 0.4330 - val_logit_loss: 0.4330 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0041 - val_logit_accuracy: 0.9093 - val_output_accuracy: 0.8530\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3206 - logit_loss: 0.3206 - layer_1_accuracy: 0.0441 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0013 - logit_accuracy: 0.9475 - output_accuracy: 0.9002 - val_loss: 0.4634 - val_logit_loss: 0.4634 - val_layer_1_accuracy: 0.0549 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0027 - val_logit_accuracy: 0.9121 - val_output_accuracy: 0.8585\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2552 - logit_loss: 0.2552 - layer_1_accuracy: 0.0414 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0015 - logit_accuracy: 0.9570 - output_accuracy: 0.9110 - val_loss: 0.4197 - val_logit_loss: 0.4197 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9148 - val_output_accuracy: 0.8599\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2445 - logit_loss: 0.2445 - layer_1_accuracy: 0.0430 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0013 - logit_accuracy: 0.9620 - output_accuracy: 0.9133 - val_loss: 0.4335 - val_logit_loss: 0.4335 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9217 - val_output_accuracy: 0.8654\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2401 - logit_loss: 0.2401 - layer_1_accuracy: 0.0435 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9637 - output_accuracy: 0.9238 - val_loss: 0.4235 - val_logit_loss: 0.4235 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8723\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2370 - logit_loss: 0.2370 - layer_1_accuracy: 0.0435 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0011 - logit_accuracy: 0.9647 - output_accuracy: 0.9255 - val_loss: 0.4234 - val_logit_loss: 0.4234 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9231 - val_output_accuracy: 0.8709\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2348 - logit_loss: 0.2348 - layer_1_accuracy: 0.0439 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9656 - output_accuracy: 0.9246 - val_loss: 0.4257 - val_logit_loss: 0.4257 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9190 - val_output_accuracy: 0.8736\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2331 - logit_loss: 0.2331 - layer_1_accuracy: 0.0437 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0013 - logit_accuracy: 0.9664 - output_accuracy: 0.9290 - val_loss: 0.4330 - val_logit_loss: 0.4330 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.8736\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2309 - logit_loss: 0.2309 - layer_1_accuracy: 0.0451 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0011 - logit_accuracy: 0.9666 - output_accuracy: 0.9336 - val_loss: 0.4163 - val_logit_loss: 0.4163 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9245 - val_output_accuracy: 0.8764\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2300 - logit_loss: 0.2300 - layer_1_accuracy: 0.0451 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0011 - logit_accuracy: 0.9668 - output_accuracy: 0.9360 - val_loss: 0.4146 - val_logit_loss: 0.4146 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.8791\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2290 - logit_loss: 0.2290 - layer_1_accuracy: 0.0439 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9675 - output_accuracy: 0.9374 - val_loss: 0.4290 - val_logit_loss: 0.4290 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9245 - val_output_accuracy: 0.8791\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2281 - logit_loss: 0.2281 - layer_1_accuracy: 0.0441 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0015 - logit_accuracy: 0.9687 - output_accuracy: 0.9387 - val_loss: 0.4337 - val_logit_loss: 0.4337 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9272 - val_output_accuracy: 0.8750\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2269 - logit_loss: 0.2269 - layer_1_accuracy: 0.0426 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0013 - logit_accuracy: 0.9679 - output_accuracy: 0.9387 - val_loss: 0.4283 - val_logit_loss: 0.4283 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9258 - val_output_accuracy: 0.8805\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2239 - logit_loss: 0.2239 - layer_1_accuracy: 0.0439 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 0.0013 - logit_accuracy: 0.9679 - output_accuracy: 0.9416 - val_loss: 0.4316 - val_logit_loss: 0.4316 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8723\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2230 - logit_loss: 0.2230 - layer_1_accuracy: 0.0445 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0013 - logit_accuracy: 0.9683 - output_accuracy: 0.9425 - val_loss: 0.4091 - val_logit_loss: 0.4091 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9354 - val_output_accuracy: 0.8805\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2217 - logit_loss: 0.2217 - layer_1_accuracy: 0.0449 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9695 - output_accuracy: 0.9458 - val_loss: 0.4045 - val_logit_loss: 0.4045 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9368 - val_output_accuracy: 0.8805\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2211 - logit_loss: 0.2211 - layer_1_accuracy: 0.0441 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9689 - output_accuracy: 0.9456 - val_loss: 0.4257 - val_logit_loss: 0.4257 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9327 - val_output_accuracy: 0.8764\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2210 - logit_loss: 0.2210 - layer_1_accuracy: 0.0451 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0011 - logit_accuracy: 0.9695 - output_accuracy: 0.9456 - val_loss: 0.4172 - val_logit_loss: 0.4172 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8750\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2193 - logit_loss: 0.2193 - layer_1_accuracy: 0.0451 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9700 - output_accuracy: 0.9488 - val_loss: 0.4297 - val_logit_loss: 0.4297 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8764\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2191 - logit_loss: 0.2191 - layer_1_accuracy: 0.0437 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 5.7274e-04 - logit_accuracy: 0.9696 - output_accuracy: 0.9475 - val_loss: 0.4494 - val_logit_loss: 0.4494 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9286 - val_output_accuracy: 0.8750\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2186 - logit_loss: 0.2186 - layer_1_accuracy: 0.0435 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 5.7274e-04 - logit_accuracy: 0.9700 - output_accuracy: 0.9475 - val_loss: 0.4391 - val_logit_loss: 0.4391 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8860\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2223 - logit_loss: 0.2223 - layer_1_accuracy: 0.0439 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 7.6365e-04 - logit_accuracy: 0.9698 - output_accuracy: 0.9492 - val_loss: 0.4343 - val_logit_loss: 0.4343 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9245 - val_output_accuracy: 0.9093\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2650 - logit_loss: 0.2650 - layer_1_accuracy: 0.0462 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 9.5456e-04 - logit_accuracy: 0.9576 - output_accuracy: 0.9191 - val_loss: 0.4975 - val_logit_loss: 0.4975 - val_layer_1_accuracy: 0.0549 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9135 - val_output_accuracy: 0.8544\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2308 - logit_loss: 0.2308 - layer_1_accuracy: 0.0449 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 3.8183e-04 - logit_accuracy: 0.9683 - output_accuracy: 0.9383 - val_loss: 0.4937 - val_logit_loss: 0.4937 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9258 - val_output_accuracy: 0.8723\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2254 - logit_loss: 0.2254 - layer_1_accuracy: 0.0451 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 3.8183e-04 - logit_accuracy: 0.9687 - output_accuracy: 0.9448 - val_loss: 0.4671 - val_logit_loss: 0.4671 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9245 - val_output_accuracy: 0.8736\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2568 - logit_loss: 0.2568 - layer_1_accuracy: 0.0449 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 3.8183e-04 - logit_accuracy: 0.9666 - output_accuracy: 0.9456 - val_loss: 0.6344 - val_logit_loss: 0.6344 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9162 - val_output_accuracy: 0.8668\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2929 - logit_loss: 0.2929 - layer_1_accuracy: 0.0435 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 5.7274e-04 - logit_accuracy: 0.9639 - output_accuracy: 0.9374 - val_loss: 0.5125 - val_logit_loss: 0.5125 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8764\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2636 - logit_loss: 0.2636 - layer_1_accuracy: 0.0433 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 5.7274e-04 - logit_accuracy: 0.9670 - output_accuracy: 0.9454 - val_loss: 0.5190 - val_logit_loss: 0.5190 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9245 - val_output_accuracy: 0.8777\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2936 - logit_loss: 0.2936 - layer_1_accuracy: 0.0424 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 5.7274e-04 - logit_accuracy: 0.9593 - output_accuracy: 0.9309 - val_loss: 0.4752 - val_logit_loss: 0.4752 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9258 - val_output_accuracy: 0.8723\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2691 - logit_loss: 0.2691 - layer_1_accuracy: 0.0401 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 7.6365e-04 - logit_accuracy: 0.9656 - output_accuracy: 0.9422 - val_loss: 0.4398 - val_logit_loss: 0.4398 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9258 - val_output_accuracy: 0.8984\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4588 - logit_loss: 0.4588 - layer_1_accuracy: 0.0418 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 3.8183e-04 - logit_accuracy: 0.9292 - output_accuracy: 0.9118 - val_loss: 0.9662 - val_logit_loss: 0.9662 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8654 - val_output_accuracy: 0.8283\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 2.0340 - logit_loss: 2.0340 - layer_1_accuracy: 0.0452 - layer_2_accuracy: 3.8183e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.7923 - output_accuracy: 0.7868 - val_loss: 1.8708 - val_logit_loss: 1.8708 - val_layer_1_accuracy: 0.0467 - val_layer_2_accuracy: 0.0014 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7788 - val_output_accuracy: 0.7390\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.7871 - logit_loss: 1.7871 - layer_1_accuracy: 0.0682 - layer_2_accuracy: 9.5456e-04 - layer_3_accuracy: 1.9091e-04 - logit_accuracy: 0.8165 - output_accuracy: 0.8083 - val_loss: 1.6615 - val_logit_loss: 1.6615 - val_layer_1_accuracy: 0.0687 - val_layer_2_accuracy: 0.0027 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8063 - val_output_accuracy: 0.7651\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.2045 - logit_loss: 1.2045 - layer_1_accuracy: 0.0733 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8522 - output_accuracy: 0.7915 - val_loss: 1.1957 - val_logit_loss: 1.1957 - val_layer_1_accuracy: 0.0659 - val_layer_2_accuracy: 0.0014 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8379 - val_output_accuracy: 0.7885\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.6294 - logit_loss: 1.6294 - layer_1_accuracy: 0.0571 - layer_2_accuracy: 1.9091e-04 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.7988 - output_accuracy: 0.7881 - val_loss: 1.7750 - val_logit_loss: 1.7750 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7665 - val_output_accuracy: 0.6937\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.1984 - logit_loss: 1.1984 - layer_1_accuracy: 0.0557 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8244 - output_accuracy: 0.7610 - val_loss: 1.1786 - val_logit_loss: 1.1786 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8036 - val_output_accuracy: 0.7473\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.2504 - logit_loss: 1.2504 - layer_1_accuracy: 0.0342 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8209 - output_accuracy: 0.7593 - val_loss: 1.2631 - val_logit_loss: 1.2631 - val_layer_1_accuracy: 0.0179 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8008 - val_output_accuracy: 0.7418\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.1524 - logit_loss: 1.1524 - layer_1_accuracy: 0.0242 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8234 - output_accuracy: 0.7665 - val_loss: 1.2397 - val_logit_loss: 1.2397 - val_layer_1_accuracy: 0.0179 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7706 - val_output_accuracy: 0.7129\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 2.3614 - logit_loss: 2.3614 - layer_1_accuracy: 0.0296 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.7014 - output_accuracy: 0.6892 - val_loss: 2.2086 - val_logit_loss: 2.2086 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.6360 - val_output_accuracy: 0.6099\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.2406 - logit_loss: 1.2406 - layer_1_accuracy: 0.0472 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.7453 - output_accuracy: 0.6459 - val_loss: 1.2144 - val_logit_loss: 1.2144 - val_layer_1_accuracy: 0.0453 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7349 - val_output_accuracy: 0.5948\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6453 - logit_loss: 0.6453 - layer_1_accuracy: 0.0521 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.7976 - output_accuracy: 0.6411 - val_loss: 0.7504 - val_logit_loss: 0.7504 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7418 - val_output_accuracy: 0.6580\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5596 - logit_loss: 0.5596 - layer_1_accuracy: 0.0554 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8154 - output_accuracy: 0.6699 - val_loss: 0.7500 - val_logit_loss: 0.7500 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7692 - val_output_accuracy: 0.6621\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6487 - logit_loss: 0.6487 - layer_1_accuracy: 0.0519 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8005 - output_accuracy: 0.6722 - val_loss: 0.8508 - val_logit_loss: 0.8508 - val_layer_1_accuracy: 0.0398 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7569 - val_output_accuracy: 0.5893\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5632 - logit_loss: 0.5632 - layer_1_accuracy: 0.0326 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.7871 - output_accuracy: 0.6157 - val_loss: 0.7389 - val_logit_loss: 0.7389 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7569 - val_output_accuracy: 0.6209\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4716 - logit_loss: 0.4716 - layer_1_accuracy: 0.0309 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8137 - output_accuracy: 0.6361 - val_loss: 0.6405 - val_logit_loss: 0.6405 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7624 - val_output_accuracy: 0.6250\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4470 - logit_loss: 0.4470 - layer_1_accuracy: 0.0315 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8251 - output_accuracy: 0.6510 - val_loss: 0.6085 - val_logit_loss: 0.6085 - val_layer_1_accuracy: 0.0330 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7706 - val_output_accuracy: 0.6305\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4224 - logit_loss: 0.4224 - layer_1_accuracy: 0.0325 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8326 - output_accuracy: 0.6674 - val_loss: 0.5951 - val_logit_loss: 0.5951 - val_layer_1_accuracy: 0.0330 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7788 - val_output_accuracy: 0.6374\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4067 - logit_loss: 0.4067 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8394 - output_accuracy: 0.6699 - val_loss: 0.5830 - val_logit_loss: 0.5830 - val_layer_1_accuracy: 0.0330 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7802 - val_output_accuracy: 0.6566\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3828 - logit_loss: 0.3828 - layer_1_accuracy: 0.0342 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8427 - output_accuracy: 0.6940 - val_loss: 0.5540 - val_logit_loss: 0.5540 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7912 - val_output_accuracy: 0.6607\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3613 - logit_loss: 0.3613 - layer_1_accuracy: 0.0365 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8540 - output_accuracy: 0.7014 - val_loss: 0.5615 - val_logit_loss: 0.5615 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7953 - val_output_accuracy: 0.6703\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3455 - logit_loss: 0.3455 - layer_1_accuracy: 0.0368 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8561 - output_accuracy: 0.7159 - val_loss: 0.5510 - val_logit_loss: 0.5510 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8036 - val_output_accuracy: 0.6703\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3339 - logit_loss: 0.3339 - layer_1_accuracy: 0.0384 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8620 - output_accuracy: 0.7243 - val_loss: 0.5287 - val_logit_loss: 0.5287 - val_layer_1_accuracy: 0.0398 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8104 - val_output_accuracy: 0.6909\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3236 - logit_loss: 0.3236 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8660 - output_accuracy: 0.7325 - val_loss: 0.4920 - val_logit_loss: 0.4920 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8201 - val_output_accuracy: 0.7060\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3105 - logit_loss: 0.3105 - layer_1_accuracy: 0.0374 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8715 - output_accuracy: 0.7447 - val_loss: 0.4837 - val_logit_loss: 0.4837 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8242 - val_output_accuracy: 0.7115\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3006 - logit_loss: 0.3006 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8795 - output_accuracy: 0.7585 - val_loss: 0.5001 - val_logit_loss: 0.5001 - val_layer_1_accuracy: 0.0398 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8338 - val_output_accuracy: 0.7074\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2880 - logit_loss: 0.2880 - layer_1_accuracy: 0.0388 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8843 - output_accuracy: 0.7619 - val_loss: 0.4877 - val_logit_loss: 0.4877 - val_layer_1_accuracy: 0.0398 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8297 - val_output_accuracy: 0.7349\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2729 - logit_loss: 0.2729 - layer_1_accuracy: 0.0378 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8864 - output_accuracy: 0.7791 - val_loss: 0.5106 - val_logit_loss: 0.5106 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8352 - val_output_accuracy: 0.7445\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2598 - logit_loss: 0.2598 - layer_1_accuracy: 0.0376 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8952 - output_accuracy: 0.7868 - val_loss: 0.5065 - val_logit_loss: 0.5065 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8434 - val_output_accuracy: 0.7459\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2502 - logit_loss: 0.2502 - layer_1_accuracy: 0.0376 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8960 - output_accuracy: 0.7948 - val_loss: 0.5030 - val_logit_loss: 0.5030 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8448 - val_output_accuracy: 0.7555\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2396 - logit_loss: 0.2396 - layer_1_accuracy: 0.0376 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9032 - output_accuracy: 0.8007 - val_loss: 0.4924 - val_logit_loss: 0.4924 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8434 - val_output_accuracy: 0.7816\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2311 - logit_loss: 0.2311 - layer_1_accuracy: 0.0376 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9059 - output_accuracy: 0.8150 - val_loss: 0.4912 - val_logit_loss: 0.4912 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8489 - val_output_accuracy: 0.7871\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2225 - logit_loss: 0.2225 - layer_1_accuracy: 0.0388 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9124 - output_accuracy: 0.8221 - val_loss: 0.4989 - val_logit_loss: 0.4989 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8571 - val_output_accuracy: 0.8022\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2107 - logit_loss: 0.2107 - layer_1_accuracy: 0.0388 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9145 - output_accuracy: 0.8310 - val_loss: 0.5214 - val_logit_loss: 0.5214 - val_layer_1_accuracy: 0.0371 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8585 - val_output_accuracy: 0.7912\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2033 - logit_loss: 0.2033 - layer_1_accuracy: 0.0389 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9192 - output_accuracy: 0.8373 - val_loss: 0.5334 - val_logit_loss: 0.5334 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8668 - val_output_accuracy: 0.7885\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1914 - logit_loss: 0.1914 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9250 - output_accuracy: 0.8421 - val_loss: 0.5211 - val_logit_loss: 0.5211 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8668 - val_output_accuracy: 0.8008\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1824 - logit_loss: 0.1824 - layer_1_accuracy: 0.0391 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9292 - output_accuracy: 0.8477 - val_loss: 0.5028 - val_logit_loss: 0.5028 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8654 - val_output_accuracy: 0.8146\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1895 - logit_loss: 0.1895 - layer_1_accuracy: 0.0393 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9299 - output_accuracy: 0.8499 - val_loss: 0.5881 - val_logit_loss: 0.5881 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8681 - val_output_accuracy: 0.8049\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1780 - logit_loss: 0.1780 - layer_1_accuracy: 0.0393 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9391 - output_accuracy: 0.8580 - val_loss: 0.5305 - val_logit_loss: 0.5305 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8764 - val_output_accuracy: 0.8283\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1744 - logit_loss: 0.1744 - layer_1_accuracy: 0.0384 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9404 - output_accuracy: 0.8681 - val_loss: 0.5401 - val_logit_loss: 0.5401 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8764 - val_output_accuracy: 0.8324\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1717 - logit_loss: 0.1717 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9389 - output_accuracy: 0.8641 - val_loss: 0.5015 - val_logit_loss: 0.5015 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8874 - val_output_accuracy: 0.8310\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1591 - logit_loss: 0.1591 - layer_1_accuracy: 0.0384 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9462 - output_accuracy: 0.8771 - val_loss: 0.5614 - val_logit_loss: 0.5614 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8901 - val_output_accuracy: 0.8269\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1541 - logit_loss: 0.1541 - layer_1_accuracy: 0.0384 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9471 - output_accuracy: 0.8782 - val_loss: 0.5484 - val_logit_loss: 0.5484 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8942 - val_output_accuracy: 0.8338\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1488 - logit_loss: 0.1488 - layer_1_accuracy: 0.0393 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9506 - output_accuracy: 0.8782 - val_loss: 0.5287 - val_logit_loss: 0.5287 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8929 - val_output_accuracy: 0.8352\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1458 - logit_loss: 0.1458 - layer_1_accuracy: 0.0393 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9519 - output_accuracy: 0.8839 - val_loss: 0.5568 - val_logit_loss: 0.5568 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8970 - val_output_accuracy: 0.8324\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1401 - logit_loss: 0.1401 - layer_1_accuracy: 0.0393 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9542 - output_accuracy: 0.8908 - val_loss: 0.5542 - val_logit_loss: 0.5542 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8915 - val_output_accuracy: 0.8434\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1364 - logit_loss: 0.1364 - layer_1_accuracy: 0.0382 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9582 - output_accuracy: 0.8942 - val_loss: 0.5951 - val_logit_loss: 0.5951 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8915 - val_output_accuracy: 0.8352\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1337 - logit_loss: 0.1337 - layer_1_accuracy: 0.0389 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9576 - output_accuracy: 0.9002 - val_loss: 0.5832 - val_logit_loss: 0.5832 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9011 - val_output_accuracy: 0.8352\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1288 - logit_loss: 0.1288 - layer_1_accuracy: 0.0391 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9609 - output_accuracy: 0.9024 - val_loss: 0.5819 - val_logit_loss: 0.5819 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9011 - val_output_accuracy: 0.8434\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1282 - logit_loss: 0.1282 - layer_1_accuracy: 0.0388 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9605 - output_accuracy: 0.9034 - val_loss: 0.5574 - val_logit_loss: 0.5574 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8984 - val_output_accuracy: 0.8475\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1524 - logit_loss: 0.1524 - layer_1_accuracy: 0.0412 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9559 - output_accuracy: 0.9124 - val_loss: 0.6869 - val_logit_loss: 0.6869 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8791 - val_output_accuracy: 0.8681\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.2646 - logit_loss: 0.2646 - layer_1_accuracy: 0.0449 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9443 - output_accuracy: 0.8860 - val_loss: 0.5790 - val_logit_loss: 0.5790 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8956 - val_output_accuracy: 0.8338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x248819f89a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 55)]              0         \n",
      "                                                                 \n",
      " layer_1 (Dense)             (None, 64)                3584      \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " layer_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " logit (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      " output (Activation)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,857\n",
      "Trainable params: 9,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NN to ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "# convert the model to ONNX format\n",
    "onnx_net = onnxmltools.convert_keras(model)\n",
    "onnxmltools.utils.save_model(onnx_net, \"my_model.onnx\")\n",
    "content = onnx_net.SerializeToString()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def setup(onnx_file: str,):\n",
    "    # Load the ONNX model\n",
    "    ort_sess = ort.InferenceSession(onnx_file)\n",
    "    ortvalue = ort.OrtValue.ortvalue_from_numpy(X_train.astype(np.float32), 'cpu')\n",
    "    layer_output = ort_sess.run(['layer_1','layer_2','layer_3','logit'], {ort_sess.get_inputs()[0].name: ortvalue}) \n",
    "    neigh = []\n",
    "    for i in range(len(layer_output)):\n",
    "        neigh.append(NearestNeighbors().fit(layer_output[i]))\n",
    "    return  ort_sess, neigh\n",
    "\n",
    "ort_sess, neigh = setup('my_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m prediction, confidence\n\u001b[0;32m     47\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m---> 48\u001b[0m prediction, confidence \u001b[39m=\u001b[39m confidences(X_test, k, ort_sess, neigh, y_train, X_calibration, y_calibration)\n\u001b[0;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mprediction: \u001b[39m\u001b[39m\"\u001b[39m, prediction) \n\u001b[0;32m     50\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconfidence: \u001b[39m\u001b[39m\"\u001b[39m, confidence\u001b[39m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[38], line 42\u001b[0m, in \u001b[0;36mconfidences\u001b[1;34m(x, k, ort_sess, neigh, y_train, x_calibration, y_calibration)\u001b[0m\n\u001b[0;32m     40\u001b[0m prediction \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax([p_0, p_1], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     41\u001b[0m confidence \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(prediction))\n\u001b[1;32m---> 42\u001b[0m confidence[prediction \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m p_0[prediction \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m]\n\u001b[0;32m     43\u001b[0m confidence[prediction \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m p_1[prediction \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m prediction, confidence\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "def confidences(x, k, ort_sess, neigh, y_train, x_calibration, y_calibration):\n",
    "    ortvalue = ort.OrtValue.ortvalue_from_numpy(x.astype(np.float32), 'cpu')\n",
    "\n",
    "    # computer  layer_wise kNN for each sample\n",
    "    layer_output = ort_sess.run(['layer_1','layer_2','layer_3','logit'], {ort_sess.get_inputs()[0].name: ortvalue})\n",
    "    omega = []\n",
    "    for j in range(len(layer_output)):\n",
    "        index = neigh[j].kneighbors(layer_output[j], k, return_distance=False)\n",
    "        c = y_train[index]\n",
    "        omega.append(c)\n",
    "\n",
    "    # compute test input alpha\n",
    "    omega = np.array(omega)\n",
    "    omega = np.transpose(omega, (1, 0, 2))\n",
    "    alpha_0 = np.sum(omega, axis=2)\n",
    "    alpha_0 = np.sum(alpha_0, axis=1)\n",
    "    alpha_1 = len(layer_output) * k - alpha_0\n",
    "\n",
    "    # compute calibrations alpha\n",
    "    ortvalue = ort.OrtValue.ortvalue_from_numpy(x_calibration.astype(np.float32), 'cpu')\n",
    "    layer_output = ort_sess.run(['layer_1','layer_2','layer_3','logit'], {ort_sess.get_inputs()[0].name: ortvalue})\n",
    "    A_omega = []\n",
    "    for j in range(len(layer_output)):\n",
    "        index = neigh[j].kneighbors(layer_output[j], 5, return_distance=False)\n",
    "        c = y_train[index]\n",
    "        A_omega.append(c)\n",
    "\n",
    "    A_omega = np.array(A_omega)\n",
    "    A_omega = np.transpose(A_omega, (1, 0, 2))\n",
    "    c_alpha_0 = np.sum(A_omega, axis=2)\n",
    "    c_alpha_0 = np.sum(c_alpha_0, axis=1)\n",
    "    c_alpha_1 = len(layer_output) * k - c_alpha_0\n",
    "    alpha = np.zeros(len(y_calibration))\n",
    "    alpha[y_calibration==1] = c_alpha_1[y_calibration==1]\n",
    "\n",
    "    # compute confidence\n",
    "    p_0 = [sum(alpha > i)/len(alpha) for i in alpha_0]\n",
    "    p_1 = [sum(alpha > i)/len(alpha) for i in alpha_1]\n",
    "    p = np.array([p_0, p_1])\n",
    "    prediction = np.argmax([p_0, p_1], axis=0)\n",
    "    confidence = np.zeros(len(prediction))\n",
    "    confidence[prediction == 0] = 1 - p_0[prediction == 0]\n",
    "    confidence[prediction == 1] = 1 - p_1[prediction == 1]\n",
    "\n",
    "    return prediction, confidence\n",
    "\n",
    "k = 5\n",
    "prediction, confidence = confidences(X_test, k, ort_sess, neigh, y_train, X_calibration, y_calibration)\n",
    "print(\"prediction: \", prediction) \n",
    "print(\"confidence: \", confidence.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a46493ef273555f0fac6598162cd73ee5d8ec19f64a4bbbda3cc3aa05bc0ca3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
