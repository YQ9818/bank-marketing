{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>...</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171429</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414286</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.389322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  default  housing  loan  campaign  pdays  previous  poutcome  \\\n",
       "0  0.171429        1       -1     1  0.029412    1.0       0.0         0   \n",
       "1  0.300000        1        1     1  0.088235    1.0       0.0         0   \n",
       "2  0.100000        1       -1     1  0.000000    1.0       0.0         0   \n",
       "3  0.285714        1        0     0  0.058824    1.0       0.0         0   \n",
       "4  0.414286        1       -1     1  0.000000    1.0       0.0         0   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  ...  month_mar  month_may  month_nov  \\\n",
       "0      0.333333        0.269680  ...          0          1          0   \n",
       "1      0.937500        0.698753  ...          0          1          0   \n",
       "2      1.000000        0.882307  ...          0          0          0   \n",
       "3      1.000000        0.882307  ...          0          0          0   \n",
       "4      0.687500        0.389322  ...          0          0          1   \n",
       "\n",
       "   month_oct  month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0          0          0                1                0                0   \n",
       "1          0          0                1                0                0   \n",
       "2          0          0                0                0                0   \n",
       "3          0          0                1                0                0   \n",
       "4          0          0                0                1                0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                1  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"..\\..\\Data\\small_ohe.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'default', 'housing', 'loan', 'campaign', 'pdays', 'previous',\n",
       "       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
       "       'euribor3m', 'nr.employed', 'y', 'pdays2', 'job_admin.',\n",
       "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
       "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'contact_cellular', 'contact_telephone',\n",
       "       'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'day_of_week_fri', 'day_of_week_mon', 'day_of_week_thu',\n",
       "       'day_of_week_tue', 'day_of_week_wed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saperating features and result vectors\n",
    "X = data.drop('y', axis=1).values\n",
    "y = data['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define no sequence of layers\n",
    "input_tensor = tf.keras.Input(shape=(55,))\n",
    "layer1 = tf.keras.layers.Dense(64,name = 'layer_1', activation='relu',use_bias=True)(input_tensor)\n",
    "layer2 = tf.keras.layers.Dense(64,name = 'layer_2', activation='relu',use_bias=True)(layer1)\n",
    "layer3 = tf.keras.layers.Dense(32,name = 'layer_3', activation='relu',use_bias=True)(layer2)\n",
    "layer4 = tf.keras.layers.Dense(1, name = 'logit', activation=None,use_bias=True)(layer3)\n",
    "output_tensor = tf.keras.layers.Activation('sigmoid', name='output')(layer4)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=[layer1,layer2,layer3,layer4,output_tensor]) \n",
    "losses = {'logit': 'BinaryCrossentropy'}\n",
    "model.compile(loss=losses, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 2.2339 - logit_loss: 2.2339 - layer_1_accuracy: 0.0285 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.2256 - logit_accuracy: 0.4999 - output_accuracy: 0.4856 - val_loss: 0.7027 - val_logit_loss: 0.7027 - val_layer_1_accuracy: 0.0399 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.2300 - val_logit_accuracy: 0.5341 - val_output_accuracy: 0.4961\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6554 - logit_loss: 0.6554 - layer_1_accuracy: 0.0363 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.2297 - logit_accuracy: 0.6089 - output_accuracy: 0.4958 - val_loss: 0.6073 - val_logit_loss: 0.6073 - val_layer_1_accuracy: 0.0472 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.2052 - val_logit_accuracy: 0.6876 - val_output_accuracy: 0.4961\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6074 - logit_loss: 0.6074 - layer_1_accuracy: 0.0418 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.2172 - logit_accuracy: 0.7053 - output_accuracy: 0.4958 - val_loss: 0.5756 - val_logit_loss: 0.5756 - val_layer_1_accuracy: 0.0518 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1951 - val_logit_accuracy: 0.7256 - val_output_accuracy: 0.4961\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5792 - logit_loss: 0.5792 - layer_1_accuracy: 0.0414 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.2303 - logit_accuracy: 0.7190 - output_accuracy: 0.4958 - val_loss: 0.5567 - val_logit_loss: 0.5567 - val_layer_1_accuracy: 0.0513 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.2162 - val_logit_accuracy: 0.7320 - val_output_accuracy: 0.4961\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5425 - logit_loss: 0.5425 - layer_1_accuracy: 0.0469 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.2238 - logit_accuracy: 0.7463 - output_accuracy: 0.4958 - val_loss: 0.5576 - val_logit_loss: 0.5576 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1988 - val_logit_accuracy: 0.7499 - val_output_accuracy: 0.4961\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5309 - logit_loss: 0.5309 - layer_1_accuracy: 0.0514 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1914 - logit_accuracy: 0.7424 - output_accuracy: 0.5001 - val_loss: 0.5447 - val_logit_loss: 0.5447 - val_layer_1_accuracy: 0.0541 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1608 - val_logit_accuracy: 0.7462 - val_output_accuracy: 0.4966\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5197 - logit_loss: 0.5197 - layer_1_accuracy: 0.0475 - layer_2_accuracy: 5.8904e-04 - layer_3_accuracy: 0.1694 - logit_accuracy: 0.7497 - output_accuracy: 0.4985 - val_loss: 0.5351 - val_logit_loss: 0.5351 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0018 - val_layer_3_accuracy: 0.1351 - val_logit_accuracy: 0.7554 - val_output_accuracy: 0.5062\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4942 - logit_loss: 0.4942 - layer_1_accuracy: 0.0499 - layer_2_accuracy: 3.9270e-04 - layer_3_accuracy: 0.1649 - logit_accuracy: 0.7554 - output_accuracy: 0.5225 - val_loss: 0.5068 - val_logit_loss: 0.5068 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1631 - val_logit_accuracy: 0.7645 - val_output_accuracy: 0.5153\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4808 - logit_loss: 0.4808 - layer_1_accuracy: 0.0471 - layer_2_accuracy: 3.9270e-04 - layer_3_accuracy: 0.1728 - logit_accuracy: 0.7612 - output_accuracy: 0.5266 - val_loss: 0.5417 - val_logit_loss: 0.5417 - val_layer_1_accuracy: 0.0531 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1530 - val_logit_accuracy: 0.7618 - val_output_accuracy: 0.5268\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4583 - logit_loss: 0.4583 - layer_1_accuracy: 0.0473 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1761 - logit_accuracy: 0.7758 - output_accuracy: 0.5574 - val_loss: 0.4901 - val_logit_loss: 0.4901 - val_layer_1_accuracy: 0.0518 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1805 - val_logit_accuracy: 0.7696 - val_output_accuracy: 0.5561\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4384 - logit_loss: 0.4384 - layer_1_accuracy: 0.0436 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1924 - logit_accuracy: 0.7846 - output_accuracy: 0.5765 - val_loss: 0.4817 - val_logit_loss: 0.4817 - val_layer_1_accuracy: 0.0531 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1768 - val_logit_accuracy: 0.7824 - val_output_accuracy: 0.5731\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4139 - logit_loss: 0.4139 - layer_1_accuracy: 0.0424 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1854 - logit_accuracy: 0.7964 - output_accuracy: 0.5981 - val_loss: 0.4751 - val_logit_loss: 0.4751 - val_layer_1_accuracy: 0.0467 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1530 - val_logit_accuracy: 0.7929 - val_output_accuracy: 0.5520\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3988 - logit_loss: 0.3988 - layer_1_accuracy: 0.0406 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1696 - logit_accuracy: 0.8046 - output_accuracy: 0.6142 - val_loss: 0.4850 - val_logit_loss: 0.4850 - val_layer_1_accuracy: 0.0486 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1695 - val_logit_accuracy: 0.7884 - val_output_accuracy: 0.5644\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3771 - logit_loss: 0.3771 - layer_1_accuracy: 0.0404 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1802 - logit_accuracy: 0.8178 - output_accuracy: 0.6375 - val_loss: 0.4473 - val_logit_loss: 0.4473 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1548 - val_logit_accuracy: 0.8090 - val_output_accuracy: 0.6161\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3521 - logit_loss: 0.3521 - layer_1_accuracy: 0.0414 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1683 - logit_accuracy: 0.8315 - output_accuracy: 0.6672 - val_loss: 0.4421 - val_logit_loss: 0.4421 - val_layer_1_accuracy: 0.0527 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1475 - val_logit_accuracy: 0.8140 - val_output_accuracy: 0.6770\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3360 - logit_loss: 0.3360 - layer_1_accuracy: 0.0442 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1679 - logit_accuracy: 0.8417 - output_accuracy: 0.6837 - val_loss: 0.4092 - val_logit_loss: 0.4092 - val_layer_1_accuracy: 0.0559 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1379 - val_logit_accuracy: 0.8131 - val_output_accuracy: 0.6858\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5360 - logit_loss: 0.5360 - layer_1_accuracy: 0.0491 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1569 - logit_accuracy: 0.7907 - output_accuracy: 0.6381 - val_loss: 0.5248 - val_logit_loss: 0.5248 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1136 - val_logit_accuracy: 0.7746 - val_output_accuracy: 0.5896\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4105 - logit_loss: 0.4105 - layer_1_accuracy: 0.0471 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1304 - logit_accuracy: 0.8145 - output_accuracy: 0.6379 - val_loss: 0.4406 - val_logit_loss: 0.4406 - val_layer_1_accuracy: 0.0518 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1168 - val_logit_accuracy: 0.7966 - val_output_accuracy: 0.6661\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3476 - logit_loss: 0.3476 - layer_1_accuracy: 0.0454 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1312 - logit_accuracy: 0.8474 - output_accuracy: 0.6829 - val_loss: 0.4260 - val_logit_loss: 0.4260 - val_layer_1_accuracy: 0.0541 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1209 - val_logit_accuracy: 0.8140 - val_output_accuracy: 0.6899\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3304 - logit_loss: 0.3304 - layer_1_accuracy: 0.0491 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1355 - logit_accuracy: 0.8555 - output_accuracy: 0.7041 - val_loss: 0.4150 - val_logit_loss: 0.4150 - val_layer_1_accuracy: 0.0582 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1031 - val_logit_accuracy: 0.8168 - val_output_accuracy: 0.6908\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3103 - logit_loss: 0.3103 - layer_1_accuracy: 0.0479 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1208 - logit_accuracy: 0.8639 - output_accuracy: 0.7200 - val_loss: 0.4284 - val_logit_loss: 0.4284 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1273 - val_logit_accuracy: 0.8388 - val_output_accuracy: 0.7091\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2819 - logit_loss: 0.2819 - layer_1_accuracy: 0.0487 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1498 - logit_accuracy: 0.8810 - output_accuracy: 0.7402 - val_loss: 0.4119 - val_logit_loss: 0.4119 - val_layer_1_accuracy: 0.0541 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1388 - val_logit_accuracy: 0.8525 - val_output_accuracy: 0.7164\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2636 - logit_loss: 0.2636 - layer_1_accuracy: 0.0471 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1508 - logit_accuracy: 0.8897 - output_accuracy: 0.7554 - val_loss: 0.4296 - val_logit_loss: 0.4296 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1351 - val_logit_accuracy: 0.8575 - val_output_accuracy: 0.7320\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2455 - logit_loss: 0.2455 - layer_1_accuracy: 0.0483 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1488 - logit_accuracy: 0.9030 - output_accuracy: 0.7667 - val_loss: 0.4228 - val_logit_loss: 0.4228 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1319 - val_logit_accuracy: 0.8676 - val_output_accuracy: 0.7494\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2332 - logit_loss: 0.2332 - layer_1_accuracy: 0.0485 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1429 - logit_accuracy: 0.9140 - output_accuracy: 0.7846 - val_loss: 0.4118 - val_logit_loss: 0.4118 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1319 - val_logit_accuracy: 0.8855 - val_output_accuracy: 0.7655\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2419 - logit_loss: 0.2419 - layer_1_accuracy: 0.0507 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1522 - logit_accuracy: 0.9148 - output_accuracy: 0.8031 - val_loss: 1.2484 - val_logit_loss: 1.2484 - val_layer_1_accuracy: 0.0655 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0967 - val_logit_accuracy: 0.7476 - val_output_accuracy: 0.8204\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6403 - logit_loss: 0.6403 - layer_1_accuracy: 0.0705 - layer_2_accuracy: 5.8904e-04 - layer_3_accuracy: 0.1885 - logit_accuracy: 0.7797 - output_accuracy: 0.6760 - val_loss: 0.6284 - val_logit_loss: 0.6284 - val_layer_1_accuracy: 0.0710 - val_layer_2_accuracy: 0.0027 - val_layer_3_accuracy: 0.1901 - val_logit_accuracy: 0.7604 - val_output_accuracy: 0.7174\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4159 - logit_loss: 0.4159 - layer_1_accuracy: 0.0613 - layer_2_accuracy: 0.0012 - layer_3_accuracy: 0.2474 - logit_accuracy: 0.8339 - output_accuracy: 0.6762 - val_loss: 0.4543 - val_logit_loss: 0.4543 - val_layer_1_accuracy: 0.0650 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.2103 - val_logit_accuracy: 0.8383 - val_output_accuracy: 0.6871\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3219 - logit_loss: 0.3219 - layer_1_accuracy: 0.0567 - layer_2_accuracy: 0.0012 - layer_3_accuracy: 0.2001 - logit_accuracy: 0.8747 - output_accuracy: 0.7314 - val_loss: 0.4388 - val_logit_loss: 0.4388 - val_layer_1_accuracy: 0.0614 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.1704 - val_logit_accuracy: 0.8607 - val_output_accuracy: 0.7476\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2819 - logit_loss: 0.2819 - layer_1_accuracy: 0.0532 - layer_2_accuracy: 9.8174e-04 - layer_3_accuracy: 0.1799 - logit_accuracy: 0.8936 - output_accuracy: 0.7746 - val_loss: 0.3813 - val_logit_loss: 0.3813 - val_layer_1_accuracy: 0.0586 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.1690 - val_logit_accuracy: 0.8511 - val_output_accuracy: 0.7810\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2882 - logit_loss: 0.2882 - layer_1_accuracy: 0.0560 - layer_2_accuracy: 0.0012 - layer_3_accuracy: 0.1846 - logit_accuracy: 0.8916 - output_accuracy: 0.7789 - val_loss: 0.4563 - val_logit_loss: 0.4563 - val_layer_1_accuracy: 0.0568 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.1645 - val_logit_accuracy: 0.8763 - val_output_accuracy: 0.7462\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2401 - logit_loss: 0.2401 - layer_1_accuracy: 0.0522 - layer_2_accuracy: 0.0012 - layer_3_accuracy: 0.1563 - logit_accuracy: 0.9183 - output_accuracy: 0.8058 - val_loss: 0.4079 - val_logit_loss: 0.4079 - val_layer_1_accuracy: 0.0586 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.1438 - val_logit_accuracy: 0.8846 - val_output_accuracy: 0.7916\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2225 - logit_loss: 0.2225 - layer_1_accuracy: 0.0544 - layer_2_accuracy: 0.0012 - layer_3_accuracy: 0.1549 - logit_accuracy: 0.9266 - output_accuracy: 0.8198 - val_loss: 0.4465 - val_logit_loss: 0.4465 - val_layer_1_accuracy: 0.0563 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.1402 - val_logit_accuracy: 0.8859 - val_output_accuracy: 0.7957\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2087 - logit_loss: 0.2087 - layer_1_accuracy: 0.0518 - layer_2_accuracy: 0.0012 - layer_3_accuracy: 0.1539 - logit_accuracy: 0.9321 - output_accuracy: 0.8307 - val_loss: 0.4494 - val_logit_loss: 0.4494 - val_layer_1_accuracy: 0.0568 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.1429 - val_logit_accuracy: 0.8956 - val_output_accuracy: 0.7874\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1999 - logit_loss: 0.1999 - layer_1_accuracy: 0.0501 - layer_2_accuracy: 3.9270e-04 - layer_3_accuracy: 0.1539 - logit_accuracy: 0.9403 - output_accuracy: 0.8376 - val_loss: 0.4256 - val_logit_loss: 0.4256 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 9.1617e-04 - val_layer_3_accuracy: 0.1342 - val_logit_accuracy: 0.8919 - val_output_accuracy: 0.8172\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1899 - logit_loss: 0.1899 - layer_1_accuracy: 0.0512 - layer_2_accuracy: 1.9635e-04 - layer_3_accuracy: 0.1561 - logit_accuracy: 0.9433 - output_accuracy: 0.8502 - val_loss: 0.4035 - val_logit_loss: 0.4035 - val_layer_1_accuracy: 0.0550 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1315 - val_logit_accuracy: 0.8978 - val_output_accuracy: 0.8218\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1969 - logit_loss: 0.1969 - layer_1_accuracy: 0.0503 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1610 - logit_accuracy: 0.9450 - output_accuracy: 0.8531 - val_loss: 0.4530 - val_logit_loss: 0.4530 - val_layer_1_accuracy: 0.0504 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1425 - val_logit_accuracy: 0.8974 - val_output_accuracy: 0.8191\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1841 - logit_loss: 0.1841 - layer_1_accuracy: 0.0483 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1596 - logit_accuracy: 0.9501 - output_accuracy: 0.8590 - val_loss: 0.4431 - val_logit_loss: 0.4431 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1448 - val_logit_accuracy: 0.8951 - val_output_accuracy: 0.8085\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1664 - logit_loss: 0.1664 - layer_1_accuracy: 0.0481 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1569 - logit_accuracy: 0.9513 - output_accuracy: 0.8708 - val_loss: 0.3771 - val_logit_loss: 0.3771 - val_layer_1_accuracy: 0.0490 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1415 - val_logit_accuracy: 0.9111 - val_output_accuracy: 0.8415\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1654 - logit_loss: 0.1654 - layer_1_accuracy: 0.0485 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1608 - logit_accuracy: 0.9548 - output_accuracy: 0.8751 - val_loss: 0.4273 - val_logit_loss: 0.4273 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1411 - val_logit_accuracy: 0.9111 - val_output_accuracy: 0.8314\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1706 - logit_loss: 0.1706 - layer_1_accuracy: 0.0507 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1590 - logit_accuracy: 0.9554 - output_accuracy: 0.8804 - val_loss: 0.4175 - val_logit_loss: 0.4175 - val_layer_1_accuracy: 0.0481 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1521 - val_logit_accuracy: 0.9208 - val_output_accuracy: 0.8410\n",
      "Epoch 42/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1766 - logit_loss: 0.1766 - layer_1_accuracy: 0.0471 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1581 - logit_accuracy: 0.9594 - output_accuracy: 0.8808 - val_loss: 0.4145 - val_logit_loss: 0.4145 - val_layer_1_accuracy: 0.0504 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1470 - val_logit_accuracy: 0.9175 - val_output_accuracy: 0.8443\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1763 - logit_loss: 0.1763 - layer_1_accuracy: 0.0467 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1600 - logit_accuracy: 0.9584 - output_accuracy: 0.8920 - val_loss: 0.4243 - val_logit_loss: 0.4243 - val_layer_1_accuracy: 0.0467 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1374 - val_logit_accuracy: 0.9052 - val_output_accuracy: 0.8314\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3865 - logit_loss: 0.3865 - layer_1_accuracy: 0.0454 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.0968 - logit_accuracy: 0.9169 - output_accuracy: 0.8258 - val_loss: 0.5786 - val_logit_loss: 0.5786 - val_layer_1_accuracy: 0.0463 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0985 - val_logit_accuracy: 0.8827 - val_output_accuracy: 0.7755\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2835 - logit_loss: 0.2835 - layer_1_accuracy: 0.0404 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1115 - logit_accuracy: 0.9462 - output_accuracy: 0.8604 - val_loss: 0.4771 - val_logit_loss: 0.4771 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0989 - val_logit_accuracy: 0.9061 - val_output_accuracy: 0.8557\n",
      "Epoch 46/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2525 - logit_loss: 0.2525 - layer_1_accuracy: 0.0418 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1219 - logit_accuracy: 0.9564 - output_accuracy: 0.8893 - val_loss: 0.5501 - val_logit_loss: 0.5501 - val_layer_1_accuracy: 0.0463 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1223 - val_logit_accuracy: 0.9043 - val_output_accuracy: 0.8287\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4047 - logit_loss: 0.4047 - layer_1_accuracy: 0.0509 - layer_2_accuracy: 1.9635e-04 - layer_3_accuracy: 0.1380 - logit_accuracy: 0.9238 - output_accuracy: 0.8692 - val_loss: 1.3376 - val_logit_loss: 1.3376 - val_layer_1_accuracy: 0.0554 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.0747 - val_logit_accuracy: 0.8213 - val_output_accuracy: 0.8424\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.4465 - logit_loss: 1.4465 - layer_1_accuracy: 0.0695 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1905 - logit_accuracy: 0.7775 - output_accuracy: 0.7243 - val_loss: 0.8345 - val_logit_loss: 0.8345 - val_layer_1_accuracy: 0.0976 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1562 - val_logit_accuracy: 0.7751 - val_output_accuracy: 0.6725\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6895 - logit_loss: 0.6895 - layer_1_accuracy: 0.0687 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1353 - logit_accuracy: 0.7781 - output_accuracy: 0.6639 - val_loss: 0.5892 - val_logit_loss: 0.5892 - val_layer_1_accuracy: 0.0623 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1842 - val_logit_accuracy: 0.7870 - val_output_accuracy: 0.5818\n",
      "Epoch 50/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4608 - logit_loss: 0.4608 - layer_1_accuracy: 0.0542 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1508 - logit_accuracy: 0.8207 - output_accuracy: 0.6666 - val_loss: 0.5306 - val_logit_loss: 0.5306 - val_layer_1_accuracy: 0.0541 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1576 - val_logit_accuracy: 0.8246 - val_output_accuracy: 0.6491\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3919 - logit_loss: 0.3919 - layer_1_accuracy: 0.0432 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1504 - logit_accuracy: 0.8622 - output_accuracy: 0.7273 - val_loss: 0.4914 - val_logit_loss: 0.4914 - val_layer_1_accuracy: 0.0454 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1443 - val_logit_accuracy: 0.8420 - val_output_accuracy: 0.7316\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3335 - logit_loss: 0.3335 - layer_1_accuracy: 0.0389 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1406 - logit_accuracy: 0.8847 - output_accuracy: 0.7656 - val_loss: 0.4781 - val_logit_loss: 0.4781 - val_layer_1_accuracy: 0.0431 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1324 - val_logit_accuracy: 0.8571 - val_output_accuracy: 0.7508\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3699 - logit_loss: 0.3699 - layer_1_accuracy: 0.0353 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1720 - logit_accuracy: 0.8582 - output_accuracy: 0.7184 - val_loss: 0.4588 - val_logit_loss: 0.4588 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1741 - val_logit_accuracy: 0.8479 - val_output_accuracy: 0.7142\n",
      "Epoch 54/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2920 - logit_loss: 0.2920 - layer_1_accuracy: 0.0395 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1706 - logit_accuracy: 0.8908 - output_accuracy: 0.7716 - val_loss: 0.4192 - val_logit_loss: 0.4192 - val_layer_1_accuracy: 0.0444 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1434 - val_logit_accuracy: 0.8644 - val_output_accuracy: 0.7664\n",
      "Epoch 55/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2631 - logit_loss: 0.2631 - layer_1_accuracy: 0.0424 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1541 - logit_accuracy: 0.9012 - output_accuracy: 0.8009 - val_loss: 0.4135 - val_logit_loss: 0.4135 - val_layer_1_accuracy: 0.0486 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1429 - val_logit_accuracy: 0.8759 - val_output_accuracy: 0.7714\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2426 - logit_loss: 0.2426 - layer_1_accuracy: 0.0442 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1408 - logit_accuracy: 0.9171 - output_accuracy: 0.8209 - val_loss: 0.3989 - val_logit_loss: 0.3989 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1319 - val_logit_accuracy: 0.8800 - val_output_accuracy: 0.7902\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2292 - logit_loss: 0.2292 - layer_1_accuracy: 0.0461 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1329 - logit_accuracy: 0.9236 - output_accuracy: 0.8317 - val_loss: 0.3793 - val_logit_loss: 0.3793 - val_layer_1_accuracy: 0.0495 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1324 - val_logit_accuracy: 0.8905 - val_output_accuracy: 0.7957\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2148 - logit_loss: 0.2148 - layer_1_accuracy: 0.0450 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1290 - logit_accuracy: 0.9338 - output_accuracy: 0.8439 - val_loss: 0.3762 - val_logit_loss: 0.3762 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1301 - val_logit_accuracy: 0.8910 - val_output_accuracy: 0.8136\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2053 - logit_loss: 0.2053 - layer_1_accuracy: 0.0450 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1245 - logit_accuracy: 0.9376 - output_accuracy: 0.8535 - val_loss: 0.3762 - val_logit_loss: 0.3762 - val_layer_1_accuracy: 0.0513 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1296 - val_logit_accuracy: 0.9033 - val_output_accuracy: 0.8085\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1934 - logit_loss: 0.1934 - layer_1_accuracy: 0.0483 - layer_2_accuracy: 0.0000e+00 - layer_3_accuracy: 0.1249 - logit_accuracy: 0.9433 - output_accuracy: 0.8618 - val_loss: 0.3515 - val_logit_loss: 0.3515 - val_layer_1_accuracy: 0.0527 - val_layer_2_accuracy: 0.0000e+00 - val_layer_3_accuracy: 0.1168 - val_logit_accuracy: 0.9116 - val_output_accuracy: 0.8273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7a0a399a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=60, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 55)]              0         \n",
      "                                                                 \n",
      " layer_1 (Dense)             (None, 64)                3584      \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " layer_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " logit (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      " output (Activation)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,857\n",
      "Trainable params: 9,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NN to ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "# convert the model to ONNX format\n",
    "onnx_net = onnxmltools.convert_keras(model)\n",
    "onnxmltools.utils.save_model(onnx_net, \"my_model.onnx\")\n",
    "content = onnx_net.SerializeToString()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def setup(onnx_file: str,):\n",
    "    # Load the ONNX model\n",
    "    ort_sess = ort.InferenceSession(onnx_file)\n",
    "    ortvalue = ort.OrtValue.ortvalue_from_numpy(X_train.astype(np.float32), 'cpu')\n",
    "    logits = ort_sess.run(['logit'], {ort_sess.get_inputs()[0].name: ortvalue})\n",
    "    outputs = ort_sess.run(['output'], {ort_sess.get_inputs()[0].name: ortvalue})\n",
    "    x_0 = X_train[y_train == 0].astype(np.float32)\n",
    "    x_1 = X_train[y_train == 1].astype(np.float32)\n",
    "\n",
    "    # get predictions for each class with positive true label   \n",
    "    pred_0 = ort_sess.run(['output'], {ort_sess.get_inputs()[0].name: x_0})[0][:,0]\n",
    "    x_0 = x_0[pred_0 < 0.5]\n",
    "    pred_1 = ort_sess.run(['output'], {ort_sess.get_inputs()[0].name: x_1})[0][:,0]\n",
    "    x_1 = x_1[pred_1 > 0.5]\n",
    "\n",
    "    logits_0_correct = ort_sess.run(['logit'], {ort_sess.get_inputs()[0].name: x_0})[0]\n",
    "    logits_1_correct = ort_sess.run(['logit'], {ort_sess.get_inputs()[0].name: x_1})[0]\n",
    "    # fit GMM to class conditional distributions\n",
    "    gmm_0 = GaussianMixture(n_components=2, random_state=0).fit(logits_0_correct)\n",
    "    gmm_1 = GaussianMixture(n_components=2, random_state=0).fit(logits_1_correct)\n",
    "    gmm_0.predict(x_0)\n",
    "    return  gmm_0.predict(x_0)\n",
    "\n",
    "setup('my_model.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a46493ef273555f0fac6598162cd73ee5d8ec19f64a4bbbda3cc3aa05bc0ca3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
