{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>...</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171429</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414286</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.389322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  default  housing  loan  campaign  pdays  previous  poutcome  \\\n",
       "0  0.171429        1       -1     1  0.029412    1.0       0.0         0   \n",
       "1  0.300000        1        1     1  0.088235    1.0       0.0         0   \n",
       "2  0.100000        1       -1     1  0.000000    1.0       0.0         0   \n",
       "3  0.285714        1        0     0  0.058824    1.0       0.0         0   \n",
       "4  0.414286        1       -1     1  0.000000    1.0       0.0         0   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  ...  month_mar  month_may  month_nov  \\\n",
       "0      0.333333        0.269680  ...          0          1          0   \n",
       "1      0.937500        0.698753  ...          0          1          0   \n",
       "2      1.000000        0.882307  ...          0          0          0   \n",
       "3      1.000000        0.882307  ...          0          0          0   \n",
       "4      0.687500        0.389322  ...          0          0          1   \n",
       "\n",
       "   month_oct  month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0          0          0                1                0                0   \n",
       "1          0          0                1                0                0   \n",
       "2          0          0                0                0                0   \n",
       "3          0          0                1                0                0   \n",
       "4          0          0                0                1                0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                1  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"..\\..\\Data\\small_ohe.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'default', 'housing', 'loan', 'campaign', 'pdays', 'previous',\n",
       "       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
       "       'euribor3m', 'nr.employed', 'y', 'pdays2', 'job_admin.',\n",
       "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_basic.4y', 'education_basic.6y',\n",
       "       'education_basic.9y', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'contact_cellular', 'contact_telephone',\n",
       "       'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'day_of_week_fri', 'day_of_week_mon', 'day_of_week_thu',\n",
       "       'day_of_week_tue', 'day_of_week_wed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saperating features and result vectors\n",
    "X = data.drop('y', axis=1).values\n",
    "y = data['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define no sequence of layers\n",
    "input_tensor = tf.keras.Input(shape=(55,))\n",
    "layer1 = tf.keras.layers.Dense(64,name = 'layer_1', activation='relu',use_bias=True)(input_tensor)\n",
    "layer2 = tf.keras.layers.Dense(64,name = 'layer_2', activation='relu',use_bias=True)(layer1)\n",
    "layer3 = tf.keras.layers.Dense(32,name = 'layer_3', activation='relu',use_bias=True)(layer2)\n",
    "layer4 = tf.keras.layers.Dense(1, name = 'logit', activation=None,use_bias=True)(layer3)\n",
    "output_tensor = tf.keras.layers.Activation('sigmoid', name='output')(layer4)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=[layer1,layer2,layer3,layer4,output_tensor]) \n",
    "losses = {'logit': 'BinaryCrossentropy'}\n",
    "model.compile(loss=losses, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 0.7385 - logit_loss: 0.7385 - layer_1_accuracy: 0.0079 - layer_2_accuracy: 0.0183 - layer_3_accuracy: 0.1088 - logit_accuracy: 0.5875 - output_accuracy: 0.4954 - val_loss: 0.5775 - val_logit_loss: 0.5775 - val_layer_1_accuracy: 0.0156 - val_layer_2_accuracy: 0.0041 - val_layer_3_accuracy: 0.0934 - val_logit_accuracy: 0.7348 - val_output_accuracy: 0.4961\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5924 - logit_loss: 0.5924 - layer_1_accuracy: 0.0110 - layer_2_accuracy: 0.0069 - layer_3_accuracy: 0.0966 - logit_accuracy: 0.7251 - output_accuracy: 0.4962 - val_loss: 0.5399 - val_logit_loss: 0.5399 - val_layer_1_accuracy: 0.0188 - val_layer_2_accuracy: 0.0032 - val_layer_3_accuracy: 0.1095 - val_logit_accuracy: 0.7444 - val_output_accuracy: 0.4970\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5600 - logit_loss: 0.5600 - layer_1_accuracy: 0.0114 - layer_2_accuracy: 0.0084 - layer_3_accuracy: 0.1172 - logit_accuracy: 0.7391 - output_accuracy: 0.4962 - val_loss: 0.5181 - val_logit_loss: 0.5181 - val_layer_1_accuracy: 0.0165 - val_layer_2_accuracy: 0.0087 - val_layer_3_accuracy: 0.0934 - val_logit_accuracy: 0.7453 - val_output_accuracy: 0.4970\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5234 - logit_loss: 0.5234 - layer_1_accuracy: 0.0122 - layer_2_accuracy: 0.0116 - layer_3_accuracy: 0.1149 - logit_accuracy: 0.7514 - output_accuracy: 0.4981 - val_loss: 0.5165 - val_logit_loss: 0.5165 - val_layer_1_accuracy: 0.0206 - val_layer_2_accuracy: 0.0060 - val_layer_3_accuracy: 0.1480 - val_logit_accuracy: 0.7568 - val_output_accuracy: 0.5011\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5348 - logit_loss: 0.5348 - layer_1_accuracy: 0.0332 - layer_2_accuracy: 0.0037 - layer_3_accuracy: 0.0840 - logit_accuracy: 0.7349 - output_accuracy: 0.5021 - val_loss: 0.5081 - val_logit_loss: 0.5081 - val_layer_1_accuracy: 0.0389 - val_layer_2_accuracy: 0.0023 - val_layer_3_accuracy: 0.0541 - val_logit_accuracy: 0.7476 - val_output_accuracy: 0.5030\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4959 - logit_loss: 0.4959 - layer_1_accuracy: 0.0434 - layer_2_accuracy: 0.0020 - layer_3_accuracy: 0.0617 - logit_accuracy: 0.7526 - output_accuracy: 0.5131 - val_loss: 0.5083 - val_logit_loss: 0.5083 - val_layer_1_accuracy: 0.0417 - val_layer_2_accuracy: 0.0023 - val_layer_3_accuracy: 0.0783 - val_logit_accuracy: 0.7613 - val_output_accuracy: 0.5259\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4587 - logit_loss: 0.4587 - layer_1_accuracy: 0.0418 - layer_2_accuracy: 0.0020 - layer_3_accuracy: 0.0732 - logit_accuracy: 0.7699 - output_accuracy: 0.5299 - val_loss: 0.4910 - val_logit_loss: 0.4910 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0018 - val_layer_3_accuracy: 0.0811 - val_logit_accuracy: 0.7655 - val_output_accuracy: 0.5383\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4360 - logit_loss: 0.4360 - layer_1_accuracy: 0.0428 - layer_2_accuracy: 0.0029 - layer_3_accuracy: 0.0730 - logit_accuracy: 0.7811 - output_accuracy: 0.5502 - val_loss: 0.4795 - val_logit_loss: 0.4795 - val_layer_1_accuracy: 0.0417 - val_layer_2_accuracy: 0.0018 - val_layer_3_accuracy: 0.0820 - val_logit_accuracy: 0.7737 - val_output_accuracy: 0.5479\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4157 - logit_loss: 0.4157 - layer_1_accuracy: 0.0456 - layer_2_accuracy: 0.0027 - layer_3_accuracy: 0.0785 - logit_accuracy: 0.7870 - output_accuracy: 0.5720 - val_loss: 0.4733 - val_logit_loss: 0.4733 - val_layer_1_accuracy: 0.0504 - val_layer_2_accuracy: 0.0018 - val_layer_3_accuracy: 0.0999 - val_logit_accuracy: 0.7641 - val_output_accuracy: 0.5657\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3881 - logit_loss: 0.3881 - layer_1_accuracy: 0.0475 - layer_2_accuracy: 0.0057 - layer_3_accuracy: 0.0964 - logit_accuracy: 0.8001 - output_accuracy: 0.5987 - val_loss: 0.4486 - val_logit_loss: 0.4486 - val_layer_1_accuracy: 0.0472 - val_layer_2_accuracy: 0.0055 - val_layer_3_accuracy: 0.0985 - val_logit_accuracy: 0.7833 - val_output_accuracy: 0.6271\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3514 - logit_loss: 0.3514 - layer_1_accuracy: 0.0491 - layer_2_accuracy: 0.0045 - layer_3_accuracy: 0.0986 - logit_accuracy: 0.8258 - output_accuracy: 0.6348 - val_loss: 0.4698 - val_logit_loss: 0.4698 - val_layer_1_accuracy: 0.0472 - val_layer_2_accuracy: 0.0041 - val_layer_3_accuracy: 0.1081 - val_logit_accuracy: 0.8012 - val_output_accuracy: 0.6143\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3228 - logit_loss: 0.3228 - layer_1_accuracy: 0.0475 - layer_2_accuracy: 0.0047 - layer_3_accuracy: 0.1009 - logit_accuracy: 0.8414 - output_accuracy: 0.6597 - val_loss: 0.4178 - val_logit_loss: 0.4178 - val_layer_1_accuracy: 0.0508 - val_layer_2_accuracy: 0.0064 - val_layer_3_accuracy: 0.1058 - val_logit_accuracy: 0.8053 - val_output_accuracy: 0.6821\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2975 - logit_loss: 0.2975 - layer_1_accuracy: 0.0485 - layer_2_accuracy: 0.0067 - layer_3_accuracy: 0.1047 - logit_accuracy: 0.8608 - output_accuracy: 0.6894 - val_loss: 0.4174 - val_logit_loss: 0.4174 - val_layer_1_accuracy: 0.0499 - val_layer_2_accuracy: 0.0060 - val_layer_3_accuracy: 0.1072 - val_logit_accuracy: 0.8273 - val_output_accuracy: 0.6967\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2819 - logit_loss: 0.2819 - layer_1_accuracy: 0.0483 - layer_2_accuracy: 0.0094 - layer_3_accuracy: 0.1025 - logit_accuracy: 0.8681 - output_accuracy: 0.7112 - val_loss: 0.4084 - val_logit_loss: 0.4084 - val_layer_1_accuracy: 0.0481 - val_layer_2_accuracy: 0.0055 - val_layer_3_accuracy: 0.1040 - val_logit_accuracy: 0.8369 - val_output_accuracy: 0.6903\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2635 - logit_loss: 0.2635 - layer_1_accuracy: 0.0495 - layer_2_accuracy: 0.0077 - layer_3_accuracy: 0.1017 - logit_accuracy: 0.8804 - output_accuracy: 0.7379 - val_loss: 0.4126 - val_logit_loss: 0.4126 - val_layer_1_accuracy: 0.0458 - val_layer_2_accuracy: 0.0064 - val_layer_3_accuracy: 0.1044 - val_logit_accuracy: 0.8580 - val_output_accuracy: 0.6885\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2419 - logit_loss: 0.2419 - layer_1_accuracy: 0.0491 - layer_2_accuracy: 0.0086 - layer_3_accuracy: 0.1029 - logit_accuracy: 0.8977 - output_accuracy: 0.7544 - val_loss: 0.3982 - val_logit_loss: 0.3982 - val_layer_1_accuracy: 0.0476 - val_layer_2_accuracy: 0.0092 - val_layer_3_accuracy: 0.0989 - val_logit_accuracy: 0.8507 - val_output_accuracy: 0.7682\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2321 - logit_loss: 0.2321 - layer_1_accuracy: 0.0499 - layer_2_accuracy: 0.0090 - layer_3_accuracy: 0.1015 - logit_accuracy: 0.9095 - output_accuracy: 0.7722 - val_loss: 0.3930 - val_logit_loss: 0.3930 - val_layer_1_accuracy: 0.0513 - val_layer_2_accuracy: 0.0110 - val_layer_3_accuracy: 0.1031 - val_logit_accuracy: 0.8740 - val_output_accuracy: 0.7558\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2082 - logit_loss: 0.2082 - layer_1_accuracy: 0.0516 - layer_2_accuracy: 0.0098 - layer_3_accuracy: 0.0994 - logit_accuracy: 0.9167 - output_accuracy: 0.7893 - val_loss: 0.3681 - val_logit_loss: 0.3681 - val_layer_1_accuracy: 0.0518 - val_layer_2_accuracy: 0.0101 - val_layer_3_accuracy: 0.1017 - val_logit_accuracy: 0.8759 - val_output_accuracy: 0.7929\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1999 - logit_loss: 0.1999 - layer_1_accuracy: 0.0528 - layer_2_accuracy: 0.0100 - layer_3_accuracy: 0.1005 - logit_accuracy: 0.9177 - output_accuracy: 0.8015 - val_loss: 0.3552 - val_logit_loss: 0.3552 - val_layer_1_accuracy: 0.0463 - val_layer_2_accuracy: 0.0101 - val_layer_3_accuracy: 0.1049 - val_logit_accuracy: 0.8754 - val_output_accuracy: 0.8026\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1801 - logit_loss: 0.1801 - layer_1_accuracy: 0.0509 - layer_2_accuracy: 0.0098 - layer_3_accuracy: 0.1066 - logit_accuracy: 0.9270 - output_accuracy: 0.8192 - val_loss: 0.3789 - val_logit_loss: 0.3789 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0105 - val_layer_3_accuracy: 0.1200 - val_logit_accuracy: 0.9001 - val_output_accuracy: 0.7641\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1699 - logit_loss: 0.1699 - layer_1_accuracy: 0.0501 - layer_2_accuracy: 0.0096 - layer_3_accuracy: 0.1056 - logit_accuracy: 0.9336 - output_accuracy: 0.8300 - val_loss: 0.3601 - val_logit_loss: 0.3601 - val_layer_1_accuracy: 0.0518 - val_layer_2_accuracy: 0.0119 - val_layer_3_accuracy: 0.1072 - val_logit_accuracy: 0.9079 - val_output_accuracy: 0.8053\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1937 - logit_loss: 0.1937 - layer_1_accuracy: 0.0538 - layer_2_accuracy: 0.0090 - layer_3_accuracy: 0.1001 - logit_accuracy: 0.9293 - output_accuracy: 0.8347 - val_loss: 0.3405 - val_logit_loss: 0.3405 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0105 - val_layer_3_accuracy: 0.1058 - val_logit_accuracy: 0.8887 - val_output_accuracy: 0.8195\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1960 - logit_loss: 0.1960 - layer_1_accuracy: 0.0511 - layer_2_accuracy: 0.0100 - layer_3_accuracy: 0.1031 - logit_accuracy: 0.9393 - output_accuracy: 0.8374 - val_loss: 0.3397 - val_logit_loss: 0.3397 - val_layer_1_accuracy: 0.0518 - val_layer_2_accuracy: 0.0119 - val_layer_3_accuracy: 0.1044 - val_logit_accuracy: 0.9015 - val_output_accuracy: 0.8420\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1691 - logit_loss: 0.1691 - layer_1_accuracy: 0.0495 - layer_2_accuracy: 0.0088 - layer_3_accuracy: 0.1005 - logit_accuracy: 0.9476 - output_accuracy: 0.8616 - val_loss: 0.3618 - val_logit_loss: 0.3618 - val_layer_1_accuracy: 0.0531 - val_layer_2_accuracy: 0.0124 - val_layer_3_accuracy: 0.1150 - val_logit_accuracy: 0.9240 - val_output_accuracy: 0.8236\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1621 - logit_loss: 0.1621 - layer_1_accuracy: 0.0522 - layer_2_accuracy: 0.0100 - layer_3_accuracy: 0.1054 - logit_accuracy: 0.9505 - output_accuracy: 0.8631 - val_loss: 0.4813 - val_logit_loss: 0.4813 - val_layer_1_accuracy: 0.0550 - val_layer_2_accuracy: 0.0105 - val_layer_3_accuracy: 0.1205 - val_logit_accuracy: 0.9130 - val_output_accuracy: 0.8104\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1655 - logit_loss: 0.1655 - layer_1_accuracy: 0.0530 - layer_2_accuracy: 0.0102 - layer_3_accuracy: 0.1019 - logit_accuracy: 0.9531 - output_accuracy: 0.8736 - val_loss: 0.3701 - val_logit_loss: 0.3701 - val_layer_1_accuracy: 0.0577 - val_layer_2_accuracy: 0.0082 - val_layer_3_accuracy: 0.1159 - val_logit_accuracy: 0.9189 - val_output_accuracy: 0.8438\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2205 - logit_loss: 0.2205 - layer_1_accuracy: 0.0538 - layer_2_accuracy: 0.0098 - layer_3_accuracy: 0.1037 - logit_accuracy: 0.9370 - output_accuracy: 0.8720 - val_loss: 0.4793 - val_logit_loss: 0.4793 - val_layer_1_accuracy: 0.0476 - val_layer_2_accuracy: 0.0037 - val_layer_3_accuracy: 0.1054 - val_logit_accuracy: 0.8727 - val_output_accuracy: 0.8795\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4412 - logit_loss: 0.4412 - layer_1_accuracy: 0.0622 - layer_2_accuracy: 0.0073 - layer_3_accuracy: 0.1241 - logit_accuracy: 0.8653 - output_accuracy: 0.7589 - val_loss: 0.3699 - val_logit_loss: 0.3699 - val_layer_1_accuracy: 0.0541 - val_layer_2_accuracy: 0.0046 - val_layer_3_accuracy: 0.1145 - val_logit_accuracy: 0.8374 - val_output_accuracy: 0.7297\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2331 - logit_loss: 0.2331 - layer_1_accuracy: 0.0463 - layer_2_accuracy: 0.0057 - layer_3_accuracy: 0.1107 - logit_accuracy: 0.9014 - output_accuracy: 0.7834 - val_loss: 0.4467 - val_logit_loss: 0.4467 - val_layer_1_accuracy: 0.0490 - val_layer_2_accuracy: 0.0078 - val_layer_3_accuracy: 0.1429 - val_logit_accuracy: 0.8905 - val_output_accuracy: 0.7426\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1650 - logit_loss: 0.1650 - layer_1_accuracy: 0.0475 - layer_2_accuracy: 0.0090 - layer_3_accuracy: 0.1270 - logit_accuracy: 0.9399 - output_accuracy: 0.8355 - val_loss: 0.3314 - val_logit_loss: 0.3314 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0096 - val_layer_3_accuracy: 0.1342 - val_logit_accuracy: 0.9148 - val_output_accuracy: 0.8406\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1333 - logit_loss: 0.1333 - layer_1_accuracy: 0.0509 - layer_2_accuracy: 0.0102 - layer_3_accuracy: 0.1210 - logit_accuracy: 0.9560 - output_accuracy: 0.8737 - val_loss: 0.3708 - val_logit_loss: 0.3708 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0110 - val_layer_3_accuracy: 0.1214 - val_logit_accuracy: 0.9111 - val_output_accuracy: 0.8493\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1508 - logit_loss: 0.1508 - layer_1_accuracy: 0.0514 - layer_2_accuracy: 0.0124 - layer_3_accuracy: 0.1103 - logit_accuracy: 0.9533 - output_accuracy: 0.8816 - val_loss: 0.4079 - val_logit_loss: 0.4079 - val_layer_1_accuracy: 0.0545 - val_layer_2_accuracy: 0.0119 - val_layer_3_accuracy: 0.1214 - val_logit_accuracy: 0.9194 - val_output_accuracy: 0.8323\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1572 - logit_loss: 0.1572 - layer_1_accuracy: 0.0526 - layer_2_accuracy: 0.0122 - layer_3_accuracy: 0.1141 - logit_accuracy: 0.9576 - output_accuracy: 0.8832 - val_loss: 0.4046 - val_logit_loss: 0.4046 - val_layer_1_accuracy: 0.0522 - val_layer_2_accuracy: 0.0124 - val_layer_3_accuracy: 0.1232 - val_logit_accuracy: 0.9281 - val_output_accuracy: 0.8415\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1453 - logit_loss: 0.1453 - layer_1_accuracy: 0.0522 - layer_2_accuracy: 0.0124 - layer_3_accuracy: 0.1133 - logit_accuracy: 0.9645 - output_accuracy: 0.8971 - val_loss: 0.3578 - val_logit_loss: 0.3578 - val_layer_1_accuracy: 0.0573 - val_layer_2_accuracy: 0.0119 - val_layer_3_accuracy: 0.1223 - val_logit_accuracy: 0.9345 - val_output_accuracy: 0.8598\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1394 - logit_loss: 0.1394 - layer_1_accuracy: 0.0534 - layer_2_accuracy: 0.0114 - layer_3_accuracy: 0.1176 - logit_accuracy: 0.9658 - output_accuracy: 0.9038 - val_loss: 0.5367 - val_logit_loss: 0.5367 - val_layer_1_accuracy: 0.0536 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 0.1205 - val_logit_accuracy: 0.9056 - val_output_accuracy: 0.8053\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3661 - logit_loss: 0.3661 - layer_1_accuracy: 0.0605 - layer_2_accuracy: 0.0143 - layer_3_accuracy: 0.0746 - logit_accuracy: 0.8967 - output_accuracy: 0.7936 - val_loss: 0.4203 - val_logit_loss: 0.4203 - val_layer_1_accuracy: 0.0719 - val_layer_2_accuracy: 0.0105 - val_layer_3_accuracy: 0.0788 - val_logit_accuracy: 0.8988 - val_output_accuracy: 0.7948\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2012 - logit_loss: 0.2012 - layer_1_accuracy: 0.0672 - layer_2_accuracy: 0.0098 - layer_3_accuracy: 0.0807 - logit_accuracy: 0.9411 - output_accuracy: 0.8219 - val_loss: 0.3478 - val_logit_loss: 0.3478 - val_layer_1_accuracy: 0.0650 - val_layer_2_accuracy: 0.0142 - val_layer_3_accuracy: 0.0852 - val_logit_accuracy: 0.8992 - val_output_accuracy: 0.8580\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1646 - logit_loss: 0.1646 - layer_1_accuracy: 0.0630 - layer_2_accuracy: 0.0134 - layer_3_accuracy: 0.0821 - logit_accuracy: 0.9501 - output_accuracy: 0.8661 - val_loss: 0.4361 - val_logit_loss: 0.4361 - val_layer_1_accuracy: 0.0628 - val_layer_2_accuracy: 0.0137 - val_layer_3_accuracy: 0.0866 - val_logit_accuracy: 0.9047 - val_output_accuracy: 0.8241\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1697 - logit_loss: 0.1697 - layer_1_accuracy: 0.0654 - layer_2_accuracy: 0.0141 - layer_3_accuracy: 0.0783 - logit_accuracy: 0.9507 - output_accuracy: 0.8551 - val_loss: 0.3827 - val_logit_loss: 0.3827 - val_layer_1_accuracy: 0.0669 - val_layer_2_accuracy: 0.0160 - val_layer_3_accuracy: 0.0930 - val_logit_accuracy: 0.9295 - val_output_accuracy: 0.8488\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1371 - logit_loss: 0.1371 - layer_1_accuracy: 0.0656 - layer_2_accuracy: 0.0155 - layer_3_accuracy: 0.0795 - logit_accuracy: 0.9619 - output_accuracy: 0.8812 - val_loss: 0.3812 - val_logit_loss: 0.3812 - val_layer_1_accuracy: 0.0650 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 0.0916 - val_logit_accuracy: 0.9304 - val_output_accuracy: 0.8534\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1133 - logit_loss: 0.1133 - layer_1_accuracy: 0.0638 - layer_2_accuracy: 0.0161 - layer_3_accuracy: 0.0821 - logit_accuracy: 0.9674 - output_accuracy: 0.8989 - val_loss: 0.3894 - val_logit_loss: 0.3894 - val_layer_1_accuracy: 0.0664 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 0.0893 - val_logit_accuracy: 0.9308 - val_output_accuracy: 0.8507\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1068 - logit_loss: 0.1068 - layer_1_accuracy: 0.0630 - layer_2_accuracy: 0.0165 - layer_3_accuracy: 0.0797 - logit_accuracy: 0.9698 - output_accuracy: 0.9067 - val_loss: 0.3747 - val_logit_loss: 0.3747 - val_layer_1_accuracy: 0.0641 - val_layer_2_accuracy: 0.0156 - val_layer_3_accuracy: 0.0939 - val_logit_accuracy: 0.9340 - val_output_accuracy: 0.8731\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1012 - logit_loss: 0.1012 - layer_1_accuracy: 0.0622 - layer_2_accuracy: 0.0167 - layer_3_accuracy: 0.0809 - logit_accuracy: 0.9705 - output_accuracy: 0.9138 - val_loss: 0.3642 - val_logit_loss: 0.3642 - val_layer_1_accuracy: 0.0628 - val_layer_2_accuracy: 0.0165 - val_layer_3_accuracy: 0.0866 - val_logit_accuracy: 0.9340 - val_output_accuracy: 0.8676\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0984 - logit_loss: 0.0984 - layer_1_accuracy: 0.0609 - layer_2_accuracy: 0.0167 - layer_3_accuracy: 0.0768 - logit_accuracy: 0.9704 - output_accuracy: 0.9140 - val_loss: 0.3572 - val_logit_loss: 0.3572 - val_layer_1_accuracy: 0.0632 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 0.0880 - val_logit_accuracy: 0.9391 - val_output_accuracy: 0.8795\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0932 - logit_loss: 0.0932 - layer_1_accuracy: 0.0613 - layer_2_accuracy: 0.0163 - layer_3_accuracy: 0.0760 - logit_accuracy: 0.9709 - output_accuracy: 0.9222 - val_loss: 0.3421 - val_logit_loss: 0.3421 - val_layer_1_accuracy: 0.0628 - val_layer_2_accuracy: 0.0147 - val_layer_3_accuracy: 0.0866 - val_logit_accuracy: 0.9400 - val_output_accuracy: 0.8855\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0952 - logit_loss: 0.0952 - layer_1_accuracy: 0.0607 - layer_2_accuracy: 0.0169 - layer_3_accuracy: 0.0728 - logit_accuracy: 0.9731 - output_accuracy: 0.9246 - val_loss: 0.4170 - val_logit_loss: 0.4170 - val_layer_1_accuracy: 0.0628 - val_layer_2_accuracy: 0.0151 - val_layer_3_accuracy: 0.0857 - val_logit_accuracy: 0.9336 - val_output_accuracy: 0.8594\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1030 - logit_loss: 0.1030 - layer_1_accuracy: 0.0611 - layer_2_accuracy: 0.0163 - layer_3_accuracy: 0.0709 - logit_accuracy: 0.9725 - output_accuracy: 0.9211 - val_loss: 0.4131 - val_logit_loss: 0.4131 - val_layer_1_accuracy: 0.0600 - val_layer_2_accuracy: 0.0142 - val_layer_3_accuracy: 0.0861 - val_logit_accuracy: 0.9345 - val_output_accuracy: 0.8667\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.4403 - logit_loss: 1.4403 - layer_1_accuracy: 0.0538 - layer_2_accuracy: 0.0124 - layer_3_accuracy: 0.0577 - logit_accuracy: 0.8337 - output_accuracy: 0.8223 - val_loss: 2.8879 - val_logit_loss: 2.8879 - val_layer_1_accuracy: 0.0412 - val_layer_2_accuracy: 0.0147 - val_layer_3_accuracy: 0.0284 - val_logit_accuracy: 0.7462 - val_output_accuracy: 0.7604\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.6640 - logit_loss: 2.6640 - layer_1_accuracy: 0.0243 - layer_2_accuracy: 0.0295 - layer_3_accuracy: 0.0204 - logit_accuracy: 0.7573 - output_accuracy: 0.7569 - val_loss: 2.5224 - val_logit_loss: 2.5224 - val_layer_1_accuracy: 0.0279 - val_layer_2_accuracy: 0.0073 - val_layer_3_accuracy: 0.0133 - val_logit_accuracy: 0.7513 - val_output_accuracy: 0.7664\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8202 - logit_loss: 1.8202 - layer_1_accuracy: 0.0214 - layer_2_accuracy: 0.0069 - layer_3_accuracy: 0.0167 - logit_accuracy: 0.7879 - output_accuracy: 0.7444 - val_loss: 1.6416 - val_logit_loss: 1.6416 - val_layer_1_accuracy: 0.0270 - val_layer_2_accuracy: 0.0027 - val_layer_3_accuracy: 0.0087 - val_logit_accuracy: 0.7361 - val_output_accuracy: 0.7664\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.2675 - logit_loss: 1.2675 - layer_1_accuracy: 0.0210 - layer_2_accuracy: 0.0043 - layer_3_accuracy: 0.0086 - logit_accuracy: 0.7901 - output_accuracy: 0.6972 - val_loss: 1.1300 - val_logit_loss: 1.1300 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.0027 - val_layer_3_accuracy: 0.0032 - val_logit_accuracy: 0.7719 - val_output_accuracy: 0.7261\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.8199 - logit_loss: 0.8199 - layer_1_accuracy: 0.0243 - layer_2_accuracy: 0.0035 - layer_3_accuracy: 0.0079 - logit_accuracy: 0.8368 - output_accuracy: 0.7226 - val_loss: 0.8490 - val_logit_loss: 0.8490 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0027 - val_layer_3_accuracy: 0.0101 - val_logit_accuracy: 0.8136 - val_output_accuracy: 0.6716\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6491 - logit_loss: 0.6491 - layer_1_accuracy: 0.0251 - layer_2_accuracy: 0.0035 - layer_3_accuracy: 0.0104 - logit_accuracy: 0.8614 - output_accuracy: 0.7039 - val_loss: 0.6995 - val_logit_loss: 0.6995 - val_layer_1_accuracy: 0.0344 - val_layer_2_accuracy: 0.0027 - val_layer_3_accuracy: 0.0137 - val_logit_accuracy: 0.8424 - val_output_accuracy: 0.6972\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5431 - logit_loss: 0.5431 - layer_1_accuracy: 0.0265 - layer_2_accuracy: 0.0043 - layer_3_accuracy: 0.0126 - logit_accuracy: 0.8747 - output_accuracy: 0.7161 - val_loss: 0.6344 - val_logit_loss: 0.6344 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0032 - val_layer_3_accuracy: 0.0124 - val_logit_accuracy: 0.8594 - val_output_accuracy: 0.6757\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4935 - logit_loss: 0.4935 - layer_1_accuracy: 0.0279 - layer_2_accuracy: 0.0035 - layer_3_accuracy: 0.0132 - logit_accuracy: 0.8844 - output_accuracy: 0.7196 - val_loss: 0.6048 - val_logit_loss: 0.6048 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0032 - val_layer_3_accuracy: 0.0124 - val_logit_accuracy: 0.8571 - val_output_accuracy: 0.7087\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4701 - logit_loss: 0.4701 - layer_1_accuracy: 0.0281 - layer_2_accuracy: 0.0035 - layer_3_accuracy: 0.0126 - logit_accuracy: 0.8863 - output_accuracy: 0.7493 - val_loss: 0.5756 - val_logit_loss: 0.5756 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0032 - val_layer_3_accuracy: 0.0124 - val_logit_accuracy: 0.8598 - val_output_accuracy: 0.7339\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4549 - logit_loss: 0.4549 - layer_1_accuracy: 0.0287 - layer_2_accuracy: 0.0059 - layer_3_accuracy: 0.0122 - logit_accuracy: 0.8973 - output_accuracy: 0.7589 - val_loss: 0.5695 - val_logit_loss: 0.5695 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0073 - val_layer_3_accuracy: 0.0128 - val_logit_accuracy: 0.8630 - val_output_accuracy: 0.7490\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4429 - logit_loss: 0.4429 - layer_1_accuracy: 0.0289 - layer_2_accuracy: 0.0112 - layer_3_accuracy: 0.0137 - logit_accuracy: 0.9003 - output_accuracy: 0.7787 - val_loss: 0.5604 - val_logit_loss: 0.5604 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0082 - val_layer_3_accuracy: 0.0137 - val_logit_accuracy: 0.8722 - val_output_accuracy: 0.7590\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4315 - logit_loss: 0.4315 - layer_1_accuracy: 0.0296 - layer_2_accuracy: 0.0122 - layer_3_accuracy: 0.0134 - logit_accuracy: 0.9103 - output_accuracy: 0.7887 - val_loss: 0.5556 - val_logit_loss: 0.5556 - val_layer_1_accuracy: 0.0389 - val_layer_2_accuracy: 0.0092 - val_layer_3_accuracy: 0.0147 - val_logit_accuracy: 0.8768 - val_output_accuracy: 0.7728\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4218 - logit_loss: 0.4218 - layer_1_accuracy: 0.0298 - layer_2_accuracy: 0.0128 - layer_3_accuracy: 0.0134 - logit_accuracy: 0.9177 - output_accuracy: 0.7958 - val_loss: 0.5550 - val_logit_loss: 0.5550 - val_layer_1_accuracy: 0.0394 - val_layer_2_accuracy: 0.0092 - val_layer_3_accuracy: 0.0156 - val_logit_accuracy: 0.8791 - val_output_accuracy: 0.7778\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4126 - logit_loss: 0.4126 - layer_1_accuracy: 0.0295 - layer_2_accuracy: 0.0126 - layer_3_accuracy: 0.0122 - logit_accuracy: 0.9213 - output_accuracy: 0.8093 - val_loss: 0.5718 - val_logit_loss: 0.5718 - val_layer_1_accuracy: 0.0376 - val_layer_2_accuracy: 0.0092 - val_layer_3_accuracy: 0.0156 - val_logit_accuracy: 0.8827 - val_output_accuracy: 0.7783\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4045 - logit_loss: 0.4045 - layer_1_accuracy: 0.0298 - layer_2_accuracy: 0.0132 - layer_3_accuracy: 0.0122 - logit_accuracy: 0.9250 - output_accuracy: 0.8156 - val_loss: 0.5574 - val_logit_loss: 0.5574 - val_layer_1_accuracy: 0.0389 - val_layer_2_accuracy: 0.0092 - val_layer_3_accuracy: 0.0156 - val_logit_accuracy: 0.8882 - val_output_accuracy: 0.7833\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3967 - logit_loss: 0.3967 - layer_1_accuracy: 0.0306 - layer_2_accuracy: 0.0135 - layer_3_accuracy: 0.0149 - logit_accuracy: 0.9274 - output_accuracy: 0.8237 - val_loss: 0.5311 - val_logit_loss: 0.5311 - val_layer_1_accuracy: 0.0389 - val_layer_2_accuracy: 0.0092 - val_layer_3_accuracy: 0.0202 - val_logit_accuracy: 0.8887 - val_output_accuracy: 0.8016\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3902 - logit_loss: 0.3902 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0141 - layer_3_accuracy: 0.0179 - logit_accuracy: 0.9299 - output_accuracy: 0.8333 - val_loss: 0.5379 - val_logit_loss: 0.5379 - val_layer_1_accuracy: 0.0399 - val_layer_2_accuracy: 0.0119 - val_layer_3_accuracy: 0.0215 - val_logit_accuracy: 0.8946 - val_output_accuracy: 0.8035\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3821 - logit_loss: 0.3821 - layer_1_accuracy: 0.0320 - layer_2_accuracy: 0.0163 - layer_3_accuracy: 0.0185 - logit_accuracy: 0.9360 - output_accuracy: 0.8396 - val_loss: 0.5359 - val_logit_loss: 0.5359 - val_layer_1_accuracy: 0.0408 - val_layer_2_accuracy: 0.0128 - val_layer_3_accuracy: 0.0183 - val_logit_accuracy: 0.8956 - val_output_accuracy: 0.8113\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3764 - logit_loss: 0.3764 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 0.0177 - layer_3_accuracy: 0.0181 - logit_accuracy: 0.9352 - output_accuracy: 0.8478 - val_loss: 0.5155 - val_logit_loss: 0.5155 - val_layer_1_accuracy: 0.0435 - val_layer_2_accuracy: 0.0142 - val_layer_3_accuracy: 0.0183 - val_logit_accuracy: 0.8983 - val_output_accuracy: 0.8227\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3723 - logit_loss: 0.3723 - layer_1_accuracy: 0.0344 - layer_2_accuracy: 0.0177 - layer_3_accuracy: 0.0181 - logit_accuracy: 0.9383 - output_accuracy: 0.8576 - val_loss: 0.5156 - val_logit_loss: 0.5156 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0147 - val_layer_3_accuracy: 0.0183 - val_logit_accuracy: 0.9011 - val_output_accuracy: 0.8264\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3666 - logit_loss: 0.3666 - layer_1_accuracy: 0.0348 - layer_2_accuracy: 0.0175 - layer_3_accuracy: 0.0185 - logit_accuracy: 0.9397 - output_accuracy: 0.8616 - val_loss: 0.5300 - val_logit_loss: 0.5300 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0133 - val_layer_3_accuracy: 0.0188 - val_logit_accuracy: 0.9079 - val_output_accuracy: 0.8268\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3620 - logit_loss: 0.3620 - layer_1_accuracy: 0.0357 - layer_2_accuracy: 0.0177 - layer_3_accuracy: 0.0198 - logit_accuracy: 0.9427 - output_accuracy: 0.8673 - val_loss: 0.5229 - val_logit_loss: 0.5229 - val_layer_1_accuracy: 0.0431 - val_layer_2_accuracy: 0.0142 - val_layer_3_accuracy: 0.0188 - val_logit_accuracy: 0.9088 - val_output_accuracy: 0.8282\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3605 - logit_loss: 0.3605 - layer_1_accuracy: 0.0359 - layer_2_accuracy: 0.0179 - layer_3_accuracy: 0.0194 - logit_accuracy: 0.9470 - output_accuracy: 0.8732 - val_loss: 0.5111 - val_logit_loss: 0.5111 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0133 - val_layer_3_accuracy: 0.0183 - val_logit_accuracy: 0.9148 - val_output_accuracy: 0.8342\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4596 - logit_loss: 0.4596 - layer_1_accuracy: 0.0375 - layer_2_accuracy: 0.0173 - layer_3_accuracy: 0.0230 - logit_accuracy: 0.9256 - output_accuracy: 0.8716 - val_loss: 0.9368 - val_logit_loss: 0.9368 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0183 - val_layer_3_accuracy: 0.0302 - val_logit_accuracy: 0.8543 - val_output_accuracy: 0.7371\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7187 - logit_loss: 0.7187 - layer_1_accuracy: 0.0253 - layer_2_accuracy: 0.0232 - layer_3_accuracy: 0.0240 - logit_accuracy: 0.8706 - output_accuracy: 0.7879 - val_loss: 1.0011 - val_logit_loss: 1.0011 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.0334 - val_layer_3_accuracy: 0.0371 - val_logit_accuracy: 0.8447 - val_output_accuracy: 0.7389\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4672 - logit_loss: 0.4672 - layer_1_accuracy: 0.0283 - layer_2_accuracy: 0.0236 - layer_3_accuracy: 0.0320 - logit_accuracy: 0.8834 - output_accuracy: 0.8186 - val_loss: 0.7184 - val_logit_loss: 0.7184 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0234 - val_layer_3_accuracy: 0.0376 - val_logit_accuracy: 0.8731 - val_output_accuracy: 0.7426\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3141 - logit_loss: 0.3141 - layer_1_accuracy: 0.0322 - layer_2_accuracy: 0.0240 - layer_3_accuracy: 0.0361 - logit_accuracy: 0.9238 - output_accuracy: 0.8235 - val_loss: 0.5791 - val_logit_loss: 0.5791 - val_layer_1_accuracy: 0.0366 - val_layer_2_accuracy: 0.0289 - val_layer_3_accuracy: 0.0371 - val_logit_accuracy: 0.8846 - val_output_accuracy: 0.7939\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2810 - logit_loss: 0.2810 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0279 - layer_3_accuracy: 0.0361 - logit_accuracy: 0.9382 - output_accuracy: 0.8408 - val_loss: 0.5478 - val_logit_loss: 0.5478 - val_layer_1_accuracy: 0.0394 - val_layer_2_accuracy: 0.0284 - val_layer_3_accuracy: 0.0371 - val_logit_accuracy: 0.8992 - val_output_accuracy: 0.8195\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2667 - logit_loss: 0.2667 - layer_1_accuracy: 0.0353 - layer_2_accuracy: 0.0289 - layer_3_accuracy: 0.0357 - logit_accuracy: 0.9454 - output_accuracy: 0.8596 - val_loss: 0.5625 - val_logit_loss: 0.5625 - val_layer_1_accuracy: 0.0394 - val_layer_2_accuracy: 0.0279 - val_layer_3_accuracy: 0.0371 - val_logit_accuracy: 0.9070 - val_output_accuracy: 0.8227\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2543 - logit_loss: 0.2543 - layer_1_accuracy: 0.0355 - layer_2_accuracy: 0.0320 - layer_3_accuracy: 0.0349 - logit_accuracy: 0.9493 - output_accuracy: 0.8698 - val_loss: 0.5138 - val_logit_loss: 0.5138 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0325 - val_layer_3_accuracy: 0.0357 - val_logit_accuracy: 0.9015 - val_output_accuracy: 0.8488\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2540 - logit_loss: 0.2540 - layer_1_accuracy: 0.0353 - layer_2_accuracy: 0.0338 - layer_3_accuracy: 0.0344 - logit_accuracy: 0.9464 - output_accuracy: 0.8804 - val_loss: 0.5538 - val_logit_loss: 0.5538 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0302 - val_layer_3_accuracy: 0.0366 - val_logit_accuracy: 0.9134 - val_output_accuracy: 0.8236\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2441 - logit_loss: 0.2441 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 0.0328 - layer_3_accuracy: 0.0344 - logit_accuracy: 0.9548 - output_accuracy: 0.8790 - val_loss: 0.5373 - val_logit_loss: 0.5373 - val_layer_1_accuracy: 0.0389 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0366 - val_logit_accuracy: 0.9180 - val_output_accuracy: 0.8420\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2358 - logit_loss: 0.2358 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0330 - layer_3_accuracy: 0.0342 - logit_accuracy: 0.9584 - output_accuracy: 0.8928 - val_loss: 0.5010 - val_logit_loss: 0.5010 - val_layer_1_accuracy: 0.0399 - val_layer_2_accuracy: 0.0334 - val_layer_3_accuracy: 0.0366 - val_logit_accuracy: 0.9180 - val_output_accuracy: 0.8566\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2634 - logit_loss: 0.2634 - layer_1_accuracy: 0.0346 - layer_2_accuracy: 0.0348 - layer_3_accuracy: 0.0348 - logit_accuracy: 0.9546 - output_accuracy: 0.8869 - val_loss: 0.5595 - val_logit_loss: 0.5595 - val_layer_1_accuracy: 0.0399 - val_layer_2_accuracy: 0.0275 - val_layer_3_accuracy: 0.0321 - val_logit_accuracy: 0.8571 - val_output_accuracy: 0.8869\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5199 - logit_loss: 0.5199 - layer_1_accuracy: 0.0359 - layer_2_accuracy: 0.0304 - layer_3_accuracy: 0.0306 - logit_accuracy: 0.8940 - output_accuracy: 0.8467 - val_loss: 0.6803 - val_logit_loss: 0.6803 - val_layer_1_accuracy: 0.0394 - val_layer_2_accuracy: 0.0302 - val_layer_3_accuracy: 0.0307 - val_logit_accuracy: 0.8933 - val_output_accuracy: 0.8007\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3711 - logit_loss: 0.3711 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0287 - layer_3_accuracy: 0.0296 - logit_accuracy: 0.9258 - output_accuracy: 0.8213 - val_loss: 1.0008 - val_logit_loss: 1.0008 - val_layer_1_accuracy: 0.0399 - val_layer_2_accuracy: 0.0266 - val_layer_3_accuracy: 0.0348 - val_logit_accuracy: 0.8388 - val_output_accuracy: 0.7233\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4206 - logit_loss: 0.4206 - layer_1_accuracy: 0.0296 - layer_2_accuracy: 0.0269 - layer_3_accuracy: 0.0367 - logit_accuracy: 0.9016 - output_accuracy: 0.8174 - val_loss: 0.6200 - val_logit_loss: 0.6200 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0279 - val_layer_3_accuracy: 0.0348 - val_logit_accuracy: 0.8896 - val_output_accuracy: 0.7801\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2609 - logit_loss: 0.2609 - layer_1_accuracy: 0.0269 - layer_2_accuracy: 0.0306 - layer_3_accuracy: 0.0379 - logit_accuracy: 0.9395 - output_accuracy: 0.8404 - val_loss: 0.4798 - val_logit_loss: 0.4798 - val_layer_1_accuracy: 0.0344 - val_layer_2_accuracy: 0.0270 - val_layer_3_accuracy: 0.0334 - val_logit_accuracy: 0.8882 - val_output_accuracy: 0.8548\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2682 - logit_loss: 0.2682 - layer_1_accuracy: 0.0302 - layer_2_accuracy: 0.0312 - layer_3_accuracy: 0.0397 - logit_accuracy: 0.9397 - output_accuracy: 0.8576 - val_loss: 0.5187 - val_logit_loss: 0.5187 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0279 - val_layer_3_accuracy: 0.0389 - val_logit_accuracy: 0.8942 - val_output_accuracy: 0.8415\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2774 - logit_loss: 0.2774 - layer_1_accuracy: 0.0314 - layer_2_accuracy: 0.0320 - layer_3_accuracy: 0.0418 - logit_accuracy: 0.9454 - output_accuracy: 0.8565 - val_loss: 0.5347 - val_logit_loss: 0.5347 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0279 - val_layer_3_accuracy: 0.0412 - val_logit_accuracy: 0.9125 - val_output_accuracy: 0.8342\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2549 - logit_loss: 0.2549 - layer_1_accuracy: 0.0316 - layer_2_accuracy: 0.0322 - layer_3_accuracy: 0.0420 - logit_accuracy: 0.9529 - output_accuracy: 0.8673 - val_loss: 0.5066 - val_logit_loss: 0.5066 - val_layer_1_accuracy: 0.0376 - val_layer_2_accuracy: 0.0284 - val_layer_3_accuracy: 0.0371 - val_logit_accuracy: 0.9130 - val_output_accuracy: 0.8420\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2315 - logit_loss: 0.2315 - layer_1_accuracy: 0.0302 - layer_2_accuracy: 0.0320 - layer_3_accuracy: 0.0418 - logit_accuracy: 0.9556 - output_accuracy: 0.8679 - val_loss: 0.4777 - val_logit_loss: 0.4777 - val_layer_1_accuracy: 0.0380 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0325 - val_logit_accuracy: 0.9166 - val_output_accuracy: 0.8406\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2000 - logit_loss: 0.2000 - layer_1_accuracy: 0.0318 - layer_2_accuracy: 0.0308 - layer_3_accuracy: 0.0401 - logit_accuracy: 0.9572 - output_accuracy: 0.8816 - val_loss: 0.5016 - val_logit_loss: 0.5016 - val_layer_1_accuracy: 0.0380 - val_layer_2_accuracy: 0.0289 - val_layer_3_accuracy: 0.0376 - val_logit_accuracy: 0.9203 - val_output_accuracy: 0.8530\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1906 - logit_loss: 0.1906 - layer_1_accuracy: 0.0324 - layer_2_accuracy: 0.0306 - layer_3_accuracy: 0.0399 - logit_accuracy: 0.9607 - output_accuracy: 0.8922 - val_loss: 0.4978 - val_logit_loss: 0.4978 - val_layer_1_accuracy: 0.0380 - val_layer_2_accuracy: 0.0284 - val_layer_3_accuracy: 0.0334 - val_logit_accuracy: 0.9194 - val_output_accuracy: 0.8543\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1857 - logit_loss: 0.1857 - layer_1_accuracy: 0.0322 - layer_2_accuracy: 0.0300 - layer_3_accuracy: 0.0379 - logit_accuracy: 0.9613 - output_accuracy: 0.8989 - val_loss: 0.5119 - val_logit_loss: 0.5119 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0293 - val_layer_3_accuracy: 0.0321 - val_logit_accuracy: 0.9198 - val_output_accuracy: 0.8566\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1817 - logit_loss: 0.1817 - layer_1_accuracy: 0.0324 - layer_2_accuracy: 0.0296 - layer_3_accuracy: 0.0375 - logit_accuracy: 0.9631 - output_accuracy: 0.9044 - val_loss: 0.5254 - val_logit_loss: 0.5254 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0289 - val_layer_3_accuracy: 0.0298 - val_logit_accuracy: 0.9258 - val_output_accuracy: 0.8552\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1791 - logit_loss: 0.1791 - layer_1_accuracy: 0.0326 - layer_2_accuracy: 0.0298 - layer_3_accuracy: 0.0344 - logit_accuracy: 0.9649 - output_accuracy: 0.9063 - val_loss: 0.4996 - val_logit_loss: 0.4996 - val_layer_1_accuracy: 0.0385 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0284 - val_logit_accuracy: 0.9249 - val_output_accuracy: 0.8585\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1745 - logit_loss: 0.1745 - layer_1_accuracy: 0.0328 - layer_2_accuracy: 0.0306 - layer_3_accuracy: 0.0353 - logit_accuracy: 0.9658 - output_accuracy: 0.9116 - val_loss: 0.4891 - val_logit_loss: 0.4891 - val_layer_1_accuracy: 0.0408 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0279 - val_logit_accuracy: 0.9235 - val_output_accuracy: 0.8639\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1748 - logit_loss: 0.1748 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0318 - layer_3_accuracy: 0.0346 - logit_accuracy: 0.9652 - output_accuracy: 0.9154 - val_loss: 0.4693 - val_logit_loss: 0.4693 - val_layer_1_accuracy: 0.0403 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0293 - val_logit_accuracy: 0.9304 - val_output_accuracy: 0.8649\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1716 - logit_loss: 0.1716 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 0.0318 - layer_3_accuracy: 0.0322 - logit_accuracy: 0.9684 - output_accuracy: 0.9207 - val_loss: 0.4753 - val_logit_loss: 0.4753 - val_layer_1_accuracy: 0.0417 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0298 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8717\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1704 - logit_loss: 0.1704 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0318 - layer_3_accuracy: 0.0351 - logit_accuracy: 0.9696 - output_accuracy: 0.9220 - val_loss: 0.4657 - val_logit_loss: 0.4657 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0316 - val_layer_3_accuracy: 0.0284 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8694\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1680 - logit_loss: 0.1680 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0320 - layer_3_accuracy: 0.0314 - logit_accuracy: 0.9678 - output_accuracy: 0.9236 - val_loss: 0.4653 - val_logit_loss: 0.4653 - val_layer_1_accuracy: 0.0417 - val_layer_2_accuracy: 0.0316 - val_layer_3_accuracy: 0.0279 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8699\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1665 - logit_loss: 0.1665 - layer_1_accuracy: 0.0336 - layer_2_accuracy: 0.0322 - layer_3_accuracy: 0.0308 - logit_accuracy: 0.9700 - output_accuracy: 0.9277 - val_loss: 0.4745 - val_logit_loss: 0.4745 - val_layer_1_accuracy: 0.0426 - val_layer_2_accuracy: 0.0316 - val_layer_3_accuracy: 0.0270 - val_logit_accuracy: 0.9299 - val_output_accuracy: 0.8644\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1648 - logit_loss: 0.1648 - layer_1_accuracy: 0.0340 - layer_2_accuracy: 0.0322 - layer_3_accuracy: 0.0304 - logit_accuracy: 0.9700 - output_accuracy: 0.9295 - val_loss: 0.4568 - val_logit_loss: 0.4568 - val_layer_1_accuracy: 0.0417 - val_layer_2_accuracy: 0.0302 - val_layer_3_accuracy: 0.0266 - val_logit_accuracy: 0.9322 - val_output_accuracy: 0.8777\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1639 - logit_loss: 0.1639 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0328 - layer_3_accuracy: 0.0306 - logit_accuracy: 0.9700 - output_accuracy: 0.9309 - val_loss: 0.4682 - val_logit_loss: 0.4682 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0330 - val_layer_3_accuracy: 0.0270 - val_logit_accuracy: 0.9322 - val_output_accuracy: 0.8708\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1623 - logit_loss: 0.1623 - layer_1_accuracy: 0.0342 - layer_2_accuracy: 0.0330 - layer_3_accuracy: 0.0306 - logit_accuracy: 0.9707 - output_accuracy: 0.9350 - val_loss: 0.4503 - val_logit_loss: 0.4503 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0325 - val_layer_3_accuracy: 0.0270 - val_logit_accuracy: 0.9331 - val_output_accuracy: 0.8763\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1618 - logit_loss: 0.1618 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0322 - layer_3_accuracy: 0.0298 - logit_accuracy: 0.9717 - output_accuracy: 0.9344 - val_loss: 0.4562 - val_logit_loss: 0.4562 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0298 - val_layer_3_accuracy: 0.0266 - val_logit_accuracy: 0.9354 - val_output_accuracy: 0.8777\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1596 - logit_loss: 0.1596 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0314 - layer_3_accuracy: 0.0298 - logit_accuracy: 0.9715 - output_accuracy: 0.9368 - val_loss: 0.4606 - val_logit_loss: 0.4606 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0261 - val_logit_accuracy: 0.9350 - val_output_accuracy: 0.8763\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1600 - logit_loss: 0.1600 - layer_1_accuracy: 0.0351 - layer_2_accuracy: 0.0320 - layer_3_accuracy: 0.0300 - logit_accuracy: 0.9725 - output_accuracy: 0.9364 - val_loss: 0.4456 - val_logit_loss: 0.4456 - val_layer_1_accuracy: 0.0444 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0257 - val_logit_accuracy: 0.9317 - val_output_accuracy: 0.8841\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1595 - logit_loss: 0.1595 - layer_1_accuracy: 0.0344 - layer_2_accuracy: 0.0326 - layer_3_accuracy: 0.0296 - logit_accuracy: 0.9715 - output_accuracy: 0.9383 - val_loss: 0.4654 - val_logit_loss: 0.4654 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0316 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.9350 - val_output_accuracy: 0.8731\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1583 - logit_loss: 0.1583 - layer_1_accuracy: 0.0348 - layer_2_accuracy: 0.0322 - layer_3_accuracy: 0.0300 - logit_accuracy: 0.9735 - output_accuracy: 0.9391 - val_loss: 0.4581 - val_logit_loss: 0.4581 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0334 - val_layer_3_accuracy: 0.0279 - val_logit_accuracy: 0.9359 - val_output_accuracy: 0.8827\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1572 - logit_loss: 0.1572 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0324 - layer_3_accuracy: 0.0293 - logit_accuracy: 0.9731 - output_accuracy: 0.9423 - val_loss: 0.4804 - val_logit_loss: 0.4804 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.9336 - val_output_accuracy: 0.8754\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1569 - logit_loss: 0.1569 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0326 - layer_3_accuracy: 0.0295 - logit_accuracy: 0.9733 - output_accuracy: 0.9435 - val_loss: 0.4613 - val_logit_loss: 0.4613 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0339 - val_layer_3_accuracy: 0.0279 - val_logit_accuracy: 0.9345 - val_output_accuracy: 0.8804\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1560 - logit_loss: 0.1560 - layer_1_accuracy: 0.0344 - layer_2_accuracy: 0.0330 - layer_3_accuracy: 0.0300 - logit_accuracy: 0.9725 - output_accuracy: 0.9456 - val_loss: 0.4663 - val_logit_loss: 0.4663 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0321 - val_layer_3_accuracy: 0.0284 - val_logit_accuracy: 0.9336 - val_output_accuracy: 0.8836\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1553 - logit_loss: 0.1553 - layer_1_accuracy: 0.0355 - layer_2_accuracy: 0.0332 - layer_3_accuracy: 0.0310 - logit_accuracy: 0.9745 - output_accuracy: 0.9446 - val_loss: 0.4551 - val_logit_loss: 0.4551 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0279 - val_logit_accuracy: 0.9340 - val_output_accuracy: 0.8869\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1556 - logit_loss: 0.1556 - layer_1_accuracy: 0.0355 - layer_2_accuracy: 0.0332 - layer_3_accuracy: 0.0312 - logit_accuracy: 0.9733 - output_accuracy: 0.9464 - val_loss: 0.4621 - val_logit_loss: 0.4621 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.9331 - val_output_accuracy: 0.8873\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1544 - logit_loss: 0.1544 - layer_1_accuracy: 0.0342 - layer_2_accuracy: 0.0334 - layer_3_accuracy: 0.0302 - logit_accuracy: 0.9729 - output_accuracy: 0.9466 - val_loss: 0.4529 - val_logit_loss: 0.4529 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0339 - val_layer_3_accuracy: 0.0275 - val_logit_accuracy: 0.9331 - val_output_accuracy: 0.8855\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1542 - logit_loss: 0.1542 - layer_1_accuracy: 0.0355 - layer_2_accuracy: 0.0328 - layer_3_accuracy: 0.0320 - logit_accuracy: 0.9733 - output_accuracy: 0.9478 - val_loss: 0.4566 - val_logit_loss: 0.4566 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0307 - val_layer_3_accuracy: 0.0270 - val_logit_accuracy: 0.9372 - val_output_accuracy: 0.8887\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1562 - logit_loss: 0.1562 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0338 - layer_3_accuracy: 0.0300 - logit_accuracy: 0.9725 - output_accuracy: 0.9503 - val_loss: 0.5191 - val_logit_loss: 0.5191 - val_layer_1_accuracy: 0.0440 - val_layer_2_accuracy: 0.0302 - val_layer_3_accuracy: 0.0247 - val_logit_accuracy: 0.9230 - val_output_accuracy: 0.8887\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2572 - logit_loss: 0.2572 - layer_1_accuracy: 0.0353 - layer_2_accuracy: 0.0334 - layer_3_accuracy: 0.0291 - logit_accuracy: 0.9596 - output_accuracy: 0.9193 - val_loss: 0.6188 - val_logit_loss: 0.6188 - val_layer_1_accuracy: 0.0435 - val_layer_2_accuracy: 0.0357 - val_layer_3_accuracy: 0.0215 - val_logit_accuracy: 0.8974 - val_output_accuracy: 0.8708\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2873 - logit_loss: 0.2873 - layer_1_accuracy: 0.0340 - layer_2_accuracy: 0.0340 - layer_3_accuracy: 0.0263 - logit_accuracy: 0.9580 - output_accuracy: 0.9079 - val_loss: 0.5790 - val_logit_loss: 0.5790 - val_layer_1_accuracy: 0.0444 - val_layer_2_accuracy: 0.0330 - val_layer_3_accuracy: 0.0243 - val_logit_accuracy: 0.9240 - val_output_accuracy: 0.8768\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2191 - logit_loss: 0.2191 - layer_1_accuracy: 0.0351 - layer_2_accuracy: 0.0328 - layer_3_accuracy: 0.0287 - logit_accuracy: 0.9670 - output_accuracy: 0.9270 - val_loss: 0.5035 - val_logit_loss: 0.5035 - val_layer_1_accuracy: 0.0444 - val_layer_2_accuracy: 0.0334 - val_layer_3_accuracy: 0.0247 - val_logit_accuracy: 0.9276 - val_output_accuracy: 0.8777\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1925 - logit_loss: 0.1925 - layer_1_accuracy: 0.0349 - layer_2_accuracy: 0.0353 - layer_3_accuracy: 0.0300 - logit_accuracy: 0.9705 - output_accuracy: 0.9344 - val_loss: 0.4895 - val_logit_loss: 0.4895 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0311 - val_layer_3_accuracy: 0.0261 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.8891\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1888 - logit_loss: 0.1888 - layer_1_accuracy: 0.0353 - layer_2_accuracy: 0.0340 - layer_3_accuracy: 0.0287 - logit_accuracy: 0.9705 - output_accuracy: 0.9409 - val_loss: 0.5360 - val_logit_loss: 0.5360 - val_layer_1_accuracy: 0.0449 - val_layer_2_accuracy: 0.0325 - val_layer_3_accuracy: 0.0247 - val_logit_accuracy: 0.9304 - val_output_accuracy: 0.8795\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1870 - logit_loss: 0.1870 - layer_1_accuracy: 0.0359 - layer_2_accuracy: 0.0349 - layer_3_accuracy: 0.0279 - logit_accuracy: 0.9719 - output_accuracy: 0.9452 - val_loss: 0.4881 - val_logit_loss: 0.4881 - val_layer_1_accuracy: 0.0458 - val_layer_2_accuracy: 0.0348 - val_layer_3_accuracy: 0.0243 - val_logit_accuracy: 0.9308 - val_output_accuracy: 0.8841\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1859 - logit_loss: 0.1859 - layer_1_accuracy: 0.0357 - layer_2_accuracy: 0.0349 - layer_3_accuracy: 0.0277 - logit_accuracy: 0.9713 - output_accuracy: 0.9486 - val_loss: 0.4903 - val_logit_loss: 0.4903 - val_layer_1_accuracy: 0.0458 - val_layer_2_accuracy: 0.0344 - val_layer_3_accuracy: 0.0243 - val_logit_accuracy: 0.9340 - val_output_accuracy: 0.8859\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5219 - logit_loss: 0.5219 - layer_1_accuracy: 0.0348 - layer_2_accuracy: 0.0322 - layer_3_accuracy: 0.0226 - logit_accuracy: 0.9293 - output_accuracy: 0.9081 - val_loss: 1.5059 - val_logit_loss: 1.5059 - val_layer_1_accuracy: 0.0330 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0023 - val_logit_accuracy: 0.8158 - val_output_accuracy: 0.8287\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.8854 - logit_loss: 1.8854 - layer_1_accuracy: 0.0310 - layer_2_accuracy: 0.0216 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.8031 - output_accuracy: 0.7885 - val_loss: 1.9202 - val_logit_loss: 1.9202 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0206 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7824 - val_output_accuracy: 0.7096\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1708 - logit_loss: 1.1708 - layer_1_accuracy: 0.0322 - layer_2_accuracy: 0.0112 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8359 - output_accuracy: 0.7901 - val_loss: 1.2044 - val_logit_loss: 1.2044 - val_layer_1_accuracy: 0.0330 - val_layer_2_accuracy: 0.0128 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8241 - val_output_accuracy: 0.7581\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7385 - logit_loss: 0.7385 - layer_1_accuracy: 0.0308 - layer_2_accuracy: 0.0122 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8612 - output_accuracy: 0.7946 - val_loss: 0.8294 - val_logit_loss: 0.8294 - val_layer_1_accuracy: 0.0325 - val_layer_2_accuracy: 0.0151 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8447 - val_output_accuracy: 0.7861\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5592 - logit_loss: 0.5592 - layer_1_accuracy: 0.0298 - layer_2_accuracy: 0.0108 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.8971 - output_accuracy: 0.8088 - val_loss: 0.7210 - val_logit_loss: 0.7210 - val_layer_1_accuracy: 0.0307 - val_layer_2_accuracy: 0.0110 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8662 - val_output_accuracy: 0.7989\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4788 - logit_loss: 0.4788 - layer_1_accuracy: 0.0300 - layer_2_accuracy: 0.0094 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9158 - output_accuracy: 0.8251 - val_loss: 0.7252 - val_logit_loss: 0.7252 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.0110 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8708 - val_output_accuracy: 0.8067\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4454 - logit_loss: 0.4454 - layer_1_accuracy: 0.0302 - layer_2_accuracy: 0.0084 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9185 - output_accuracy: 0.8429 - val_loss: 0.7646 - val_logit_loss: 0.7646 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0096 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8736 - val_output_accuracy: 0.8007\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4393 - logit_loss: 0.4393 - layer_1_accuracy: 0.0306 - layer_2_accuracy: 0.0084 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9219 - output_accuracy: 0.8557 - val_loss: 0.7680 - val_logit_loss: 0.7680 - val_layer_1_accuracy: 0.0330 - val_layer_2_accuracy: 0.0105 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8786 - val_output_accuracy: 0.8085\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6118 - logit_loss: 0.6118 - layer_1_accuracy: 0.0310 - layer_2_accuracy: 0.0147 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.8898 - output_accuracy: 0.8470 - val_loss: 1.3976 - val_logit_loss: 1.3976 - val_layer_1_accuracy: 0.0298 - val_layer_2_accuracy: 0.0353 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.7742 - val_output_accuracy: 0.7169\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7136 - logit_loss: 0.7136 - layer_1_accuracy: 0.0269 - layer_2_accuracy: 0.0212 - layer_3_accuracy: 9.8174e-04 - logit_accuracy: 0.8635 - output_accuracy: 0.7783 - val_loss: 0.7652 - val_logit_loss: 0.7652 - val_layer_1_accuracy: 0.0275 - val_layer_2_accuracy: 0.0165 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8337 - val_output_accuracy: 0.7316\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4255 - logit_loss: 0.4255 - layer_1_accuracy: 0.0267 - layer_2_accuracy: 0.0143 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.8938 - output_accuracy: 0.7915 - val_loss: 0.6528 - val_logit_loss: 0.6528 - val_layer_1_accuracy: 0.0275 - val_layer_2_accuracy: 0.0156 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8672 - val_output_accuracy: 0.7746\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3847 - logit_loss: 0.3847 - layer_1_accuracy: 0.0273 - layer_2_accuracy: 0.0151 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9138 - output_accuracy: 0.8107 - val_loss: 0.6369 - val_logit_loss: 0.6369 - val_layer_1_accuracy: 0.0307 - val_layer_2_accuracy: 0.0179 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8704 - val_output_accuracy: 0.7852\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3569 - logit_loss: 0.3569 - layer_1_accuracy: 0.0296 - layer_2_accuracy: 0.0181 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9250 - output_accuracy: 0.8359 - val_loss: 0.6355 - val_logit_loss: 0.6355 - val_layer_1_accuracy: 0.0302 - val_layer_2_accuracy: 0.0211 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8768 - val_output_accuracy: 0.7920\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3391 - logit_loss: 0.3391 - layer_1_accuracy: 0.0300 - layer_2_accuracy: 0.0188 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9293 - output_accuracy: 0.8488 - val_loss: 0.5978 - val_logit_loss: 0.5978 - val_layer_1_accuracy: 0.0298 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.8800 - val_output_accuracy: 0.8071\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3278 - logit_loss: 0.3278 - layer_1_accuracy: 0.0306 - layer_2_accuracy: 0.0198 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9389 - output_accuracy: 0.8561 - val_loss: 0.6179 - val_logit_loss: 0.6179 - val_layer_1_accuracy: 0.0302 - val_layer_2_accuracy: 0.0206 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9020 - val_output_accuracy: 0.8090\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3153 - logit_loss: 0.3153 - layer_1_accuracy: 0.0308 - layer_2_accuracy: 0.0212 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9452 - output_accuracy: 0.8643 - val_loss: 0.5777 - val_logit_loss: 0.5777 - val_layer_1_accuracy: 0.0289 - val_layer_2_accuracy: 0.0206 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9006 - val_output_accuracy: 0.8209\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3046 - logit_loss: 0.3046 - layer_1_accuracy: 0.0300 - layer_2_accuracy: 0.0216 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9470 - output_accuracy: 0.8720 - val_loss: 0.5731 - val_logit_loss: 0.5731 - val_layer_1_accuracy: 0.0293 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9047 - val_output_accuracy: 0.8264\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2973 - logit_loss: 0.2973 - layer_1_accuracy: 0.0300 - layer_2_accuracy: 0.0216 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9484 - output_accuracy: 0.8802 - val_loss: 0.5775 - val_logit_loss: 0.5775 - val_layer_1_accuracy: 0.0293 - val_layer_2_accuracy: 0.0211 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9075 - val_output_accuracy: 0.8301\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2926 - logit_loss: 0.2926 - layer_1_accuracy: 0.0298 - layer_2_accuracy: 0.0220 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9509 - output_accuracy: 0.8857 - val_loss: 0.5453 - val_logit_loss: 0.5453 - val_layer_1_accuracy: 0.0293 - val_layer_2_accuracy: 0.0215 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9075 - val_output_accuracy: 0.8552\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3289 - logit_loss: 0.3289 - layer_1_accuracy: 0.0308 - layer_2_accuracy: 0.0222 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9435 - output_accuracy: 0.8873 - val_loss: 0.5274 - val_logit_loss: 0.5274 - val_layer_1_accuracy: 0.0311 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9056 - val_output_accuracy: 0.8543\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3054 - logit_loss: 0.3054 - layer_1_accuracy: 0.0324 - layer_2_accuracy: 0.0214 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9486 - output_accuracy: 0.8881 - val_loss: 0.5356 - val_logit_loss: 0.5356 - val_layer_1_accuracy: 0.0321 - val_layer_2_accuracy: 0.0211 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9153 - val_output_accuracy: 0.8406\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2938 - logit_loss: 0.2938 - layer_1_accuracy: 0.0326 - layer_2_accuracy: 0.0204 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9562 - output_accuracy: 0.8920 - val_loss: 0.5606 - val_logit_loss: 0.5606 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9162 - val_output_accuracy: 0.8401\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2889 - logit_loss: 0.2889 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0226 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9570 - output_accuracy: 0.8969 - val_loss: 0.5728 - val_logit_loss: 0.5728 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0243 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9171 - val_output_accuracy: 0.8401\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2846 - logit_loss: 0.2846 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0240 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9584 - output_accuracy: 0.9067 - val_loss: 0.5650 - val_logit_loss: 0.5650 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0243 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9189 - val_output_accuracy: 0.8438\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2815 - logit_loss: 0.2815 - layer_1_accuracy: 0.0314 - layer_2_accuracy: 0.0234 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9596 - output_accuracy: 0.9075 - val_loss: 0.5689 - val_logit_loss: 0.5689 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0234 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9189 - val_output_accuracy: 0.8475\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2787 - logit_loss: 0.2787 - layer_1_accuracy: 0.0314 - layer_2_accuracy: 0.0236 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9605 - output_accuracy: 0.9107 - val_loss: 0.5594 - val_logit_loss: 0.5594 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0238 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9203 - val_output_accuracy: 0.8534\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2762 - logit_loss: 0.2762 - layer_1_accuracy: 0.0314 - layer_2_accuracy: 0.0242 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9621 - output_accuracy: 0.9144 - val_loss: 0.5862 - val_logit_loss: 0.5862 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9189 - val_output_accuracy: 0.8516\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2741 - logit_loss: 0.2741 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0249 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9631 - output_accuracy: 0.9158 - val_loss: 0.5592 - val_logit_loss: 0.5592 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0238 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9235 - val_output_accuracy: 0.8575\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2720 - logit_loss: 0.2720 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0249 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9639 - output_accuracy: 0.9193 - val_loss: 0.5717 - val_logit_loss: 0.5717 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0270 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9198 - val_output_accuracy: 0.8552\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2709 - logit_loss: 0.2709 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0251 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9645 - output_accuracy: 0.9222 - val_loss: 0.5633 - val_logit_loss: 0.5633 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9217 - val_output_accuracy: 0.8603\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2704 - logit_loss: 0.2704 - layer_1_accuracy: 0.0314 - layer_2_accuracy: 0.0243 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9647 - output_accuracy: 0.9203 - val_loss: 0.5636 - val_logit_loss: 0.5636 - val_layer_1_accuracy: 0.0316 - val_layer_2_accuracy: 0.0247 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9212 - val_output_accuracy: 0.8607\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2676 - logit_loss: 0.2676 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0234 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9656 - output_accuracy: 0.9230 - val_loss: 0.5742 - val_logit_loss: 0.5742 - val_layer_1_accuracy: 0.0321 - val_layer_2_accuracy: 0.0238 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9212 - val_output_accuracy: 0.8607\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2658 - logit_loss: 0.2658 - layer_1_accuracy: 0.0314 - layer_2_accuracy: 0.0230 - layer_3_accuracy: 0.0012 - logit_accuracy: 0.9652 - output_accuracy: 0.9242 - val_loss: 0.5644 - val_logit_loss: 0.5644 - val_layer_1_accuracy: 0.0321 - val_layer_2_accuracy: 0.0229 - val_layer_3_accuracy: 9.1617e-04 - val_logit_accuracy: 0.9226 - val_output_accuracy: 0.8649\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5373 - logit_loss: 0.5373 - layer_1_accuracy: 0.0322 - layer_2_accuracy: 0.0240 - layer_3_accuracy: 0.0016 - logit_accuracy: 0.9264 - output_accuracy: 0.9081 - val_loss: 0.9573 - val_logit_loss: 0.9573 - val_layer_1_accuracy: 0.0325 - val_layer_2_accuracy: 0.0183 - val_layer_3_accuracy: 0.0023 - val_logit_accuracy: 0.8731 - val_output_accuracy: 0.7948\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5500 - logit_loss: 0.5500 - layer_1_accuracy: 0.0310 - layer_2_accuracy: 0.0214 - layer_3_accuracy: 0.0027 - logit_accuracy: 0.9138 - output_accuracy: 0.8443 - val_loss: 0.8154 - val_logit_loss: 0.8154 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0156 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8539 - val_output_accuracy: 0.8768\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6019 - logit_loss: 0.6019 - layer_1_accuracy: 0.0351 - layer_2_accuracy: 0.0141 - layer_3_accuracy: 3.9270e-04 - logit_accuracy: 0.9052 - output_accuracy: 0.8647 - val_loss: 0.6750 - val_logit_loss: 0.6750 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0101 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.8901 - val_output_accuracy: 0.8278\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4059 - logit_loss: 0.4059 - layer_1_accuracy: 0.0318 - layer_2_accuracy: 0.0120 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9383 - output_accuracy: 0.8716 - val_loss: 0.6383 - val_logit_loss: 0.6383 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0174 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9093 - val_output_accuracy: 0.8378\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3706 - logit_loss: 0.3706 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0159 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9515 - output_accuracy: 0.8859 - val_loss: 0.6263 - val_logit_loss: 0.6263 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0165 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9143 - val_output_accuracy: 0.8534\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3594 - logit_loss: 0.3594 - layer_1_accuracy: 0.0322 - layer_2_accuracy: 0.0163 - layer_3_accuracy: 3.9270e-04 - logit_accuracy: 0.9570 - output_accuracy: 0.9003 - val_loss: 0.6261 - val_logit_loss: 0.6261 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0174 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9166 - val_output_accuracy: 0.8585\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3527 - logit_loss: 0.3527 - layer_1_accuracy: 0.0340 - layer_2_accuracy: 0.0157 - layer_3_accuracy: 3.9270e-04 - logit_accuracy: 0.9566 - output_accuracy: 0.9091 - val_loss: 0.6430 - val_logit_loss: 0.6430 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9185 - val_output_accuracy: 0.8607\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3482 - logit_loss: 0.3482 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0171 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9584 - output_accuracy: 0.9154 - val_loss: 0.6249 - val_logit_loss: 0.6249 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0179 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9180 - val_output_accuracy: 0.8658\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3229 - logit_loss: 0.3229 - layer_1_accuracy: 0.0336 - layer_2_accuracy: 0.0175 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9580 - output_accuracy: 0.9173 - val_loss: 0.5725 - val_logit_loss: 0.5725 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0169 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9198 - val_output_accuracy: 0.8694\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3184 - logit_loss: 0.3184 - layer_1_accuracy: 0.0336 - layer_2_accuracy: 0.0177 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9590 - output_accuracy: 0.9226 - val_loss: 0.6326 - val_logit_loss: 0.6326 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9212 - val_output_accuracy: 0.8690\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3153 - logit_loss: 0.3153 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 0.0185 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9592 - output_accuracy: 0.9258 - val_loss: 0.6281 - val_logit_loss: 0.6281 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0197 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9212 - val_output_accuracy: 0.8749\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3114 - logit_loss: 0.3114 - layer_1_accuracy: 0.0340 - layer_2_accuracy: 0.0187 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9611 - output_accuracy: 0.9281 - val_loss: 0.6056 - val_logit_loss: 0.6056 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0192 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9194 - val_output_accuracy: 0.8781\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3120 - logit_loss: 0.3120 - layer_1_accuracy: 0.0340 - layer_2_accuracy: 0.0196 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9633 - output_accuracy: 0.9287 - val_loss: 0.5989 - val_logit_loss: 0.5989 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9198 - val_output_accuracy: 0.8814\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3099 - logit_loss: 0.3099 - layer_1_accuracy: 0.0332 - layer_2_accuracy: 0.0198 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9627 - output_accuracy: 0.9319 - val_loss: 0.6355 - val_logit_loss: 0.6355 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0211 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9226 - val_output_accuracy: 0.8781\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3109 - logit_loss: 0.3109 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 0.0181 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9615 - output_accuracy: 0.9358 - val_loss: 0.5901 - val_logit_loss: 0.5901 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0202 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9185 - val_output_accuracy: 0.8818\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3070 - logit_loss: 0.3070 - layer_1_accuracy: 0.0332 - layer_2_accuracy: 0.0187 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9633 - output_accuracy: 0.9358 - val_loss: 0.6044 - val_logit_loss: 0.6044 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0215 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9240 - val_output_accuracy: 0.8827\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3046 - logit_loss: 0.3046 - layer_1_accuracy: 0.0332 - layer_2_accuracy: 0.0181 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9656 - output_accuracy: 0.9403 - val_loss: 0.5884 - val_logit_loss: 0.5884 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0220 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9249 - val_output_accuracy: 0.8910\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3032 - logit_loss: 0.3032 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0192 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9654 - output_accuracy: 0.9411 - val_loss: 0.6237 - val_logit_loss: 0.6237 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9240 - val_output_accuracy: 0.8832\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3024 - logit_loss: 0.3024 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0198 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9652 - output_accuracy: 0.9440 - val_loss: 0.6103 - val_logit_loss: 0.6103 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9290 - val_output_accuracy: 0.8891\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3013 - logit_loss: 0.3013 - layer_1_accuracy: 0.0332 - layer_2_accuracy: 0.0202 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9662 - output_accuracy: 0.9433 - val_loss: 0.6445 - val_logit_loss: 0.6445 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0238 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9276 - val_output_accuracy: 0.8827\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3031 - logit_loss: 0.3031 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0212 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9662 - output_accuracy: 0.9450 - val_loss: 0.6391 - val_logit_loss: 0.6391 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0243 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9290 - val_output_accuracy: 0.8841\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3028 - logit_loss: 0.3028 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0208 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9660 - output_accuracy: 0.9458 - val_loss: 0.5946 - val_logit_loss: 0.5946 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0229 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9304 - val_output_accuracy: 0.8887\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3030 - logit_loss: 0.3030 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0208 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9664 - output_accuracy: 0.9462 - val_loss: 0.6321 - val_logit_loss: 0.6321 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0243 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9295 - val_output_accuracy: 0.8891\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3279 - logit_loss: 0.3279 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0196 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9641 - output_accuracy: 0.9344 - val_loss: 0.6665 - val_logit_loss: 0.6665 - val_layer_1_accuracy: 0.0366 - val_layer_2_accuracy: 0.0179 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9134 - val_output_accuracy: 0.8690\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3450 - logit_loss: 0.3450 - layer_1_accuracy: 0.0324 - layer_2_accuracy: 0.0188 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9601 - output_accuracy: 0.9315 - val_loss: 0.6515 - val_logit_loss: 0.6515 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0224 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9290 - val_output_accuracy: 0.8859\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3279 - logit_loss: 0.3279 - layer_1_accuracy: 0.0310 - layer_2_accuracy: 0.0190 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9652 - output_accuracy: 0.9413 - val_loss: 0.5652 - val_logit_loss: 0.5652 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0229 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9166 - val_output_accuracy: 0.9038\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3478 - logit_loss: 0.3478 - layer_1_accuracy: 0.0326 - layer_2_accuracy: 0.0171 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9582 - output_accuracy: 0.9311 - val_loss: 0.6878 - val_logit_loss: 0.6878 - val_layer_1_accuracy: 0.0344 - val_layer_2_accuracy: 0.0238 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9185 - val_output_accuracy: 0.8727\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3229 - logit_loss: 0.3229 - layer_1_accuracy: 0.0338 - layer_2_accuracy: 0.0202 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9643 - output_accuracy: 0.9352 - val_loss: 0.6624 - val_logit_loss: 0.6624 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0211 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9240 - val_output_accuracy: 0.8827\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3189 - logit_loss: 0.3189 - layer_1_accuracy: 0.0336 - layer_2_accuracy: 0.0210 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9651 - output_accuracy: 0.9435 - val_loss: 0.6508 - val_logit_loss: 0.6508 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9253 - val_output_accuracy: 0.8896\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3174 - logit_loss: 0.3174 - layer_1_accuracy: 0.0336 - layer_2_accuracy: 0.0222 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9662 - output_accuracy: 0.9476 - val_loss: 0.6516 - val_logit_loss: 0.6516 - val_layer_1_accuracy: 0.0344 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9262 - val_output_accuracy: 0.8937\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3173 - logit_loss: 0.3173 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0224 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9649 - output_accuracy: 0.9454 - val_loss: 0.6613 - val_logit_loss: 0.6613 - val_layer_1_accuracy: 0.0344 - val_layer_2_accuracy: 0.0261 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9262 - val_output_accuracy: 0.8832\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3169 - logit_loss: 0.3169 - layer_1_accuracy: 0.0332 - layer_2_accuracy: 0.0200 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9660 - output_accuracy: 0.9497 - val_loss: 0.6580 - val_logit_loss: 0.6580 - val_layer_1_accuracy: 0.0344 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 0.0000e+00 - val_logit_accuracy: 0.9267 - val_output_accuracy: 0.8910\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3160 - logit_loss: 0.3160 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0220 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9666 - output_accuracy: 0.9515 - val_loss: 0.6401 - val_logit_loss: 0.6401 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9285 - val_output_accuracy: 0.9001\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3154 - logit_loss: 0.3154 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0208 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9662 - output_accuracy: 0.9521 - val_loss: 0.6658 - val_logit_loss: 0.6658 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9272 - val_output_accuracy: 0.8887\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3154 - logit_loss: 0.3154 - layer_1_accuracy: 0.0332 - layer_2_accuracy: 0.0218 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9658 - output_accuracy: 0.9515 - val_loss: 0.6273 - val_logit_loss: 0.6273 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0234 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9295 - val_output_accuracy: 0.9020\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3153 - logit_loss: 0.3153 - layer_1_accuracy: 0.0326 - layer_2_accuracy: 0.0226 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9666 - output_accuracy: 0.9521 - val_loss: 0.6651 - val_logit_loss: 0.6651 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0252 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9262 - val_output_accuracy: 0.8923\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3150 - logit_loss: 0.3150 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0228 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9670 - output_accuracy: 0.9523 - val_loss: 0.6362 - val_logit_loss: 0.6362 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9290 - val_output_accuracy: 0.8969\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3146 - logit_loss: 0.3146 - layer_1_accuracy: 0.0328 - layer_2_accuracy: 0.0232 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9662 - output_accuracy: 0.9537 - val_loss: 0.6433 - val_logit_loss: 0.6433 - val_layer_1_accuracy: 0.0353 - val_layer_2_accuracy: 0.0243 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9285 - val_output_accuracy: 0.8992\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3136 - logit_loss: 0.3136 - layer_1_accuracy: 0.0336 - layer_2_accuracy: 0.0240 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9678 - output_accuracy: 0.9548 - val_loss: 0.6173 - val_logit_loss: 0.6173 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0243 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9308 - val_output_accuracy: 0.9029\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3151 - logit_loss: 0.3151 - layer_1_accuracy: 0.0334 - layer_2_accuracy: 0.0238 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9666 - output_accuracy: 0.9537 - val_loss: 0.6105 - val_logit_loss: 0.6105 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0243 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9313 - val_output_accuracy: 0.9047\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3144 - logit_loss: 0.3144 - layer_1_accuracy: 0.0328 - layer_2_accuracy: 0.0243 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9668 - output_accuracy: 0.9543 - val_loss: 0.6568 - val_logit_loss: 0.6568 - val_layer_1_accuracy: 0.0357 - val_layer_2_accuracy: 0.0261 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9244 - val_output_accuracy: 0.8928\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3157 - logit_loss: 0.3157 - layer_1_accuracy: 0.0326 - layer_2_accuracy: 0.0271 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9656 - output_accuracy: 0.9562 - val_loss: 0.6591 - val_logit_loss: 0.6591 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0261 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9267 - val_output_accuracy: 0.8988\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3151 - logit_loss: 0.3151 - layer_1_accuracy: 0.0312 - layer_2_accuracy: 0.0247 - layer_3_accuracy: 1.9635e-04 - logit_accuracy: 0.9664 - output_accuracy: 0.9552 - val_loss: 0.6928 - val_logit_loss: 0.6928 - val_layer_1_accuracy: 0.0339 - val_layer_2_accuracy: 0.0261 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9253 - val_output_accuracy: 0.8896\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3142 - logit_loss: 0.3142 - layer_1_accuracy: 0.0330 - layer_2_accuracy: 0.0259 - layer_3_accuracy: 0.0000e+00 - logit_accuracy: 0.9684 - output_accuracy: 0.9541 - val_loss: 0.6647 - val_logit_loss: 0.6647 - val_layer_1_accuracy: 0.0348 - val_layer_2_accuracy: 0.0257 - val_layer_3_accuracy: 4.5809e-04 - val_logit_accuracy: 0.9262 - val_output_accuracy: 0.8951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c588362e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 55)]              0         \n",
      "                                                                 \n",
      " layer_1 (Dense)             (None, 64)                3584      \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " layer_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " logit (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      " output (Activation)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,857\n",
      "Trainable params: 9,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NN to ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "# convert the model to ONNX format\n",
    "onnx_net = onnxmltools.convert_keras(model)\n",
    "onnxmltools.utils.save_model(onnx_net, \"my_model.onnx\")\n",
    "content = onnx_net.SerializeToString()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def setup(onnx_file: str,):\n",
    "    # Load the ONNX model\n",
    "    ort_sess = ort.InferenceSession(onnx_file)\n",
    "    ortvalue = ort.OrtValue.ortvalue_from_numpy(X_train.astype(np.float32), 'cpu')\n",
    "    logits = ort_sess.run(['logit'], {ort_sess.get_inputs()[0].name: ortvalue})\n",
    "    outputs = ort_sess.run(['output'], {ort_sess.get_inputs()[0].name: ortvalue})\n",
    "    x_0 = X_train[y_train == 0].astype(np.float32)\n",
    "    x_1 = X_train[y_train == 1].astype(np.float32)\n",
    "\n",
    "    # get predictions for each class with positive true label   \n",
    "    pred_0 = ort_sess.run(['output'], {ort_sess.get_inputs()[0].name: x_0})[0][:,0]\n",
    "    x_0 = x_0[pred_0 < 0.5]\n",
    "    pred_1 = ort_sess.run(['output'], {ort_sess.get_inputs()[0].name: x_1})[0][:,0]\n",
    "    x_1 = x_1[pred_1 > 0.5]\n",
    "\n",
    "    logits_0_correct = ort_sess.run(['logit'], {ort_sess.get_inputs()[0].name: x_0})[0]\n",
    "    logits_1_correct = ort_sess.run(['logit'], {ort_sess.get_inputs()[0].name: x_1})[0]\n",
    "\n",
    "    # fit GMM to class conditional distributions\n",
    "    best_bic = 100000000\n",
    "    best_gmm_0 = GaussianMixture(n_components=1, random_state=0)\n",
    "    for i in range(1,20):\n",
    "        gmm_0 = GaussianMixture(n_components=i, random_state=0).fit(logits_0_correct)\n",
    "        current_bic = gmm_0.bic(logits_0_correct)\n",
    "        if current_bic < best_bic:\n",
    "            best_bic = current_bic\n",
    "            best_gmm_0 = gmm_0\n",
    "\n",
    "    best_bic = 100000000\n",
    "    best_gmm_1 = GaussianMixture(n_components=1, random_state=0)\n",
    "    for i in range(1,20):\n",
    "        gmm_1 = GaussianMixture(n_components=i, random_state=0).fit(logits_1_correct)\n",
    "        current_bic = gmm_1.bic(logits_1_correct)\n",
    "        if current_bic < best_bic:\n",
    "            best_bic = current_bic\n",
    "            best_components = i\n",
    "            best_gmm_1 = gmm_1 \n",
    "    \n",
    "    return  best_gmm_0, best_gmm_1, ort_sess\n",
    "\n",
    "gmm_0, gmm_1, ort_sess = setup('my_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm_0 number of components is 7\n",
      "gmm_1 number of components is 12\n"
     ]
    }
   ],
   "source": [
    "print('gmm_0 number of components is {}'.format(gmm_0.get_params()['n_components']))\n",
    "print('gmm_1 number of_components is {}'.format(gmm_1.get_params()['n_components']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.88806647e-01, 1.85143100e-01, 8.40374178e-01, ...,\n",
       "        9.99909566e-01, 5.10854426e-09, 5.76177051e-01]),\n",
       " array([0.1593505 , 0.15916828, 0.16116668, ..., 0.16419966, 0.19559842,\n",
       "        0.16012216])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = 80\n",
    "q2 = 60\n",
    "u1 = 0.5\n",
    "u2 = 0.2\n",
    "import math\n",
    "def confidence(x, gmm_0, gmm_1, ort_sess):\n",
    "    logits = ort_sess.run(['logit'], {ort_sess.get_inputs()[0].name: x.astype(np.float32)})[0]\n",
    "\n",
    "    u = []\n",
    "    for gmm in [gmm_0, gmm_1]:\n",
    "        p = gmm.score_samples(logits)\n",
    "        s = max(p) - p\n",
    "\n",
    "        sq1 = np.percentile(s, q1)\n",
    "        sq2 = np.percentile(s, q2)\n",
    "\n",
    "        l1 = math.log(1/u1 - 1)\n",
    "        l2 = math.log(1/u2 - 1)\n",
    "        c2 = (sq2 * l1 - sq1 * l2) / (l1 - l2) \n",
    "        c1 = -l2 / (sq2-c2)\n",
    "\n",
    "        g = 1/(1 + np.exp(-c1 * (s - c2)))\n",
    "        u.append(g)\n",
    "    return u\n",
    "\n",
    "confidence(X_test, gmm_0, gmm_1, ort_sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a46493ef273555f0fac6598162cd73ee5d8ec19f64a4bbbda3cc3aa05bc0ca3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
